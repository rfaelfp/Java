<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">MicroProfile Reactive Messaging in WildFly 23, and WildFly MicroProfile Reactive Specifications Feature Pack 2.0.0.Final</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ZjGnSybcPN0/" /><author><name>Kabir Khan</name></author><id>https://wildfly.org//news/2021/03/11/WildFly-MicroProfile-Reactive-specifications-feature-pack-2.0/</id><updated>2021-03-11T12:00:00Z</updated><content type="html">I am pleased to announce the 2.0.0.Final release of the MicroProfile Reactive Specifications Feature Pack for WildFly. Between the and the release, we pulled the core of what the feature pack contained into WildFLy. WildFly now contains these Galleon layers which used to live in the 1.0.x stream of the feature pack: * microprofile-reactive-messaging - Provides the functionality - this is a framework for building event-driven, data streaming and event sourcing applications using CDI. The streams, or channels, can be backed by a variety of messaging technologies. * microprofile-reactive-messaging-kafka - The include the connector for Kafka in WildFly, in the layer * microprofile-reactive-streams-operators - provides the functionality. The WildFly 23.0.0.Final zip available from our page contains these layers, however they are not enabled by default. To enable the functionality you need to add the extensions and enable the subsystems. The simplest way is to run this . This script is taken from the WildFly Reactive Messaging with Kafka QuickStart, which you can find to get you started. Additionally there are sections about these subsystems in our Admin Guide (/). THE FEATURE PACK As before to use the feature pack you will need to use Galleon to provision a server, as pointed out in the feature pack . That README contains more details of what is contained, but in summary it contains Galleon layers to provide the following functionality: * functionality. * Additional Reactive Messaging connectors for: * AMQP * MQTT We decided to remove RxJava2 support of context propagation for the feature pack since that caused some problems under the hood. RxJava2 is not a supported API for user applications in WildFly (although we use it for somem internal functionality). If you have the need to process streams, please use the MicroProfile Reactive Streams Operators API instead. Note that the 2.0.x series of the feature pack will only work with WildFLy 23. For earlier WildFly versions, use the 1.0.x releases. The present latest release on that stream, 1.0.2, works with WildFLy 21 and WildFly 22. SPEC COMPLIANCE It is worth pointing out that we’re strictly staying with what version 1.0 of the MicroProfile Reactive Messaging specification provides. However, the SmallRye Reactive Messaging we use is used to develop the next version of the specification, which is not ready yet. If you wish to get a preview of that, the steps are to instead of compiling your application against org.eclipse.microprofile.reactive.messaging:microprofile-reactive-messaging-api:1.0, compile against io.smallrye.reactive:smallrye-reactive-messaging-api:3.0.0, and make sure you start the server with -Djboss.as.reactive.messaging.experimental=true which will bypasss some checks and allow you to use more recent, although currently unreleased constructs such as and . Note: - these APIs may still change until there is a final release of the next specification version. WHAT IS COMING UP? Once the MicroProfile Reactive Messaging 2.0 specification is released and the other reactive specifications, MicroProfile Reactive Streams Operators and MicroProfile Context Propagation, are finalised, we will start work on integrating them into a future (as yet to be determined) WildFly version. With the current information, the feature pack then mainly becomes a place for the connectors we don’t want in WildFly yet. FEEDBACK We’re keen to hear your feedback! Please raise any issues found with the feature pack at . And for the parts in WildFly, raise issues at , in the WFLY project (using 'MP Reactive Messaging' as the component).&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ZjGnSybcPN0" height="1" width="1" alt=""/&gt;</content><dc:creator>Kabir Khan</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/03/11/WildFly-MicroProfile-Reactive-specifications-feature-pack-2.0/</feedburner:origLink></entry><entry><title type="html">Supply chain integration - Common architectural elements</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/0YLeOL6ZVQY/supply-chain-integration-common-architectural-elements.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/2a7zREqrrec/supply-chain-integration-common-architectural-elements.html</id><updated>2021-03-11T06:00:00Z</updated><content type="html">Part 2 - Common architectural elements  In  from this series I introduced a use case around supply chain integration for retail stores. The process was laid out how I've approached the use case and how portfolio solutions are the base for researching a generic architectural blueprint.  The only thing left to cover was the order in which you'll be led through the blueprint details. This article starts the real journey at the very top, with a generic architecture from which we'll discuss the common architectural elements one by one. This will start our journey into the logical elements that make up the supply chain integration architecture blueprint. BLUEPRINTS REVIEW As mentioned before, the architectural details covered here are base on real solutions using open source technologies. The example scenario presented here is a generic common blueprint that was uncovered researching those solutions. It's my intent to provide a blueprint that provides guidance and not deep technical details. This section covers the visual representations as presented, but it's expected that they'll be evolving based on future research. There are many ways to represent each element in this architectural blueprint, but I've chosen a format that I hope makes it easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. Now let's take a look at the details in this blueprint and outline the solution. FROM SPECIFIC TO GENERIC Before diving in to the common elements, it might be nice to understand that this is not a catch all for every possible supply chain integration solution. It's a collection of identified elements that I've uncovered in multiple customer implementations. These elements presented here are then the generic common architectural elements that I've identified and collected in to the generic architectural blueprint.  It's my intent to provide a blueprint for guidance and not deep technical details. You're smart enough to figure out wiring integration points in your own architectures. You're capable of slotting in the technologies and components you've committed to in the past where applicable.  It's my job here to describe the architectural blueprint generic components and outline a few specific cases with visual diagrams so that you're able to make the right decisions from the start of your own projects. Another challenge has been how to visually represent the architectural blueprint. There are many ways to represent each element, but I've chosen some icons, text and colours that I hope are going to make it all easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. Now let's take a quick tour of the generic architecture and outline the common elements uncovered in my research. CONTAINER PLATFORM Without a doubt, every modern organisation engaged in business optimisation has seen the value of containers and use of a container platform. The container platform provides for one consistent environment for developers and operations to manage services, applications, integration points, process integration, planning services, and security. It's also the one way to ensure you can uniformly leverage the same container infrastructure across a hybrid multicloud environment. It avoids becoming locked into any private or cloud infrastructure as you have an exit strategy with a container platform that's consistent across your architecture. There are a few elements here worth mentioning, first off the use of supply chain microservices for centralising all interactions with supply chain relevant systems of record and provides access to other services. An api management element for well defined access to services and events, and both message transformation and event streaming services to react and transform communication messages across the platform. Finally, there are elements representing collections of integration microservices and integration data microservices for storage service access. The security aspect is interwoven in the container platform, as each container service, application, or integration can be plugged in to an organisations authentication and authorization mechanisms. INFRASTRUCTURE SERVICES These elements in the common architecture are found in the solutions researched. They were mentioned by name and consisted of an single-sign-on (SSO) that ensures a smooth interaction between processes, authorisation, authentication, and integration services. The AI / Machine Learning platform, shown with a private cloud icon, can be any modern data platform  that are managed and deployed in this organisation's infrastructure to support the retail usage of AI / ML by ensuring access to supply chain data. EXTERNAL SYSTEMS There one more element that represents the external supply chain systems that are integrated with the core elements of this architecture.  As there are often many third-party systems, this element covers basically everything that customers use from partnering ventors. This can be SaaS solutions or any other third-party backend systems. STORAGE SERVICES The storage services uncovered in the research were pretty simplistic and for that reason there's a single physical block storage element.  In later articles, when more detail is shown, I'll make a point to mention the link to a separate architecture blueprint supporting the retail data framework which is linked to this use case. WHAT'S NEXT This was just a short overview of the common generic elements that make up our architecture blueprint for the supply chain integration use case.  An overview of this series on the supply chain integration portfolio architecture blueprint can be found here: 1. 2. 3. Example supply chain integration Catch up on any articles you missed by following one of the links above. Next in this series, taking a look at an example supply chain integration architecture to provide you with a map for your own supply chain solutions. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/0YLeOL6ZVQY" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/2a7zREqrrec/supply-chain-integration-common-architectural-elements.html</feedburner:origLink></entry><entry><title type="html">WildFly 23 is released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/XiMb74ygcHs/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2021/03/11/WildFly23-Final-Released/</id><updated>2021-03-11T00:00:00Z</updated><content type="html">I’m pleased to announce that the WildFly 23 Final zip is now available . It’s been a busy time since the January WildFly 22 release, with a bit shorter development cycle than normal. But a lot has been accomplished. Let’s have a look at what’s new. NEW FEATURES ECLIPSE MICROPROFILE 4.0 In this release we have moved our Eclipse MicroProfile platform implementations from the 3.3 platform specification versions to the 4.0 versions. WildFly 23 supports the following Eclipse MicroProfile platform specifications: Specification Version in WildFly 23 MicroProfile Config MicroProfile Fault Tolerance MicroProfile Health MicroProfile JWT Authentication MicroProfile Metrics MicroProfile OpenAPI MicroProfile OpenTracing MicroProfile Rest Client We also provide all of the MicroProfile specs that are also part of Jakarta EE 8. Please note that an . This may result in incompatible changes between specification releases, which WildFly will necessarily reflect. With MicroProfile 4.0 the following specifications include API incompatible changes: * * * * * MICROPROFILE REACTIVE MESSAGING WildFly 23 now provides . This includes providing a connector for interaction with Kafka streams. This capability adds support for two more MicroProfile specifications to WildFly, implemented via two new extensions and subsystems: Specification Version in WildFly 23 MicroProfile Reactive Messaging MicroProfile Reactive Streams Operators Please note that these extensions and subsystems are not included by default in the standard standalone.xml files that WildFly provides. Users who want them can add them to their configuration by using Galleon to or and telling Galleon to include the new Galleon layers we’ve added for these. Or, use our zip and use the CLI to add the new extensions and subsystems. Further details can be . EXPRESSION RESOLUTION FROM A CREDENTIAL STORE WildFly 23 adds support for expressions in the management model to be . This enhancement makes use of a new resource expression-encryption in the elytron subsystem to configure the expression resolution. This new resource also contains a management operation create-expression which allows users to create encrypted expressions using the usual management clients. In addition to the new resource for expression resolution a new secret-key-credential-store has been added for the purpose of providing an initial secret key to the application server process. In the past users needed to rely on masking a password but this was achieved using a well known public password and password based encryption. Starting from a secret key allows administrators to manage their own initial secret. Both this new credential store resource and the existing credential-store resource have been updated to support the generation of secret keys as well as the ability to export and import previously generated secret keys. Finally the wildfly-elytron-tool has also been updated to support both types of credential store and the credential-store command updated to support management of secret keys and the generation of encrypted tokens for use in expressions. Users of the deprecated Picketbox-vault-backed expression resolution mechanism are strongly encouraged to move to this new feature, as our intent is to remove support for Picketbox and the Picketbox-vault in an upcoming release. PROVISIONING AND MANAGING WILDFLY * For users who wish to deploy multiple applications on the same server instance where one application during startup needs to make an external (i.e. over the network) invocation on another, we have provided a mechanism that prevents such requests being accepted. Not handling such requests can prevent startup of the deployment making them and prevent the server booting. A number of users have asked for this use case tp be supported, so we have done so, but this is not a recommended deployment architecture. A server that is not booting gracefully may receive incoming requests that it is not yet ready to handle, resulting in errors. * There is now . A common file can be used to set up the environment for all the shell scripts that WildFly provides. For example, you can set the JAVA_HOME in a common.conf script configuration file to ensure the same version of Java is used for all scripts. * When launching a WildFly bootable jar, users can as part of boot. This provides a mechanism for performing final configuration that cannot be accomplished via the preferred approach of configuring at build time or via typical runtime customization mechanisms like setting environment variables or system properties. This support is Tech Preview as the mechanism may change in later releases. MESSAGING * The management API can now be used to for investigative purposes. * The behavior of the embedded Artemis broker’s critical-analyzer feature . * The embedded Artemis broker can be configured to for subsequent investigation instead of immediately deleting it. * A call-timeout attribute has been . The attribute specifies the time out for blocking calls performed by a core bridge. OTHER AREAS * The Jakarta Concurrency managed executors provided by the ee subsystem can be that have been executing for an unexpectedly long time. Such tasks can also be manually terminated. * The transaction subsystem now supports for transactions. * The undertow subsystem can now be included as part of the request and response JSESSION_ID cookie. * Deployments can now depend on and use the APIs provided by the following Infinispan-related modules without getting a private API usage warning: * org.infinispan (embedded cache) * org.infinispan.client.hotrod (client for remote infinispan server) * org.infinispan.commons * Principal propagation of EJBs was different for legacy security and Elytron security in some cases. To provide a possibility to configure which behaviour should apply, we legacy-compliant-principal-propagation to application-security-domain component in the ejb3 subsystem. This attribute is optional and the principal propagation is legacy compliant by default. WILDFLY PREVIEW As I when we released WildFly 22 Alpha1, along with our traditional Jakarta EE 8 distribution we want to give our users a preview of what will be coming in WildFly as we move on to EE 9 and later. We call this distribution "WildFly Preview". The WildFly 23.0.0.Final release includes an update to WildFly Preview. Even though this is coming from a .Final tag of the WildFly codebase, WildFly Preview should always be regarded as a tech-preview/beta distribution. EE 9 is primarily about implementing the necessary change in the Jakarta EE APIs from the javax.* package namespace to the jakarta.* namespace. This is a big change that is going to take a while to percolate through the EE ecosystem, e.g. for the many projects that compile against the EE APIs to provide versions that use jakarta.*. While this happens we want to continue to deliver new features and fixes to our community, so the primary WildFly distribution will continue to provide the EE 8 APIs. FEATURE PACK CHANGES WildFly users can use Galleon feature packs to or . The WildFly project produces five different feature packs: wildfly-core, wildfly-servlet, wildfly-ee, wildfly and wildfly-preview. The composition of these feature packs has changed somewhat in WildFly 23, in that the wildfly-ee feature pack no longer depends on wildfly-servlet or (transitively) wildfly-core. Instead it directly incorporates the same content that was previously made available via a dependency relationship. For most users, this subtle difference should have no impact. If you are producing your own feature pack that depends on wildfly or wildfly-ee you may need to adjust your pom.xml and wildfly-feature-pack-build.xml to remove any dependeny on wildfly-servlet and wildfly-core. The WildFly project still produces the wildfly-core and wildfly-servlet feature packs for those who wish to use them, although they may be discontinued at some point. STANDARDS SUPPORT WildFly 23.0.0 is a Jakarta EE 8 compatible implementation, with both the Full Platform and the Web Profile. Beginning with WildFly 23 we will be exclusively focusing on the Jakarta EE test suite for EE certification / compliance. WildFly 23 is also a compliant implementation of the Eclipse MicroProfile 4.0 platform specification. The WildFly Preview distribution released today is not yet a compatible implementation of Jakarta EE 9 or MicroProfile 4.0. We’re continuing to make good progress toward being able to certify compatibility, but we’re not there yet. The main area where users may hit meaningful issues related to EE compliance is in webservices if deployment descriptors using the EE 9 xml schemas are used. This can be worked around by using EE 8 schemas, which are functionally equivalent. JDK SUPPORT Our recommendation is that you run WildFly on the most recent long-term support JDK release, i.e. on JDK 11 for WildFly 23. While we do do some testing of WildFly on JDK 12 and 13, we do considerably more testing of WildFly itself on the LTS JDKs, and we make no attempt to ensure the projects producing the various libraries we integrate are testing their libraries on anything other than JDK 8 or 11. WildFly 23 also is heavily tested and runs well on Java 8. We plan to continue to support Java 8 at least through WildFly 24, and probably beyond. While we recommend using an LTS JDK release, I do believe WildFly runs well on JDK 13. By run well, I mean the main WildFly testsuite runs with no more than a few failures in areas not expected to be commonly used. We want developers who are trying to evaluate what a newer JVM means for their applications to be able to look to WildFly as a useful development platform. We do see a couple of test failures with JDK 13 when using the deprecated Picketlink subsystem and WS Trust. Work to allow WildFly to run on JDK 15 and later is ongoing. We’re continuing our work to digest fully some of the package removals that came in JDK 14, particularly in the security area. The biggest barrier we face is the deprecated legacy security implementation based on Picketbox cannot support JDK 14. We intend to remove support for that security implementation quite soon and to only provide Elytron-based security. Please note that WildFly runs on Java 11 and later in classpath mode. DOCUMENTATION The WildFly 23 documentation is available at the . The WildFly 23 management API documentation is in the . JIRA RELEASE NOTES The full list of issues resolved is available . Issues resolved in the WildFly Core 15 release included with WildFly 23 are available . ENJOY! Thank you for your continued support of WildFly. We’d love to hear your feedback at the .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/XiMb74ygcHs" height="1" width="1" alt=""/&gt;</content><dc:creator>Brian Stansberry</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/03/11/WildFly23-Final-Released/</feedburner:origLink></entry><entry><title>Write your own Red Hat Ansible Tower inventory plugin</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ykaTXiaqjao/" /><category term="Automation" /><category term="Python" /><category term="Ansible" /><category term="Ansible inventories" /><category term="Ansible inventory plugin" /><category term="AWX" /><category term="Python 3" /><author><name>Rigel Di Scala</name></author><id>https://developers.redhat.com/blog/?p=780487</id><updated>2021-03-10T08:00:44Z</updated><published>2021-03-10T08:00:44Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/ansible/ansible"&gt;Ansible&lt;/a&gt; is an engine and language for automating many different IT tasks, such as provisioning a physical device, creating a virtual machine, or configuring an application and its dependencies. Ansible organizes these tasks in &lt;em&gt;playbook&lt;/em&gt; files, which run on one or more remote target hosts. &lt;em&gt;Inventory&lt;/em&gt; files maintain lists of these hosts and are formatted as YAML or INI documents. For example, a simple inventory file in INI format follows:&lt;/p&gt; &lt;pre&gt;[web] web1.example.com web2.example.com &lt;/pre&gt; &lt;p&gt;Ansible inventories can be &lt;em&gt;static&lt;/em&gt; (stored in a file and managed in a source code repository) or &lt;em&gt;dynamic&lt;/em&gt; (retrieved from an external web resource, such as through a RESTful API). Dynamic inventories are generated on-demand using &lt;em&gt;inventory scripts&lt;/em&gt; or &lt;em&gt;inventory plugins&lt;/em&gt;, consisting of code that Ansible runs to get a list of hosts to target when executing playbooks.&lt;/p&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/reference_appendices/tower.html"&gt;Red Hat Ansible Tower&lt;/a&gt;, also known as &lt;a target="_blank" rel="nofollow" href="https://github.com/ansible/awx"&gt;AWX&lt;/a&gt; (the name of its upstream community project), is a front-end to &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/products/red-hat-ansible-engine/"&gt;Red Hat Ansible Engine&lt;/a&gt; that simplifies operations on large IT infrastructures. Operators can log into the Ansible Tower web interface and create single jobs or complex workflows using Ansible Engine building blocks such as tasks, roles, and playbooks. Enterprises typically manage assets in a configuration management database (CMDB), such as &lt;a target="_blank" rel="nofollow" href="https://netbox.readthedocs.io/en/stable/"&gt;NetBox&lt;/a&gt;, which Ansible Tower connects to using a specially written script or plugin.&lt;/p&gt; &lt;p&gt;This article shows you how to use Ansible Tower to create dynamic inventories. We&amp;#8217;ll start with a sample inventory script, then transform the script into a plugin. As you&amp;#8217;ll see, inventory plugins can accept parameters, which gives them an advantage over plain scripts.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Inventory scripts are &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible-tower/latest/html/administration/custom_inventory_script.html#"&gt;deprecated in Ansible Tower&lt;/a&gt;, so they will be removed in a future version. There’s a good reason: Source code is properly managed in a version control system, where developers and operators can track and review changes to its corpus.&lt;/p&gt; &lt;h2&gt;A sample inventory script&lt;/h2&gt; &lt;p&gt;Inventory scripts are organized in a single executable file, written in a scripting language such as Python or Bash. The script must return its data in JSON format. For instance, the following output provides the Ansible playbook with a list of hosts and related data:&lt;/p&gt; &lt;pre&gt;{ "all": { "hosts": ["web1.example.com", "web2.example.com"] }, "_meta": { "hostvars": { "web1.example.com": { "ansible_user": "root" }, "web2.example.com": { "ansible_user": "root" } } } } &lt;/pre&gt; &lt;p&gt;The following Bash code is an inventory script that generates the output just shown:&lt;/p&gt; &lt;pre&gt;#!/usr/bin/env bash # id: scripts/trivial-inventory-script.sh cat &amp;#60;&amp;#60; EOF { "all": { "hosts": ["web1.example.com", "web2.example.com"] }, "_meta": { "hostvars": { "web1.example.com": { "ansible_user": "rdiscala" }, "web2.example.com": { "ansible_user": "rdiscala" } } } } EOF &lt;/pre&gt; &lt;p&gt;Here, an Ansible command runs the inventory script and compares the actual output to the expected output:&lt;/p&gt; &lt;pre&gt;$ ansible -m ping -i scripts/trivial-inventory-script.sh all web1.example.com | SUCCESS =&amp;#62; { "ansible_facts": { "discovered_interpreter_python": "/usr/bin/python" }, "changed": false, "ping": "pong" } web2.example.com | SUCCESS =&amp;#62; { "ansible_facts": { "discovered_interpreter_python": "/usr/bin/python" }, "changed": false, "ping": "pong" } &lt;/pre&gt; &lt;p&gt;The output shows that Ansible correctly interpreted the information given in the &lt;code&gt;hostvars&lt;/code&gt; section and used my username &lt;code&gt;rdiscala&lt;/code&gt; to connect via SSH to the server hosts.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The sample script is intentionally brief and omits a detail: Ansible invokes these scripts with the &lt;code&gt;--list&lt;/code&gt; option if a list of hosts needs to be produced, as it does in our case. Alternatively, Ansible provides the &lt;code&gt;--host=NAME&lt;/code&gt; option when it needs the variables of a specific host, identified by its &lt;code&gt;NAME&lt;/code&gt;. To make the script fully compliant, you would need to implement logic to handle these options.&lt;/p&gt; &lt;h2&gt;Making scripts work in Ansible Tower&lt;/h2&gt; &lt;p&gt;Scripts are defined in the Inventory Scripts section of Ansible Tower&amp;#8217;s web interface. Alternatively, you can write a script in any scripting language supported on the Ansible Tower host. As shown in Figure 1, you can paste the script we&amp;#8217;ve just written directly into the &lt;b&gt;CUSTOM SCRIPT&lt;/b&gt; field and use it to sync an inventory inside Ansible Tower.&lt;/p&gt; &lt;div id="attachment_780867" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script.png"&gt;&lt;img aria-describedby="caption-attachment-780867" class="wp-image-780867" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-300x191.png" alt="Ansible Tower's Inventory Scripts screen contains a text field named CUSTOM SCRIPT, where an administrator can insert an inventory script." width="640" height="408" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-300x191.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-768x490.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script.png 936w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780867" class="wp-caption-text"&gt;Figure 1: You can plug a pre-written script into Ansible Tower&amp;#8217;s Inventory Scripts section.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can now use this new script as an &lt;em&gt;inventory source&lt;/em&gt; in any Ansible Tower inventory. An inventory source provides information about hosts to Ansible Tower on demand. When the source syncs, the script will run, fetch the data, and format it as shown previously so that Ansible Tower can import it into its own host database. The complete list of hosts will show up in the &lt;b&gt;HOSTS&lt;/b&gt; table, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_780877" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts.png"&gt;&lt;img aria-describedby="caption-attachment-780877" class="wp-image-780877 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts-1024x482.png" alt="Ansible Tower's Inventory Scripts screen contains a text field named CUSTOM SCRIPT, where an administrator can insert an inventory script." width="640" height="301" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts-1024x482.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts-300x141.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts-768x362.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts.png 1036w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780877" class="wp-caption-text"&gt;Figure 2: Find the complete list of hosts in the HOSTS table.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Create an inventory plugin with Ansible Galaxy&lt;/h2&gt; &lt;p&gt;The newer and recommended way to distribute and consume Ansible content is to create an inventory plugin and package it as an &lt;a target="_blank" rel="nofollow" href="https://www.ansible.com/blog/getting-started-with-ansible-collections"&gt;Ansible collection&lt;/a&gt;. An inventory plugin is considered a module when packaged in a collection.&lt;/p&gt; &lt;p&gt;You can kickstart your effort by using the &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/cli/ansible-galaxy.html"&gt;Ansible Galaxy command-line program&lt;/a&gt; to create the basic structure for a collection:&lt;/p&gt; &lt;pre&gt;$ ansible-galaxy collection init zedr.blog_examples - Collection zedr.blog_examples was created successfully $ tree . . └── zedr └── blog_examples ├── docs ├── galaxy.yml ├── plugins │ └── README.md ├── README.md └── roles &lt;/pre&gt; &lt;p&gt;Let’s start with &lt;code&gt;galaxy.yml&lt;/code&gt;, the manifest file describes this collection:&lt;/p&gt; &lt;pre&gt;namespace: zedr name: blog_examples version: 1.0.0 readme: README.md authors: - Rigel Di Scala &amp;#60;rigel@redhat.com&amp;#62; &lt;/pre&gt; &lt;p&gt;We will create our plugin as a Python script named &lt;code&gt;example_hosts.py&lt;/code&gt; inside the &lt;code&gt;plugins/inventory&lt;/code&gt; folder. Placing the script in this location lets Ansible detect it as an inventory plugin. We can delete the &lt;code&gt;docs&lt;/code&gt; and &lt;code&gt;roles&lt;/code&gt; folders to focus on the minimum viable set of files needed to implement our collection. We should end up with a folder structure like this one:&lt;/p&gt; &lt;pre&gt;$ tree . . └── zedr └── blog_examples ├── galaxy.yml ├── plugins │ └── inventory │ └── example_hosts.py └── README.md &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Important&lt;/strong&gt;: Always specify the full namespace of the collection (for instance, &lt;code&gt;zedr.blog_examples&lt;/code&gt;) when referring to assets contained within it, such as roles and plugins.&lt;/p&gt; &lt;p&gt;We can now copy over, clean up, and populate the &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html"&gt;basic boilerplate code&lt;/a&gt; for an inventory plugin:&lt;/p&gt; &lt;pre&gt;from ansible.plugins.inventory import BaseInventoryPlugin ANSIBLE_METADATA = { 'metadata_version': '', 'status': [], 'supported_by': '' } DOCUMENTATION = ''' --- module: plugin_type: short_description: version_added: "" description: options: author: ''' class InventoryModule(BaseInventoryPlugin): """An example inventory plugin.""" NAME = 'FQDN_OF_THE_PLUGIN_GOES_HERE' def verify_file(self, path): """Verify that the source file can be processed correctly. Parameters: path:AnyStr The path to the file that needs to be verified Returns: bool True if the file is valid, else False """ def parse(self, inventory, loader, path, cache=True): """Parse and populate the inventory with data about hosts. Parameters: inventory The inventory to populate """ # The following invocation supports Python 2 in case we are # still relying on it. Use the more convenient, pure Python 3 syntax # if you don't need it. super(InventoryModule, self).parse(inventory, loader, path, cache) &lt;/pre&gt; &lt;h3&gt;About the code&lt;/h3&gt; &lt;p&gt;You&amp;#8217;ll note that this boilerplate defines two methods: &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#verify-file"&gt;&lt;code&gt;verify_file()&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;parse()&lt;/code&gt;. Use &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#verify-file"&gt;&lt;code&gt;verify_file()&lt;/code&gt;&lt;/a&gt; when the host list you want to process comes from a file, such as a CSV document, on a filesystem at a given path. This method is used to validate the file quickly before passing it to the more expensive &lt;code&gt;parse()&lt;/code&gt; method. Normally, &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#verify-file"&gt;&lt;code&gt;verify_file()&lt;/code&gt;&lt;/a&gt; ensures that the file is valid incoming JSON and matches a predefined schema. (Note that the &lt;code&gt;verify_file()&lt;/code&gt; method is currently empty and must be filled in.)&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;verify_file()&lt;/code&gt; method can return &lt;code&gt;True&lt;/code&gt; when input comes from a source other than a file, such as when calling a remote HTTP API. But it could also verify the incoming JSON.&lt;/p&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#parse"&gt;&lt;code&gt;parse()&lt;/code&gt;&lt;/a&gt; method does most of the work of processing the source data to filter and format it correctly. However, instead of directly constructing the payload&amp;#8217;s &lt;code&gt;dict&lt;/code&gt; namespace, as we did in the inventory script, we will rely on the &lt;em&gt;instance attribute&lt;/em&gt;, &lt;code&gt;self.inventory&lt;/code&gt;, which is a special object with its own methods. The attribute offers &lt;code&gt;add_host()&lt;/code&gt; and &lt;code&gt;set_variable()&lt;/code&gt; methods to construct a data object suitable for Ansible to consume. (The &lt;code&gt;parse()&lt;/code&gt; method is currently empty except for a call to the superclass&amp;#8217;s function.)&lt;/p&gt; &lt;p&gt;Additionally, note that the module-level attributes &lt;code&gt;ANSIBLE_METADATA&lt;/code&gt; and &lt;code&gt;DOCUMENTATION&lt;/code&gt; are required, and that the &lt;code&gt;NAME&lt;/code&gt; attribute must have the plugin&amp;#8217;s fully qualified domain name, including the namespace.&lt;/p&gt; &lt;h3&gt;Invoking the plugin&lt;/h3&gt; &lt;p&gt;When the plugin is invoked in Ansible from the command line, the following chain of events occurs:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The conventional name &lt;code&gt;InventoryModule&lt;/code&gt; is imported from the chosen inventory module (&lt;code&gt;zedr.blog_example.example_hosts.py&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;An instance of &lt;code&gt;InventoryModule&lt;/code&gt; is created.&lt;/li&gt; &lt;li&gt;The instance method &lt;code&gt;InventoryModule.verify_file()&lt;/code&gt; is called to perform an initial validation of the file (when applicable) and is expected to return a truthy value to proceed.&lt;/li&gt; &lt;li&gt;The instance method &lt;code&gt;InventoryModule.parse()&lt;/code&gt; is called to populate the &lt;code&gt;InventoryModule.inventory&lt;/code&gt; object.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;InventoryModule.inventory&lt;/code&gt; object is introspected to retrieve the host data that Ansible will consume.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We can now rewrite the script logic as follows:&lt;/p&gt; &lt;pre&gt;from ansible.plugins.inventory import BaseInventoryPlugin ANSIBLE_METADATA = { 'metadata_version': '1.0.0', 'status': ['preview'], 'supported_by': 'community' } DOCUMENTATION = ''' --- module: example_hosts plugin_type: inventory short_description: An example Ansible Inventory Plugin version_added: "2.9.13" description: - "A very simple Inventory Plugin created for demonstration purposes only." options: author: - Rigel Di Scala ''' class InventoryModule(BaseInventoryPlugin): """An example inventory plugin.""" NAME = 'zedr.blog_examples.example_hosts' def verify_file(self, path): """Verify that the source file can be processed correctly. Parameters: path:AnyStr The path to the file that needs to be verified Returns: bool True if the file is valid, else False """ # Unused, always return True return True def _get_raw_host_data(self): """Get the raw static data for the inventory hosts Returns: dict The host data formatted as expected for an Inventory Script """ return { "all": { "hosts": ["web1.example.com", "web2.example.com"] }, "_meta": { "hostvars": { "web1.example.com": { "ansible_user": "rdiscala" }, "web2.example.com": { "ansible_user": "rdiscala" } } } } def parse(self, inventory, *args, **kwargs): """Parse and populate the inventory with data about hosts. Parameters: inventory The inventory to populate We ignore the other parameters in the future signature, as we will not use them. Returns: None """ # The following invocation supports Python 2 in case we are # still relying on it. Use the more convenient, pure Python 3 syntax # if you don't need it. super(InventoryModule, self).parse(inventory, *args, **kwargs) raw_data = self._get_raw_host_data() _meta = raw_data.pop('_meta') for group_name, group_data in raw_data.items(): for host_name in group_data['hosts']: self.inventory.add_host(host_name) for var_key, var_val in _meta['hostvars'][host_name].items(): self.inventory.set_variable(host_name, var_key, var_val) &lt;/pre&gt; &lt;p&gt;Note that we have ignored facilities related to grouping and &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#inventory-cache"&gt;caching&lt;/a&gt; to keep things simple. These facilities are worth looking into to organize the host list better and optimize the synchronization process&amp;#8217;s performance.&lt;/p&gt; &lt;h3&gt;Build, install, and test the plugin&lt;/h3&gt; &lt;p&gt;The next step is to build the Ansible collection package, install it locally, and test the plugin:&lt;/p&gt; &lt;pre&gt;$ cd zedr/blog_examples $ mkdir build $ ansible-galaxy collection build -f --output-path build Created collection for zedr.blog_examples at /home/rdiscala/blog/ansible-tower-inventory-plugin/collections/zedr/blog_examples/build/zedr-blog_examples-1.0.0.tar.gz $ ansible-galaxy collection install build/zedr-blog_examples-1.0.0.tar.gz Process install dependency map Starting collection install process Installing 'zedr.blog_examples:1.0.0' to '/home/rdiscala/.ansible/collections/ansible_collections/zedr/blog_examples' &lt;/pre&gt; &lt;p&gt;Next, we need to enable our plugin by adding a local &lt;code&gt;galaxy.cfg&lt;/code&gt; file in our current working directory. The contents are:&lt;/p&gt; &lt;pre&gt;[inventory] enable_plugins = zedr.blog_examples.example_hosts &lt;/pre&gt; &lt;p&gt;To check whether the local installation was successful, we can attempt to display the documentation for our inventory plugin, using its fully qualified domain name:&lt;/p&gt; &lt;pre&gt;$ ansible-doc -t inventory zedr.blog_examples.example_hosts &amp;#62; INVENTORY (/home/rdiscala/.ansible/collections/ansible_collections/zedr/blog_examples/plugins/inventory/example_hosts.py) An example Inventory Plugin created for demonstration purposes only. * This module is maintained by The Ansible Community AUTHOR: Rigel Di Scala &amp;#60;rigel@redhat.com&amp;#62; METADATA: status: - preview supported_by: community PLUGIN_TYPE: inventory &lt;/pre&gt; &lt;p&gt;We can also list the available plugins to verify that ours is detected correctly. Note that for this to work with the Ansible collection, you will need &lt;a target="_blank" rel="nofollow" href="https://pypi.org/project/ansible/#history2.10"&gt;Ansible version 3.0 or higher&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;$ ansible-doc -t inventory -l advanced_host_list Parses a 'host list' with ranges amazon.aws.aws_ec2 EC2 inventory source amazon.aws.aws_rds rds instance source auto Loads and executes an inventory plugin specified in a YAML config (...) zedr.blog_examples.example_hosts A trivial example of an Ansible Inventory Plugin &lt;/pre&gt; &lt;p&gt;Finally, we can test the plugin locally by running it using an inventory configuration file. Create a file named &lt;code&gt;inventory.yml&lt;/code&gt; with the following content:&lt;/p&gt; &lt;pre&gt;plugin: "zedr.blog_examples.example_hosts" &lt;/pre&gt; &lt;p&gt;Here is the command to invoke the plugin and generate the inventory data:&lt;/p&gt; &lt;pre&gt;$ ansible-inventory --list -i inventory.yml { "_meta": { "hostvars": { "web1.example.com": { "ansible_user": "rdiscala" }, "web2.example.com": { "ansible_user": "rdiscala" } } }, "all": { "children": [ "ungrouped" ] }, "ungrouped": { "hosts": [ "web1.example.com", "web2.example.com" ] } } &lt;/pre&gt; &lt;p&gt;Ansible has generated two &amp;#8220;virtual&amp;#8221; groups: &lt;code&gt;ungrouped&lt;/code&gt;, with our list of hosts, and &lt;code&gt;all&lt;/code&gt;, which includes &lt;code&gt;ungrouped&lt;/code&gt;. We have verified that the plugin is working correctly.&lt;/p&gt; &lt;h2&gt;Making the plugin work in Ansible Tower&lt;/h2&gt; &lt;p&gt;Ansible Tower can automate a collection&amp;#8217;s installation, making its roles and plugins available to projects and job templates. To make it work, we need the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A place to provide the package file that we built for our collection. We&amp;#8217;ll use a Git repo hosted on GitHub, but it could also be published on &lt;a target="_blank" rel="nofollow" href="https://galaxy.ansible.com/"&gt;Ansible Galaxy&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;A repo for the project files containing the &lt;code&gt;requirements.yml&lt;/code&gt; file that references our collection and the &lt;code&gt;inventory.yml&lt;/code&gt; configuration file we used previously.&lt;/li&gt; &lt;li&gt;An Ansible Tower project that points to the project files repo.&lt;/li&gt; &lt;li&gt;An Ansible Tower inventory.&lt;/li&gt; &lt;li&gt;An Ansible Tower inventory source for our inventory.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The following events will be triggered when Ansible Tower executes a job that uses this inventory:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The job triggers a project update (the internal &lt;code&gt;project_update.yml&lt;/code&gt; playbook).&lt;/li&gt; &lt;li&gt;The project syncs with its associated Git repo.&lt;/li&gt; &lt;li&gt;If necessary, the project installs any needed dependencies, which should be listed in the &lt;code&gt;collection/requirements.yml&lt;/code&gt; file.&lt;/li&gt; &lt;li&gt;The project update triggers an inventory update.&lt;/li&gt; &lt;li&gt;The inventory update triggers an inventory source sync.&lt;/li&gt; &lt;li&gt;The inventory source sync reads the inventory file &lt;code&gt;inventory.yml&lt;/code&gt; and runs our plugin to fetch the host data.&lt;/li&gt; &lt;li&gt;The host data populates the inventory.&lt;/li&gt; &lt;li&gt;The job runs the associated playbook on the inventory host list using the provided hostnames and variables.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Figure 3 shows this workflow.&lt;/p&gt; &lt;div id="attachment_780817" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow.png"&gt;&lt;img aria-describedby="caption-attachment-780817" class="wp-image-780817 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow-1024x512.png" alt="Visualizing the inventory-update process workflow just described." width="640" height="320" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow-1024x512.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow-300x150.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow-768x384.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780817" class="wp-caption-text"&gt;Figure 3: The workflow for populating a host list using an inventory plugin.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, let&amp;#8217;s create the components required to make the plugin work.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The following example was tested on Ansible Tower 3.7.1.&lt;/p&gt; &lt;h3&gt;Create a Git repo for the collection&lt;/h3&gt; &lt;p&gt;To start, we&amp;#8217;ll create a new repo on Github and push the collection files we created earlier. A &lt;a target="_blank" rel="nofollow" href="https://github.com/zedr/blog_examples"&gt;sample repo&lt;/a&gt; is available on GitHub.&lt;/p&gt; &lt;p&gt;Ansible cannot clone a repository and build the collection by itself, so we need to build the package and make it available as a downloadable &lt;code&gt;tar.gz&lt;/code&gt; file. As an example, from the &lt;a href="https://github.com/zedr/blog_examples/releases/"&gt;Releases page&lt;/a&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: At the time of writing, Ansible Tower cannot fetch the package as an authenticated user, so you will need to allow anonymous clients.&lt;/p&gt; &lt;p&gt;If you are using GitHub, you can set up a GitHub Actions workflow to fully automate this process:&lt;/p&gt; &lt;pre&gt;# id: .github/workflows/main.yml name: CI # Only build releases when a new tag is pushed. on: push: tags: - '*' jobs: build: runs-on: ubuntu-latest steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v2 # Extract the version from the tag name so it can be used later. - name: Get the version id: get_version run: echo ::set-output name=VERSION::${GITHUB_REF#refs/tags/} # Install a recent version of Python 3 - name: Setup Python uses: actions/setup-python@v2 with: python-version: 3.7 # Install our dependencies, e.g. Ansible - name: Install Python 3.7 run: python3.7 -m pip install -r requirements.txt - name: Build the Ansible collection run: | mkdir -p build ansible-galaxy collection build -f --output-path build - name: Create a Release id: create_a_release uses: actions/create-release@v1 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: tag_name: ${{ steps.get_version.outputs.VERSION }} release_name: Release ${{ steps.get_version.outputs.VERSION }} draft: false - name: Upload a Release Asset uses: actions/upload-release-asset@v1.0.2 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: upload_url: ${{ steps.create_a_release.outputs.upload_url }} asset_path: build/zedr-blog_examples-${{ steps.get_version.outputs.VERSION }}.tar.gz asset_name: "zedr-blog_examples-${{ steps.get_version.outputs.VERSION }}.tar.gz" asset_content_type: "application/gzip" &lt;/pre&gt; &lt;h3&gt;Create a Git repo for project files&lt;/h3&gt; &lt;p&gt;Next, we need another Git repo for the files that the Ansible Tower project will source. Here is the folder structure:&lt;/p&gt; &lt;pre&gt;$ tree . . ├── collections │ └── requirements.yml └── inventory.yml &lt;/pre&gt; &lt;p&gt;Note that &lt;code&gt;collections/requirements.yml&lt;/code&gt; will contain a reference to our Ansible collection package so that Ansible Tower can download, install, and use it when the inventory is synced. Additionally, the &lt;code&gt;inventory.yml&lt;/code&gt; is the same file we created earlier, containing the plugin&amp;#8217;s fully qualified domain name. See the &lt;a target="_blank" rel="nofollow" href="https://github.com/zedr-automation/example_project"&gt;example repo&lt;/a&gt; for more details.&lt;/p&gt; &lt;h3&gt;Create a new Ansible Tower project&lt;/h3&gt; &lt;p&gt;Next, sign in to your Ansible Tower instance, create a new project, and fill in the following fields and checkboxes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Name&lt;/b&gt;: &lt;code&gt;My Project&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Organization&lt;/b&gt;: &lt;code&gt;Default&lt;/code&gt; (or whatever you prefer).&lt;/li&gt; &lt;li&gt;&lt;b&gt;SCM Type&lt;/b&gt;: &lt;code&gt;Git&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;SCM URL&lt;/b&gt;: &lt;code&gt;https://github.com/zedr-automation/example_project.git&lt;/code&gt; (or the Git repo URL of your project).&lt;/li&gt; &lt;li&gt;&lt;b&gt;SCM Branch/Tag/Commit&lt;/b&gt;: &lt;code&gt;master&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;SCM Update Options&lt;/b&gt;: select &lt;b&gt;Clean&lt;/b&gt;, &lt;b&gt;Delete On Update&lt;/b&gt;, and &lt;b&gt;Update Revision on Launch&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Figure 4 shows the resulting form.&lt;/p&gt; &lt;div id="attachment_780857" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project.png"&gt;&lt;img aria-describedby="caption-attachment-780857" class="wp-image-780857" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project-300x246.png" alt="This form creates the Ansible Tower project." width="640" height="525" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project-300x246.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project-768x629.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project.png 920w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780857" class="wp-caption-text"&gt;Figure 4: Creating the Ansible Tower project.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Create a new Ansible Tower inventory&lt;/h3&gt; &lt;p&gt;There are just two fields to create a new inventory in Tower: For the &lt;b&gt;Name&lt;/b&gt; field, enter &lt;code&gt;My Inventory&lt;/code&gt;. For the &lt;b&gt;Organization&lt;/b&gt;, you can select the default or whatever you previously entered. Figure 5 shows the resulting form.&lt;/p&gt; &lt;div id="attachment_780837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory.png"&gt;&lt;img aria-describedby="caption-attachment-780837" class="wp-image-780837" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory-300x214.png" alt="This form creates the Ansible Tower inventory." width="640" height="456" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory-300x214.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory-768x548.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory.png 923w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780837" class="wp-caption-text"&gt;Figure 5: Creating the Ansible Tower inventory.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Create a new inventory source for the inventory&lt;/h3&gt; &lt;p&gt;Finally, create a new inventory source for the inventory. Fill in the fields and checkboxes as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Name&lt;/b&gt;: &lt;code&gt;My inventory source&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Source&lt;/b&gt;: &lt;code&gt;Sourced from a project&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Project&lt;/b&gt;: &lt;code&gt;My project&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Inventory File&lt;/b&gt;: &lt;code&gt;inventory.yml&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Update Options&lt;/b&gt;: Select &lt;b&gt;Overwrite&lt;/b&gt;, &lt;b&gt;Overwrite Variables&lt;/b&gt;, and &lt;b&gt;Update on Project Update&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Save the form and then click the &lt;b&gt;Start sync process&lt;/b&gt; button for the new inventory source you just created. If the process finishes correctly, your inventory&amp;#8217;s HOSTS page will display the two example hosts, as shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_780827" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts.png"&gt;&lt;img aria-describedby="caption-attachment-780827" class="wp-image-780827" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts-300x148.png" alt="The two hosts just created appear in the hosts list in the Ansible Tower inventory." width="640" height="316" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts-768x380.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts.png 999w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780827" class="wp-caption-text"&gt;Figure 6: Viewing the HOSTS list in the Ansible Tower inventory.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Final thoughts&lt;/h2&gt; &lt;p&gt;The inventory plugin we&amp;#8217;ve created is basic, but it’s a good foundation for implementing more complex ones that can query external sources of data, perhaps using third-party libraries. Being modules, inventory plugins can also accept parameters, giving them an advantage over plain scripts. For more information, see the official Ansible documentation on &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_plugins.html#plugin-configuration-documentation-standards"&gt;plugin configuration&lt;/a&gt;. Also, note that if you decide to use a third-party library not present in Python’s standard library, such as &lt;a target="_blank" rel="nofollow" href="https://requests.readthedocs.io/en/master/"&gt;Requests&lt;/a&gt;, you will need to install it manually in the appropriate &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible-tower/3.7.1/html/administration/tipsandtricks.html#using-virtualenv-with-at"&gt;Python virtual environment inside Ansible Tower&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Happy developing!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#038;title=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" data-a2a-url="https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/" data-a2a-title="Write your own Red Hat Ansible Tower inventory plugin"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/"&gt;Write your own Red Hat Ansible Tower inventory plugin&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ykaTXiaqjao" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Ansible is an engine and language for automating many different IT tasks, such as provisioning a physical device, creating a virtual machine, or configuring an application and its dependencies. Ansible organizes these tasks in playbook files, which run on one or more remote target hosts. Inventory files maintain lists of these hosts and are formatted [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/"&gt;Write your own Red Hat Ansible Tower inventory plugin&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">780487</post-id><dc:creator>Rigel Di Scala</dc:creator><dc:date>2021-03-10T08:00:44Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/</feedburner:origLink></entry><entry><title type="html">ja.quarkus.io is now public</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FyAkPrXlrCU/" /><author><name /></author><id>https://quarkus.io/blog/ja-quarkus-io/</id><updated>2021-03-10T00:00:00Z</updated><content type="html">Today we’re proud to announce our quarkus.io Japanese localization site (https://ja.quarkus.io) is now open. It is where our valuable guides and blog entries are translated. Some contents have not been translated yet, but we are continuing to translate them one by one. We are working on the localization of the...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FyAkPrXlrCU" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/ja-quarkus-io/</feedburner:origLink></entry><entry><title>An introduction to JavaScript SDK for CloudEvents</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/QyzqZRtXZYY/" /><category term="Event-Driven" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="CloudEvents" /><category term="serverless functions" /><category term="Typescript" /><author><name>Lucas Holmquist</name></author><id>https://developers.redhat.com/blog/?p=810797</id><updated>2021-03-09T08:00:50Z</updated><published>2021-03-09T08:00:50Z</published><content type="html">&lt;p&gt;In today&amp;#8217;s world of &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;serverless&lt;/a&gt; functions and &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt;, events are everywhere. The problem is that they are described differently depending on the producer technology you use.&lt;/p&gt; &lt;p&gt;Without a common standard, the burden is on developers to constantly relearn how to consume events. Not having a standard also makes it more difficult for authors of libraries and tooling to deliver event data across environments like SDKs. Recently, a new project was created to help with this effort.&lt;/p&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://cloudevents.io/"&gt;CloudEvents&lt;/a&gt; is a specification for describing event data in common formats to provide interoperability across services, platforms, and systems. In fact, Red Hat OpenShift Serverless Functions uses CloudEvents. For more information about this new developer feature, see &lt;a target="_blank" rel="nofollow" href="/blog/2021/01/04/create-your-first-serverless-function-with-red-hat-openshift-serverless-functions/"&gt;&lt;em&gt;Create your first serverless function with Red Hat OpenShift Serverless Functions&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;The CloudEvents specification&lt;/h2&gt; &lt;p&gt;The specification&amp;#8217;s goal isn’t to create yet another event format and try to force everyone to use it. Rather, we want to define common metadata for events and establish where this metadata should appear in the message being sent.&lt;/p&gt; &lt;p&gt;It is a simple spec with simple goals. In fact, a CloudEvent requires only four pieces of metadata:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;type&lt;/code&gt; describes what kind of event this might be (e.g., a “create” event).&lt;/li&gt; &lt;li&gt;&lt;code&gt;specversion&lt;/code&gt; denotes the version of the spec used to create the CloudEvent.&lt;/li&gt; &lt;li&gt;&lt;code&gt;source&lt;/code&gt; describes where the event came from.&lt;/li&gt; &lt;li&gt;&lt;code&gt;id&lt;/code&gt; is a unique identifier that is useful for de-duping.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There are other useful fields, like &lt;code&gt;subject&lt;/code&gt;, which when combined with &lt;code&gt;source&lt;/code&gt; can add a little more context to where the event originated.&lt;/p&gt; &lt;p&gt;As I mentioned, the CloudEvents specification is only concerned with the common metadata listed above, and the location where this metadata is placed when sending the event.&lt;/p&gt; &lt;p&gt;Currently, there are two event formats: Binary, which is the preferred format, and structured. Binary is recommended because it is additive. That is, the binary format only adds some headers to the HTTP request. If there is a middleware that doesn’t understand CloudEvents, it won’t break anything, but if that system is updated to support CloudEvents, it starts working.&lt;/p&gt; &lt;p&gt;Structured formats are for those who don’t have any format currently defined and are looking for guidance on how things should be structured.&lt;/p&gt; &lt;p&gt;Here is a quick example of what those two event formats might look like in raw HTTP:&lt;/p&gt; &lt;pre&gt;// Binary Post /event HTTP/1.0 Host: example.com Content-Type: application/json ce-specversion: 1.0 ce-type: com.nodeshift.create ce-source: nodeshift.dev ce-id: 123456 { "action": "createThing", "item": "2187" } // Structured Post /event HTTP/1.0 Host: example.com Content-Type: application/cloudevents+json { "specversion": "1.0" "type": "com.nodeshift.create" "source": "nodeshift.dev" "id": "123456" "data": { "action": "createThing", "item": "2187" } } &lt;/pre&gt; &lt;h2&gt;JavaScript SDK for CloudEvents&lt;/h2&gt; &lt;p&gt;Of course, we don’t want to have to format these events manually. That is where the &lt;a target="_blank" rel="nofollow" href="https://www.npmjs.com/package/cloudevents"&gt;JavaScript SDK for CloudEvents&lt;/a&gt; comes in. There are three main goals that an SDK should accomplish:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Compose an event.&lt;/li&gt; &lt;li&gt;Encode an event for sending.&lt;/li&gt; &lt;li&gt;Decode an incoming event.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Installing the JavaScript SDK is like using any other Node module:&lt;/p&gt; &lt;pre&gt;$ npm install cloudevents &lt;/pre&gt; &lt;p&gt;Now that we’ve seen what a CloudEvent is and how it is useful let&amp;#8217;s take a look at an example.&lt;/p&gt; &lt;h2&gt;Create a new CloudEvent&lt;/h2&gt; &lt;p&gt;First, we are going to create a new CloudEvent object:&lt;/p&gt; &lt;pre&gt;const { CloudEvent } = require('cloudevents'); // Create a new CloudEvent const ce = new CloudEvent({ type: 'com.cloudevent.fun', source: 'fun-with-cloud-events', data: { key: 'DATA' } }); &lt;/pre&gt; &lt;p&gt;If we log this out with the object&amp;#8217;s built-in &lt;code&gt;toJSON&lt;/code&gt; method, we might see something like this:&lt;/p&gt; &lt;pre&gt;console.log(ce.toJSON()); { id: '...', type: 'com.cloudevent.fun', source: 'fun-with-cloud-events', specversion: '1.0', time: '...', data: { key: 'DATA' } } &lt;/pre&gt; &lt;h3&gt;Sending the message&lt;/h3&gt; &lt;p&gt;Next, let&amp;#8217;s look at how to send this over HTTP using the binary format.&lt;/p&gt; &lt;p&gt;First, we need to create our message in the binary format, which you can do easily with the &lt;code&gt;HTTP.binary&lt;/code&gt; method. We will use the CloudEvent from the previous example:&lt;/p&gt; &lt;pre&gt; const message = HTTP.binary(ce); //const message = HTTP.structured(ce); // Showing just for completeness &lt;/pre&gt; &lt;p&gt;Again, if we log this out, it might look something like this:&lt;/p&gt; &lt;pre&gt; headers: { 'content-type': 'application/json;', 'ce-id': '...', 'ce-type': 'com.cloudevent.fun', 'ce-source': 'fun-with-cloud-events', 'ce-specversion': '1.0', 'ce-time': '...' }, body: { key: 'DATA' } } &lt;/pre&gt; &lt;p&gt;Now that the message has been formatted properly, we can send it by using a library like &lt;a target="_blank" rel="nofollow" href="https://github.com/axios/axios"&gt;Axios&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Note that the CloudEvents SDK doesn’t handle sending messages; it only handles formatting the message headers and message body. This allows you to use any HTTP library you want to send the message.&lt;/p&gt; &lt;pre&gt;const axios = require('axios') axios({ method: 'post', url: 'http://localhost:3000/cloudeventy', data: message.body, headers: message.headers }).then((response) =&amp;#62; { console.log(response.data); }); &lt;/pre&gt; &lt;p&gt;We are sending a POST request to the “cloudevent-y” REST endpoint. In this example, I have used a simple Express.js application, but you can use any framework you like.&lt;/p&gt; &lt;h3&gt;Receiving the message&lt;/h3&gt; &lt;p&gt;Once we have the message, we can use the &lt;code&gt;HTTP.toEvent&lt;/code&gt; method to convert it back into a CloudEvent object.&lt;/p&gt; &lt;pre&gt;const express = require('express'); const { HTTP } = require('cloudevents'); const app = express(); app.post('/cloudeventy', (req, res) =&amp;#62; { const ce = HTTP.toEvent({ headers: req.headers, body: req.body }); console.log(ce.toJSON()); res.send({key: 'Event Received'}); }); &lt;/pre&gt; &lt;p&gt;Again, the log output looks similar to what we saw when we output the CloudEvent object:&lt;/p&gt; &lt;pre&gt;{ id: '...', type: 'com.cloudevent.fun', source: 'fun-with-cloud-events', specversion: '1.0', time: '...', data: { key: 'DATA' } } &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;To learn more about the JavaScript SDK for CloudEvents, &lt;a target="_blank" rel="nofollow" href="https://github.com/cloudevents/sdk-javascript"&gt;check out the GitHub project&lt;/a&gt;. For more information about the history, development, and design rationale behind the specification, see the &lt;a href="https://github.com/cloudevents/spec/blob/master/primer.md" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;CloudEvents Primer&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#038;title=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" data-a2a-url="https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/" data-a2a-title="An introduction to JavaScript SDK for CloudEvents"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/"&gt;An introduction to JavaScript SDK for CloudEvents&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/QyzqZRtXZYY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In today&amp;#8217;s world of serverless functions and microservices, events are everywhere. The problem is that they are described differently depending on the producer technology you use. Without a common standard, the burden is on developers to constantly relearn how to consume events. Not having a standard also makes it more difficult for authors of libraries [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/"&gt;An introduction to JavaScript SDK for CloudEvents&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">810797</post-id><dc:creator>Lucas Holmquist</dc:creator><dc:date>2021-03-09T08:00:50Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/</feedburner:origLink></entry><entry><title>Deploying Node.js applications to Kubernetes with Nodeshift and Minikube</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/fAqJZg6t3vY/" /><category term="Developer Tools" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="minikube" /><category term="nodeshift" /><category term="openshift" /><category term="S2I" /><author><name>Lucas Holmquist</name></author><id>https://developers.redhat.com/blog/?p=865157</id><updated>2021-03-09T08:00:39Z</updated><published>2021-03-09T08:00:39Z</published><content type="html">&lt;p&gt;In a &lt;a target="_blank" rel="nofollow" href="/blog/2019/08/30/easily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift/"&gt;previous article&lt;/a&gt;, I showed how easy it was to deploy a &lt;a target="_blank" rel="nofollow" href="/topics/nodejs"&gt;Node.js&lt;/a&gt; application during development to &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; using the Nodeshift command-line interface (CLI). In this article, we will take a look at using Nodeshift to deploy Node.js applications to vanilla &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;—specifically, with Minikube.&lt;/p&gt; &lt;h2&gt;Getting started&lt;/h2&gt; &lt;p&gt;If you want to follow along with this tutorial, you will need to run Minikube. I won&amp;#8217;t cover the setup process, but &lt;a target="_blank" rel="nofollow" href="https://minikube.sigs.k8s.io/docs/start/"&gt;Minikube&amp;#8217;s documentation&lt;/a&gt; can guide you through it. For the tutorial, I also assume that you have installed &lt;a target="_blank" rel="nofollow" href="https://nodejs.org/en/download"&gt;Node.js and Node Package Manager (npm)&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The code samples we&amp;#8217;ll use are available on &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift-starters/basic-node-app-dockerized"&gt;GitHub&lt;/a&gt;. Our example is a very basic Node.js application with a Dockerfile. In fact, it is taken from the &lt;a target="_blank" rel="nofollow" href="https://nodejs.org/en/docs/guides/nodejs-docker-webapp/"&gt;&lt;i&gt;Dockerizing a Node.js web app&lt;/i&gt;&lt;/a&gt; guide on Nodejs.org.&lt;/p&gt; &lt;h2&gt;The Nodeshift CLI&lt;/h2&gt; &lt;p&gt;As the Nodeshift module readme states, Nodeshift is an opinionated command-line application and programmable API that you can use to deploy Node.js applications to &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. You can easily run it using the &lt;code&gt;npx&lt;/code&gt; command, and it will create the appropriate YAML files to deploy your application.&lt;/p&gt; &lt;p&gt;Nodeshift is a great tool to use if you are developing against an OpenShift cluster, which uses the Source-to-Image (S2I) workflow. In short, Nodeshift creates an OpenShift &lt;code&gt;BuildConfig&lt;/code&gt;, which calls a Node.js S2I image to build your Node application. In most cases, you can achieve this by running &lt;code&gt;npm install&lt;/code&gt;. The build result is put into an OpenShift &lt;code&gt;ImageStream&lt;/code&gt; that resides in the internal OpenShift container registry. This image is then used to deploy your application.&lt;/p&gt; &lt;p&gt;But what about deploying to a vanilla Kubernetes cluster that doesn’t know anything about BuildConfigs, ImageStreams, or S2I? Well, as of &lt;a href="https://github.com/nodeshift/nodeshift/releases/tag/v7.3.0"&gt;Nodeshift&amp;#8217;s 7.3 release&lt;/a&gt;, you can now deploy your Node.js applications to Minikube.&lt;/p&gt; &lt;h2&gt;Deploying Node.js to Minikube&lt;/h2&gt; &lt;p&gt;Before we look at how Nodeshift works for deploying a Node.js application to Minikube, let’s take a minute for a high-level overview of deploying to Kubernetes.&lt;/p&gt; &lt;p&gt;First, you will create an application container image, which you can do with Docker. Once you have a container image, you&amp;#8217;ll need to push that image to a container registry that your cluster has access to, something like &lt;a target="_blank" rel="nofollow" href="https://hub.docker.com/"&gt;Docker Hub&lt;/a&gt;. Once the image is available, you must then specify that image in your deployment YAML and create a service to expose the application.&lt;/p&gt; &lt;p&gt;This flow starts to be more cumbersome when you start iterating on your code. It isn’t really development-friendly if you need to run a Docker build and push that new image to Docker Hub every time. Not to mention that you also need to update your deployment with the new version of the image to ensure it redeploys.&lt;/p&gt; &lt;p&gt;Nodeshift&amp;#8217;s goal is to make developers&amp;#8217; lives easier when deploying to OpenShift and Kubernetes. Let&amp;#8217;s see how Nodeshift helps with each of those unwieldy steps.&lt;/p&gt; &lt;h2&gt;Minikube&amp;#8217;s internal Docker server&lt;/h2&gt; &lt;p&gt;A major difference between OpenShift and Kubernetes is that there is no easy way to run S2I builds on plain Kubernetes. We also don’t want to run a Docker build and push to Docker Hub every time we change our code. Fortunately, Minikube gives us an alternative.&lt;/p&gt; &lt;p&gt;Minikube has its own internal Docker server that we can connect to using the &lt;a target="_blank" rel="nofollow" href="https://docs.docker.com/engine/api/v1.41/#"&gt;Docker Engine API&lt;/a&gt;. We can use this server to run our Docker build in the environment, which means that we don’t have to push the image to an external resource like Docker Hub. We can then use this image in our deployment.&lt;/p&gt; &lt;p&gt;To get access to the internal Docker server, Minikube has a command to export some environment variables to add to your terminal shell. This command is &lt;code&gt;minikube docker-env&lt;/code&gt;, which might output something like this:&lt;/p&gt; &lt;pre&gt;export DOCKER_TLS_VERIFY="1" export DOCKER_HOST="tcp://192.168.39.12:2376" export DOCKER_CERT_PATH="/home/lucasholmquist/.minikube/certs" export MINIKUBE_ACTIVE_DOCKERD="minikube" # To point your shell to minikube's docker-daemon, run: # eval $(minikube -p minikube docker-env) &lt;/pre&gt; &lt;h2&gt;Making it easier with Nodeshift&lt;/h2&gt; &lt;p&gt;Nodeshift abstracts the details we don’t really care about so we can focus on our applications. In this case, we don’t want to think about how to connect to Minikube&amp;#8217;s internal server or how to run Docker commands by hand, and we don’t want to think about updating our deployment YAML every time we build a new image to redeploy it.&lt;/p&gt; &lt;p&gt;Using the Nodeshift CLI with the &lt;code&gt;--kube&lt;/code&gt; flag simplifies those tasks. Let’s see how it works using our &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift-starters/basic-node-app-dockerized"&gt;example application&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;We will use &lt;code&gt;npx&lt;/code&gt; to deploy the Node.js application to Minikube, so we don’t need to install anything globally. Run it like this in the example directory:&lt;/p&gt; &lt;pre&gt;$ npx nodeshift --kube &lt;/pre&gt; &lt;p&gt;Nodeshift creates a service and deployment by default if none are provided. Also, note that the type of service it creates is a &lt;code&gt;LoadBalancer&lt;/code&gt;, which allows us to expose our application without using ingress.&lt;/p&gt; &lt;p&gt;The Nodeshift CLI runs the same &lt;code&gt;goals&lt;/code&gt; for a Kubernetes deploy as it does for an OpenShift deploy. The key difference comes during the &lt;code&gt;build&lt;/code&gt; phase. Instead of creating an OpenShift &lt;code&gt;BuildConfig&lt;/code&gt; and running an S2I process on the cluster, Nodeshift uses the &lt;a target="_blank" rel="nofollow" href="https://www.npmjs.com/package/dockerode"&gt;dockerode&lt;/a&gt; module to connect to Minikube&amp;#8217;s internal Docker server and run a build using the provided Dockerfile. The built image is now in that internal registry, ready to be deployed by the deployment YAML that the Nodeshift CLI creates. Nodeshift also adds a randomly-generated number to the deployment&amp;#8217;s metadata, which is then applied during every redeploy. This will trigger Minikube to redeploy the application with the new image.&lt;/p&gt; &lt;p&gt;The following is an example log output:&lt;/p&gt; &lt;pre&gt;~/develop/nodeshift-starters/basic-node-app-dockerized» npx nodeshift --kube 2021-02-09T20:03:18.405Z INFO loading configuration 2021-02-09T20:03:18.452Z INFO Using the kubernetes flag. 2021-02-09T20:03:18.762Z INFO using namespace default at https://192.168.39.12:8443 2021-02-09T20:03:18.763Z WARNING a file property was not found in your package.json, archiving the current directory. 2021-02-09T20:03:18.773Z INFO creating archive of .dockerignore, .gitignore, Dockerfile, README.md, package-lock.json, package.json, server.js 2021-02-09T20:03:18.774Z INFO Building Docker Image 2021-02-09T20:03:18.848Z TRACE {"stream":"Step 1/7 : FROM node:14"} 2021-02-09T20:03:18.848Z TRACE {"stream":"\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":" ---\u003e cb544c4472e9\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":"Step 2/7 : WORKDIR /usr/src/app"} 2021-02-09T20:03:18.849Z TRACE {"stream":"\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":" ---\u003e Using cache\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":" ---\u003e 57c9e3a4e918\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":"Step 3/7 : COPY package*.json ./"} 2021-02-09T20:03:18.850Z TRACE {"stream":"\n"} 2021-02-09T20:03:19.050Z TRACE {"stream":" ---\u003e 742050ca3266\n"} 2021-02-09T20:03:19.050Z TRACE {"stream":"Step 4/7 : RUN npm install"} 2021-02-09T20:03:19.050Z TRACE {"stream":"\n"} 2021-02-09T20:03:19.109Z TRACE {"stream":" ---\u003e Running in f3477d5f2b00\n"} 2021-02-09T20:03:21.739Z TRACE {"stream":"\u001b[91mnpm WARN basic-node-app-dockerized@1.0.0 No description\n\u001b[0m"} 2021-02-09T20:03:21.744Z TRACE {"stream":"\u001b[91mnpm WARN basic-node-app-dockerized@1.0.0 No repository field.\n\u001b[0m"} 2021-02-09T20:03:21.745Z TRACE {"stream":"\u001b[91m\n\u001b[0m"} 2021-02-09T20:03:21.746Z TRACE {"stream":"added 50 packages from 37 contributors and audited 50 packages in 1.387s\n"} 2021-02-09T20:03:21.780Z TRACE {"stream":"found 0 vulnerabilities\n\n"} 2021-02-09T20:03:22.303Z TRACE {"stream":"Removing intermediate container f3477d5f2b00\n"} 2021-02-09T20:03:22.303Z TRACE {"stream":" ---\u003e afb97a82c035\n"} 2021-02-09T20:03:22.303Z TRACE {"stream":"Step 5/7 : COPY . ."} 2021-02-09T20:03:22.303Z TRACE {"stream":"\n"} 2021-02-09T20:03:22.481Z TRACE {"stream":" ---\u003e 1a451003c472\n"} 2021-02-09T20:03:22.481Z TRACE {"stream":"Step 6/7 : EXPOSE 8080"} 2021-02-09T20:03:22.482Z TRACE {"stream":"\n"} 2021-02-09T20:03:22.545Z TRACE {"stream":" ---\u003e Running in a76389d44b59\n"} 2021-02-09T20:03:22.697Z TRACE {"stream":"Removing intermediate container a76389d44b59\n"} 2021-02-09T20:03:22.697Z TRACE {"stream":" ---\u003e 8ee240b7f9ab\n"} 2021-02-09T20:03:22.697Z TRACE {"stream":"Step 7/7 : CMD [ \"node\", \"server.js\" ]"} 2021-02-09T20:03:22.698Z TRACE {"stream":"\n"} 2021-02-09T20:03:22.759Z TRACE {"stream":" ---\u003e Running in 1f7325ab3c64\n"} 2021-02-09T20:03:22.911Z TRACE {"stream":"Removing intermediate container 1f7325ab3c64\n"} 2021-02-09T20:03:22.912Z TRACE {"stream":" ---\u003e d7f5d1e95592\n"} 2021-02-09T20:03:22.912Z TRACE {"aux":{"ID":"sha256:d7f5d1e9559242f767b54b168c36df5c7cbce6ebc7eb1145d7f6292f20e8cda2"}} 2021-02-09T20:03:22.913Z TRACE {"stream":"Successfully built d7f5d1e95592\n"} 2021-02-09T20:03:22.929Z TRACE {"stream":"Successfully tagged basic-node-app-dockerized:latest\n"} 2021-02-09T20:03:22.933Z WARNING No .nodeshift directory 2021-02-09T20:03:22.954Z INFO openshift.yaml and openshift.json written to /home/lucasholmquist/develop/nodeshift-starters/basic-node-app-dockerized/tmp/nodeshift/resource/ 2021-02-09T20:03:22.975Z INFO creating new service basic-node-app-dockerized 2021-02-09T20:03:22.979Z TRACE Deployment Applied 2021-02-09T20:03:23.036Z INFO Application running at: http://192.168.39.12:30076 2021-02-09T20:03:23.036Z INFO complete &lt;/pre&gt; &lt;p&gt;Following the deployment, the Nodeshift CLI also provides the URL where the application is running in the console output. The output might look something like this:&lt;/p&gt; &lt;pre&gt;... INFO Application running at http://192.168.39.12:30769 ... &lt;/pre&gt; &lt;p&gt;Navigating to the URL provided returns &amp;#8220;Hello World.&amp;#8221;&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article gave a brief overview of the Nodeshift CLI&amp;#8217;s support for deploying to Minikube. In the future, we plan to add more Kubernetes platforms and other developer-friendly features, like possibly having the Nodeshift CLI create a default Dockerfile if there isn’t one.&lt;/p&gt; &lt;p&gt;If you like what you see and want to learn more, check out the &lt;a target="_blank" rel="nofollow" href="https://nodeshift.dev/"&gt;Nodeshift project&lt;/a&gt;. As always, if there are more features you would like to see, &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift/nodeshift"&gt;create an issue&lt;/a&gt; over on GitHub. To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js landing page.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#038;title=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" data-a2a-url="https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/" data-a2a-title="Deploying Node.js applications to Kubernetes with Nodeshift and Minikube"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/"&gt;Deploying Node.js applications to Kubernetes with Nodeshift and Minikube&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/fAqJZg6t3vY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In a previous article, I showed how easy it was to deploy a Node.js application during development to Red Hat OpenShift using the Nodeshift command-line interface (CLI). In this article, we will take a look at using Nodeshift to deploy Node.js applications to vanilla Kubernetes—specifically, with Minikube. Getting started If you want to follow along [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/"&gt;Deploying Node.js applications to Kubernetes with Nodeshift and Minikube&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">865157</post-id><dc:creator>Lucas Holmquist</dc:creator><dc:date>2021-03-09T08:00:39Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/</feedburner:origLink></entry><entry><title>A guide to Red Hat OpenShift 4.5 installer-provisioned infrastructure on vSphere</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/V3nPGQGz_F8/" /><category term="Kubernetes" /><category term="Linux" /><category term="Operator" /><category term="container host provisioning" /><category term="installer" /><category term="openshift" /><category term="RHEL" /><category term="vSphere" /><author><name>Nuttee Jirattivongvibul</name></author><id>https://developers.redhat.com/blog/?p=785627</id><updated>2021-03-09T08:00:38Z</updated><published>2021-03-09T08:00:38Z</published><content type="html">&lt;p&gt;With &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift 4&lt;/a&gt;, Red Hat completely re-architected how developers install, upgrade, and manage OpenShift to develop applications on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. Under the hood, the installation process uses the &lt;a target="_blank" rel="nofollow" href="https://github.com/openshift/installer"&gt;OpenShift installer&lt;/a&gt; to automate container host provisioning using &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) CoreOS. It is then easy to initialize the cluster and set up the cloud domain name system (DNS), load balancer, storage, and so on.&lt;/p&gt; &lt;p&gt;Initially, the fully automated OpenShift installation option (called &lt;em&gt;installer-provisioned infrastructure&lt;/em&gt;) was available only for public and private clouds. In &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/welcome/index.html"&gt;OpenShift 4.5&lt;/a&gt;, the installer was updated to support installer-provisioned infrastructure on &lt;a target="_blank" rel="nofollow" href="https://www.vmware.com/products/vsphere.html"&gt;VMware vSphere&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article is for enterprise IT users and developers who run their workloads on vSphere. I will show you how to bring up your OpenShift clusters in 30 minutes without the pain of needing to do manual tasks each time.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s walk through the prerequisites for using OpenShift&amp;#8217;s installer-provisioned infrastructure with vSphere. Make sure your development environment is set up as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;To download and run the OpenShift installer binary, you will need a &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; virtual machine (VM) or a Linux guest on your laptop. This host must be able to access your vCenter and VM subnet.&lt;/li&gt; &lt;li&gt;You will also need a VMware cluster with the following configuration: &lt;ul&gt; &lt;li&gt;One vCenter instance.&lt;/li&gt; &lt;li&gt;An ESXi cluster with the minimum for provisioning a standard OpenShift cluster.&lt;/li&gt; &lt;li&gt;vSphere 6.5 with hardware version 13 or 6.7 update 2.&lt;/li&gt; &lt;li&gt;800GB storage from the datastore.&lt;/li&gt; &lt;li&gt;18 or more virtual central processing units (vCPUs). The minimum setup is three leaders with four vCPUs per node and three followers with two vCPUs per node. The recommended configuration is four vCPUs on followers, even for lab purposes. You will also need a temporary vCPU for the bootstrap machine.&lt;/li&gt; &lt;li&gt;88GB memory. You will need three leaders with 16GB RAM per node, three followers with 8GB RAM per node, and 16GB temporary RAM for the bootstrap machine.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Network configurations&lt;/h3&gt; &lt;p&gt;You will need a network and subnet with Dynamic Host Configuration Protocol (DHCP) enabled with the long-lease time for this pool. As an example, my lab network is VM Network with the IP address of 198.18.1.0/24. The DHCP pool is at 198.18.1.11-200.&lt;/p&gt; &lt;p&gt;For the DNS server IP requirements, you will need a DNS server with two A records. Note that the two DNS A records point to the API and ingress virtual IP addresses. These will point to the OpenShift installer-provisioned cluster load balancer (&lt;a target="_blank" rel="nofollow" href="https://www.haproxy.com/"&gt;HAProxy&lt;/a&gt; with Keepalived run as containers in OpenShift nodes).&lt;/p&gt; &lt;p&gt;Here is how OpenShift vSphere&amp;#8217;s installer-provisioned infrastructure simplifies the load balancer service for the cluster:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;api.&amp;#60;cluster-name&amp;#62;.&amp;#60;base-domain&amp;#62;&lt;/code&gt; with one reserved IP address for the API virtual IP on the same cluster network. As an example, the IP address for &lt;code&gt;api.ocp01.example.com&lt;/code&gt; could be 198.18.1.201.&lt;/li&gt; &lt;li&gt;&lt;code&gt;*.apps.&amp;#60;cluster-name&amp;#62;.&amp;#60;base-domain&amp;#62;&lt;/code&gt; with one reserved IP address for the ingress virtual IP on the same cluster network. As an example, the IP address for &lt;code&gt;api.ocp01.example.com&lt;/code&gt; could be 198.18.1.202.&lt;/li&gt; &lt;li&gt;The DNS test result should look like this: &lt;pre&gt;[root@centos7-tools1 ~]# nslookup api.apps.ocp01.example.com Server: 198.18.133.1 Address: 198.18.133.1#53 Name: api.ocp01.example.com Address: 198.18.1.201 [root@centos7-tools1 ~]# nslookup api.apps.ocp01.example.com Server: 198.18.133.1 Address: 198.18.133.1#53 Name: api.ocp01.example.com Address: 198.18.1.201&lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Account privileges&lt;/h3&gt; &lt;p&gt;You will also need to configure the vCenter account privileges specified in the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/installing/installing_vsphere/installing-vsphere-installer-provisioned.html#installation-vsphere-installer-infra-requirements_installing-vsphere-installer-provisioned"&gt;OpenShift guide to installing a cluster on vSphere&lt;/a&gt;. Please set your account privileges before continuing with this guide.&lt;/p&gt; &lt;p&gt;Finally, you&amp;#8217;ll need a Red Hat account to access &lt;a target="_blank" rel="nofollow" href="https://cloud.redhat.com"&gt;cloud.redhat.com&lt;/a&gt; and retrieve your pull secret for the OpenShift self-supported 60-day trial.&lt;/p&gt; &lt;p&gt;When you are done, the infrastructure preparation should look similar to the diagram in Figure 1.&lt;/p&gt; &lt;div id="attachment_875697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1.png"&gt;&lt;img aria-describedby="caption-attachment-875697" class="wp-image-875697" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1.png" alt="Components in the external network and OpenShift cluster network." width="640" height="458" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1.png 937w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1-300x215.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1-768x550.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-875697" class="wp-caption-text"&gt;Figure 1: Set up your development environment for installer-provisioned infrastructure on vSphere.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once your development environment is set up, we can continue to the next step.&lt;/p&gt; &lt;h2&gt;Set up the installer VM&lt;/h2&gt; &lt;p&gt;You need to perform a few one-time tasks before starting the OpenShift installer. Once you&amp;#8217;ve done these tasks, you will be able to re-use them to deploy as many clusters as you like.&lt;/p&gt; &lt;h3&gt;Generate the SSH private key&lt;/h3&gt; &lt;p&gt;Generate your secure shell (SSH) private and public key if you don&amp;#8217;t have one in your &lt;code&gt;~/.ssh/&lt;/code&gt; directory. You will need the key for OpenShift node access when it is time to perform debugging tasks:&lt;/p&gt; &lt;pre&gt;ssh-keygen -t rsa -b 4096 -N '' -f ~/.ssh/id_rsa&lt;/pre&gt; &lt;h3&gt;Obtain the installation and client binaries&lt;/h3&gt; &lt;p&gt;You can create your free account and go to the &lt;a target="_blank" rel="nofollow" href="https://cloud.redhat.com/openshift/install"&gt;Red Hat Cloud Services Portal—OpenShift Cluster Manager&lt;/a&gt; to obtain the installer and client binaries for your operating system. Do the following from the portal&amp;#8217;s web user interface:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Log in to the &lt;a target="_blank" rel="nofollow" href="https://cloud.redhat.com/openshift/install"&gt;OpenShift Cluster Manager&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Create an OpenShift cluster&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Choose &lt;strong&gt;Red Hat OpenShift Container Platform&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;On &lt;strong&gt;Select an infrastructure provider&lt;/strong&gt;, select &lt;strong&gt;Run on VMware vSphere&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;In the OpenShift installer, select your operating system binary, for example, Linux. Then, click &lt;strong&gt;Download installer&lt;/strong&gt;. If you want the latest release, use this download URL: &lt;a target="_blank" rel="nofollow" href="https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-install-linux.tar.gz"&gt;https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-install-linux.tar.gz&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Download pull secret&lt;/strong&gt; or copy the pull secret and save it to a file.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Download command-line tools&lt;/strong&gt; and select your operating system. Or, you can use this URL for the latest Linux binary: &lt;a target="_blank" rel="nofollow" href="https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux.tar.gz"&gt;https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux.tar.gz&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Extract the installation and client programs. For example, run this command: &lt;pre&gt;tar xvf openshift-install-linux.tar.gz tar xvf openshift-client-linux.tar.gz cp oc /usr/local/bin/ &lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Add the vCenter root CA certificates to your system trust&lt;/h3&gt; &lt;p&gt;The OpenShift installer requires access to vCenter&amp;#8217;s API, so the vCenter certificate must be trusted. Download the vCenter&amp;#8217;s root certificate authority (CA) certificates and extract and copy them to your system trust:&lt;/p&gt; &lt;pre&gt;export VCENTER=&lt;b&gt;&amp;#60;your vcenter hostname or IP Address&amp;#62;&lt;/b&gt; wget https://${VCENTER}/certs/download.zip --no-check-certificate unzip download.zip cp certs/lin/* /etc/pki/ca-trust/source/anchors update-ca-trust extract &lt;/pre&gt; &lt;p&gt;Your installer machine is now set up, and you can run the installer as many times as you want.&lt;/p&gt; &lt;h2&gt;Demonstration: Deploying a simple cluster&lt;/h2&gt; &lt;p&gt;For this demonstration, we will deploy a quick, standard cluster that doesn&amp;#8217;t require any customization.&lt;/p&gt; &lt;h3&gt;Run the installer&lt;/h3&gt; &lt;p&gt;The OpenShift installer is a command-line interface that requests your input for the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;SSH public key: For example, &lt;code&gt;/root/.ssh/id_rsa.pub&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Platform: vSphere.&lt;/li&gt; &lt;li&gt;vCenter: Your vCenter hostname, for example, &lt;code&gt;vc1.example.com&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Username: Your vCenter username, for example, &lt;code&gt;administrator@vsphere.local&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Password: Your vCenter password.&lt;/li&gt; &lt;li&gt;Network: Select your cluster network with the DHCP you previously set up.&lt;br /&gt; The OpenShift installer will connect to your vCenter and list your network for you to select.&lt;/li&gt; &lt;li&gt;A virtual IP address for the API: This is the IP address that you allocated and mapped to the &lt;code&gt;api.&amp;#60;cluster-name&amp;#62;.&amp;#60;base-domain&amp;#62;&lt;/code&gt; DNS record (for example, 198.18.1.201).&lt;/li&gt; &lt;li&gt;A virtual IP address for ingress: This is the IP address that you allocated and mapped to the &lt;code&gt;*.apps.&amp;#60;cluster-name&amp;#62;.&amp;#60;base-domain&amp;#62;&lt;/code&gt; DNS record (for example, 198.18.1.202).&lt;/li&gt; &lt;li&gt;Base domain: This will be the same as your &lt;code&gt;&amp;#60;base-domain&amp;#62;&lt;/code&gt;, such as &lt;code&gt;example.com&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Cluster name: This will be the same as your &lt;code&gt;&amp;#60;cluster-name&amp;#62;&lt;/code&gt;, such as &lt;code&gt;ocp01&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Pull secret: The pull secret that you downloaded or copied from the OpenShift cluster management page.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Here is an example of output from the OpenShift installer&amp;#8217;s installation process:&lt;/p&gt; &lt;pre&gt;export INSTALLATION_DIR=$HOME/ocp01-01 mkdir $INSTALLATION_DIR ./openshift-install create cluster --dir=$INSTALLATION_DIR --log-level=info ? SSH Public Key /root/.ssh/id_rsa.pub ? Platform vsphere ? vCenter vc1.example.com ? Username administrator@vsphere.local ? Password [? for help] ************* INFO Connecting to vCenter vc1.example.com INFO Defaulting to only available datacenter: DC1 INFO Defaulting to only available cluster: DC1-Cluster INFO Defaulting to only available datastore: NFS_Datastore ? Network: VM Network ? Virtual IP Address for API: 198.18.1.201 ? Virtual IP Address for Ingress: 198.18.1.202 ? Base Domain: example.com ? Cluster Name: ocp01 ? Pull Secret [? for help] *************** &lt;/pre&gt; &lt;h3&gt;Provision a bootstrap machine and leader nodes&lt;/h3&gt; &lt;p&gt;The OpenShift installer will now provision a bootstrap machine and three leader nodes. Your API virtual IP and ingress virtual IP will first host on the bootstrap machine for the leader nodes to self-initialize with the ignition and bootstrapping process. The deployment in the bootstrapping stage will look like the diagram in Figure 2.&lt;/p&gt; &lt;div id="attachment_875717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2.png"&gt;&lt;img aria-describedby="caption-attachment-875717" class="wp-image-875717" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2.png" alt="A diagram of the bootstrapping deployment." width="640" height="458" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2.png 937w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2-300x215.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2-768x550.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-875717" class="wp-caption-text"&gt;Figure 2: Deployment in the bootstrapping stage.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When the bootstrapping is complete and all the leader node&amp;#8217;s API servers are up, the OpenShift bootstrap node will be destroyed automatically with the installer. Then, the installer will start provisioning the follower nodes with an &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/machine_management/creating-infrastructure-machinesets.html"&gt;OpenShift MachineSet&lt;/a&gt;. For this, you could do a machine auto-scaler or manually increase or decrease the nodes later, using either the OpenShift web console or command-line tools (&lt;code&gt;oc&lt;/code&gt; or &lt;code&gt;kubectl&lt;/code&gt;). The API virtual IP and ingress virtual IP will also be moved to &lt;em&gt;hosted&lt;/em&gt; status on the leader nodes and infrastructure and follower nodes.&lt;/p&gt; &lt;p&gt;Your deployment in the provisioning stage will look like the diagram in Figure 3.&lt;/p&gt; &lt;div id="attachment_875727" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3.png"&gt;&lt;img aria-describedby="caption-attachment-875727" class="wp-image-875727" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3.png" alt="A diagram of the deployment in the provisioning stage." width="640" height="458" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3.png 937w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3-300x215.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3-768x550.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-875727" class="wp-caption-text"&gt;Figure 3: Deployment in the provisioning stage.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Provisioning the OpenShift cluster normally takes 40 to 60 minutes to complete.&lt;/p&gt; &lt;h2&gt;Post-installation configuration&lt;/h2&gt; &lt;p&gt;You can log into your cluster as a default system user by exporting a &lt;code&gt;kubeconfig&lt;/code&gt; file to &lt;code&gt;KUBECONFIG ENV&lt;/code&gt; vars. This file is created during the installation for a specific cluster and stored in &lt;code&gt;$INSTALLATION_DIR/auth/kubeconfig&lt;/code&gt;. Let&amp;#8217;s go through the post-installation configuration process together.&lt;/p&gt; &lt;p&gt;First, export the &lt;code&gt;kubeadmin&lt;/code&gt; credentials:&lt;/p&gt; &lt;pre&gt;export KUBECONFIG=$INSTALLATION_DIR/auth/kubeconfig&lt;/pre&gt; &lt;p&gt;Next, verify that you can run the &lt;code&gt;oc&lt;/code&gt; command successfully using the exported configuration:&lt;/p&gt; &lt;pre&gt;oc whoami oc get node &lt;/pre&gt; &lt;p&gt;Infrastructure administrators and developers can use the OpenShift console to work with Kubernetes clusters. To access the console for the first time, the installer generates a &lt;code&gt;kubeadmin&lt;/code&gt; credential in the &lt;code&gt;$INSTALLATION_DIR/auth/password&lt;/code&gt; file. Use the &lt;code&gt;oc&lt;/code&gt; command to get the URL for your OpenShift console:&lt;/p&gt; &lt;pre&gt;oc -n openshift-console get route &lt;/pre&gt; &lt;p&gt;Copy the URL and open it in your web browser, and use the initial credentials to log in. For the username, enter &lt;code&gt;kubeadmin&lt;/code&gt;; for the password, use the password from &lt;code&gt;$INSTALLATION_DIR/auth/kubeadmin_password&lt;/code&gt;, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_792547" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login.png"&gt;&lt;img aria-describedby="caption-attachment-792547" class="wp-image-792547 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login-1024x541.png" alt="The login screen." width="640" height="338" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login-1024x541.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login-300x158.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login-768x405.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792547" class="wp-caption-text"&gt;Figure 4: The OpenShift console OAuth login screen.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 5 shows the overview page in the OpenShift console.&lt;/p&gt; &lt;div id="attachment_792557" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview.png"&gt;&lt;img aria-describedby="caption-attachment-792557" class="wp-image-792557 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview-1024x527.png" alt="The overview page shows the cluster details, status, and current utilization." width="640" height="329" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview-1024x527.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview-300x154.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview-768x395.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792557" class="wp-caption-text"&gt;Figure 5: The OpenShift console overview page.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Container registry storage&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/courses/openshift/getting-started"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; uses an internal registry to upgrade clusters and support continuous integration and continuous deployment (&lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;CI/CD&lt;/a&gt;) with containers built within clusters. You will need to set up storage for OpenShift&amp;#8217;s internal registry before you can deploy the demo application.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: For our example, we will use ReadWriteOnce (RWO) storage that supports only a single registry instance. For production, Red Hat recommends using the scalable registry that requires ReadWriteMany (RWX) storage.&lt;/p&gt; &lt;h3&gt;Configuring the OpenShift image registry&lt;/h3&gt; &lt;p&gt;You can configure the OpenShift image registry using either the web console or a command-line tool. I&amp;#8217;ll show you how to do this task both ways. If you are new to Kubernetes, you might find the OpenShift console helpful for seeing and understanding your cluster&amp;#8217;s status. On the other hand, using a CLI tool is powerful and gets the tasks done quickly with JSON or YAML declarations.&lt;/p&gt; &lt;h4&gt;Using the OpenShift web console&lt;/h4&gt; &lt;p&gt;The first thing you&amp;#8217;ll do is create a persistent volume claim (PVC) with 100GB capacity from the default storage class (&amp;#8220;thin&amp;#8221;) using the VMware datastore:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Change to the &lt;b&gt;openshift-image-registry&lt;/b&gt; project.&lt;/li&gt; &lt;li&gt;Go to &lt;b&gt;Storage &amp;#62; Persistent Volume Claims&lt;/b&gt; and click &lt;b&gt;Create Persistent Volume Claim&lt;/b&gt;, as shown in Figure 6. &lt;p&gt;&lt;div id="attachment_792637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1.png"&gt;&lt;img aria-describedby="caption-attachment-792637" class="wp-image-792637 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1-1024x546.png" alt="The initial page to create a persistent volume claim." width="640" height="341" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1-1024x546.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1-300x160.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1-768x409.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792637" class="wp-caption-text"&gt;Figure 6: Create a persistent volume claim.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Enter the following parameters: &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Storage Class&lt;/strong&gt;: &lt;code&gt;thin&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Persistent Volume Claim Name&lt;/strong&gt;: &lt;code&gt;image-registry-storage&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Access Mode&lt;/strong&gt;: &lt;code&gt;Single User (RWO)&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Size&lt;/strong&gt;: &lt;code&gt;100GiB&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Then, click &lt;b&gt;Create&lt;/b&gt;, as shown in Figure 7. &lt;p&gt;&lt;div id="attachment_792627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02.png"&gt;&lt;img aria-describedby="caption-attachment-792627" class="wp-image-792627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02-1024x637.png" alt="Configure the PVC, then click Create." width="640" height="398" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02-1024x637.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02-300x187.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02-768x478.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792627" class="wp-caption-text"&gt;Figure 7: Configure and create the persistent volume claim.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Next, you will edit the registry configuration to use the &lt;strong&gt;&amp;#60;PVC name&amp;#62;&lt;/strong&gt; you&amp;#8217;ve just created and also update the &lt;code&gt;managementState&lt;/code&gt; and &lt;code&gt;updateStrategy&lt;/code&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Go to &lt;b&gt;Administration &amp;#62; Custom Resource Definitions&lt;/b&gt;, shown in Figure 8. &lt;p&gt;&lt;div id="attachment_792617" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01.png"&gt;&lt;img aria-describedby="caption-attachment-792617" class="wp-image-792617 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1024x546.png" alt="Edit the registry configuration to use the new PVC." width="640" height="341" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1024x546.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-300x160.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-768x409.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792617" class="wp-caption-text"&gt;Figure 8: Go to &lt;strong&gt;Administration &amp;#62; Custom Resource Definitions&lt;/strong&gt; in the OpenShift web console.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Click on the &lt;b&gt;CRD Config&lt;/b&gt; of &lt;code&gt;imageregistry.operator.openshift.io&lt;/code&gt;, shown in Figure 9. &lt;p&gt;&lt;div id="attachment_792607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04.png"&gt;&lt;img aria-describedby="caption-attachment-792607" class="wp-image-792607 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04-1024x549.png" alt="Click the 'CRD config' link." width="640" height="343" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04-1024x549.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04-300x161.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04-768x412.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792607" class="wp-caption-text"&gt;Figure 9: Click &lt;strong&gt;CRD Config&lt;/strong&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Change to the &lt;b&gt;Instance&lt;/b&gt; tab and click on the config name &lt;b&gt;cluster&lt;/b&gt;, shown in Figure 10. &lt;p&gt;&lt;div id="attachment_792597" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06.png"&gt;&lt;img aria-describedby="caption-attachment-792597" class="wp-image-792597 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06-1024x543.png" alt="Click the config name 'cluster.'" width="640" height="339" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06-1024x543.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06-300x159.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06-768x407.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792597" class="wp-caption-text"&gt;Figure 10: Click the config name, &lt;strong&gt;cluster&lt;/strong&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Select the action &lt;b&gt;Edit Config&lt;/b&gt;, shown in Figure 11: &lt;p&gt;&lt;div id="attachment_792587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07.png"&gt;&lt;img aria-describedby="caption-attachment-792587" class="wp-image-792587 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07-1024x483.png" alt="Edit the configuration." width="640" height="302" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07-1024x483.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07-300x142.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07-768x363.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792587" class="wp-caption-text"&gt;Figure 11: Select &lt;strong&gt;Edit Config&lt;/strong&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Edit the following parameters and click &lt;b&gt;Save&lt;/b&gt;: &lt;pre&gt;managementState: Managed rolloutStrategy: Recreate storage: pvc: claim: image-registry-storage &lt;/pre&gt; &lt;p&gt;Figure 12 shows the resulting YAML file on the &lt;b&gt;Config Details&lt;/b&gt; page.&lt;/p&gt; &lt;p&gt;&lt;div id="attachment_792577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08.png"&gt;&lt;img aria-describedby="caption-attachment-792577" class="wp-image-792577 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08-1024x418.png" alt="A screenshot of the YAML file." width="640" height="261" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08-1024x418.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08-300x123.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08-768x314.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792577" class="wp-caption-text"&gt;Figure 12: The edited configuration file.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The Image Registry Operator will now create an image registry for your OpenShift cluster. You can check by selecting &lt;b&gt;Project = openshift-image-registry&lt;/b&gt; and going to &lt;b&gt;Workloads &amp;#62; Pods&lt;/b&gt;. You will see the &lt;code&gt;image-registry&lt;/code&gt; pod is in the process of being created, as shown in Figure 13.&lt;/p&gt; &lt;div id="attachment_792567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09.png"&gt;&lt;img aria-describedby="caption-attachment-792567" class="wp-image-792567 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09-1024x520.png" alt="The image-registry pod was started seconds ago." width="640" height="325" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09-1024x520.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09-768x390.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792567" class="wp-caption-text"&gt;Figure 13: The image-registry pod is being created.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;Using the OpenShift CLI&lt;/h4&gt; &lt;p&gt;Now, we&amp;#8217;ll perform the same tasks using the OpenShift CLI. Once again, we start by creating a persistent volume claim:&lt;/p&gt; &lt;pre&gt;cat &amp;#60;&amp;#60;EOF &amp;#62;&amp;#62; image-registry-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: image-registry-storage namespace: openshift-image-registry spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Gi storageClassName: 'thin' EOF oc apply -f image-registry-pvc.yaml &lt;/pre&gt; &lt;p&gt;Next, patch the &lt;code&gt;imageregistry.operator.openshift.io config&lt;/code&gt; &amp;#8220;cluster&amp;#8221;:&lt;/p&gt; &lt;pre&gt;$ oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed","rolloutStrategy":"Recreate","storage":{"pvc":{"claim":"image-registry-storage"}}}}'&lt;/pre&gt; &lt;p&gt;That&amp;#8217;s it! Your OpenShift cluster is ready to build and deploy to your container applications.&lt;/p&gt; &lt;h2&gt;Conclusion and next steps&lt;/h2&gt; &lt;p&gt;This article showed you how to use OpenShift&amp;#8217;s installer-provisioned infrastructure to quickly create and configure an enterprise-grade, production-ready Kubernetes cluster with Red Hat OpenShift Container Platform on VMware vSphere. Visit &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/"&gt;learn.openshift.com&lt;/a&gt; for free, guided hands-on labs to keep learning how to deploy your applications or learn basic OpenShift operations.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#038;title=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" data-a2a-url="https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/" data-a2a-title="A guide to Red Hat OpenShift 4.5 installer-provisioned infrastructure on vSphere"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/"&gt;A guide to Red Hat OpenShift 4.5 installer-provisioned infrastructure on vSphere&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/V3nPGQGz_F8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;With Red Hat OpenShift 4, Red Hat completely re-architected how developers install, upgrade, and manage OpenShift to develop applications on Kubernetes. Under the hood, the installation process uses the OpenShift installer to automate container host provisioning using Red Hat Enterprise Linux (RHEL) CoreOS. It is then easy to initialize the cluster and set up the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/"&gt;A guide to Red Hat OpenShift 4.5 installer-provisioned infrastructure on vSphere&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">785627</post-id><dc:creator>Nuttee Jirattivongvibul</dc:creator><dc:date>2021-03-09T08:00:38Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/</feedburner:origLink></entry><entry><title>Red Hat Summit Virtual Experience 2021: Register today</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qxEz7hH963I/" /><category term="Uncategorized" /><category term="Burr Sutter" /><category term="red hat summit" /><category term="Summit 2021" /><author><name>Red Hat Developer</name></author><id>https://developers.redhat.com/blog/?p=878357</id><updated>2021-03-08T08:00:55Z</updated><published>2021-03-08T08:00:55Z</published><content type="html">&lt;p&gt;Automation, application deployment, and how to speed up your journey to the cloud. These and other developer hot topics will take center stage at &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/summit"&gt;Red Hat Summit 2021&lt;/a&gt;. Join thousands of your peers by &lt;a target="_blank" rel="nofollow" href="https://reg.summit.redhat.com/flow/redhat/sum21/regGeneralAttendee/login?intcmp=7013a0000026UTXAA2"&gt;registering&lt;/a&gt; for our all-new, free, two-part virtual Summit experience. Keynote speaker Burr Sutter will be delving deep into developer technologies as we come together to learn, share stories of success and failure, and turn knowledge into action.&lt;/p&gt; &lt;p&gt;We’ve reimagined this year’s Red Hat Summit as a multi-part experience that includes two no-cost virtual components in April and June, followed by a series of small-scale in-person events later in the year.&lt;/p&gt; &lt;h2&gt;Virtual Experience | &lt;a target="_blank" rel="nofollow" href="https://www.addevent.com/event/gw5377211"&gt;April 27-28, 2021&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Join us online from wherever you are in the world.&lt;/p&gt; &lt;p&gt;What to expect:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Keynotes from Red Hat leaders&lt;/li&gt; &lt;li&gt;Exciting news and announcements&lt;/li&gt; &lt;li&gt;Global customer and partner spotlights&lt;/li&gt; &lt;li&gt;Live demos&lt;/li&gt; &lt;li&gt;Access to Red Hat experts&lt;/li&gt; &lt;li&gt;Games and entertainment&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Virtual Experience | &lt;a target="_blank" rel="nofollow" href="https://www.addevent.com/event/Kx5377253"&gt;June 15-16, 2021&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Build on what you learned in April in this second installment.&lt;/p&gt; &lt;p&gt;What to expect:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Seven channels of breakout sessions featuring in-depth technical content&lt;/li&gt; &lt;li&gt;Even more access to Red Hat experts&lt;/li&gt; &lt;li&gt;Customer stories and global content&lt;/li&gt; &lt;li&gt;Demos, chat lounges, and community engagement&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://reg.summit.redhat.com/flow/redhat/sum21/regGeneralAttendee/login?intcmp=7013a0000026UTXAA2"&gt;Visit the Red Hat Summit site to secure your spot at both events with one registration&lt;/a&gt;. &lt;a target="_blank" rel="nofollow" href="/summit"&gt;Bookmark this page&lt;/a&gt; for the latest Summit-related developer sessions and on-demand videos.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#038;title=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/" data-a2a-title="Red Hat Summit Virtual Experience 2021: Register today"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/"&gt;Red Hat Summit Virtual Experience 2021: Register today&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qxEz7hH963I" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Automation, application deployment, and how to speed up your journey to the cloud. These and other developer hot topics will take center stage at Red Hat Summit 2021. Join thousands of your peers by registering for our all-new, free, two-part virtual Summit experience. Keynote speaker Burr Sutter will be delving deep into developer technologies as [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/"&gt;Red Hat Summit Virtual Experience 2021: Register today&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">878357</post-id><dc:creator>Red Hat Developer</dc:creator><dc:date>2021-03-08T08:00:55Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/</feedburner:origLink></entry><entry><title>New developer quick starts and more in the Red Hat OpenShift 4.7 web console</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ihpK80S_v6g/" /><category term="CI/CD" /><category term="Kubernetes" /><category term="Operator" /><category term="Serverless" /><category term="helm charts" /><category term="openshift" /><category term="serverless" /><category term="Tekton" /><author><name>Serena Chechile Nichols</name></author><id>https://developers.redhat.com/blog/?p=873037</id><updated>2021-03-08T08:00:26Z</updated><published>2021-03-08T08:00:26Z</published><content type="html">&lt;p&gt;We are continuing to evolve the developer experience in &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com"&gt;Red Hat OpenShift 4.7&lt;/a&gt;. This article highlights what&amp;#8217;s new for developers in the OpenShift 4.7 web console. Keep reading to learn about exciting changes to the topology view, an improved developer catalog experience, new developer quick starts, user interface support for &lt;a target="_blank" rel="nofollow" href="/courses/middleware/openshift-pipelines"&gt;Red Hat OpenShift Pipelines&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="/topics/serverless-architecture"&gt;Red Hat OpenShift Serverless&lt;/a&gt;, and more.&lt;/p&gt; &lt;h2&gt;Quick-add in the topology view&lt;/h2&gt; &lt;p&gt;One of my favorite features in OpenShift 4.7 is the new quick-add option in the web console&amp;#8217;s topology view. You can use this UI control to search for an item from the developer catalog directly from the topology view without changing context. As you type, matches are dynamically shown in a list. You can then click on a match to see a quick overview in the right panel, then click on the call-to-action to install it. The demonstration in Figure 1 shows the new quick-add feature.&lt;/p&gt; &lt;div id="attachment_877827" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/quickadd.gif"&gt;&lt;img aria-describedby="caption-attachment-877827" class="wp-image-877827 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4.7-fig1.gif" alt="An animated demonstration of the quick-add feature." width="640" height="348" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877827" class="wp-caption-text"&gt;Figure 1: The new quick-add feature in the OpenShift web console&amp;#8217;s topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Additionally, the web console now offers persistent storage for user settings so that you can persist layouts in the topology view. We&amp;#8217;ve had many requests for this feature, shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_877837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/topology-layout.gif"&gt;&lt;img aria-describedby="caption-attachment-877837" class="wp-image-877837 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4-7-fig2.gif" alt="A demonstration of persistence in the topology graph layouts." width="640" height="369" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877837" class="wp-caption-text"&gt;Figure 2: Topology graph layouts are now persisted.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;New features in the developer catalog&lt;/h2&gt; &lt;p&gt;The developer catalog is a one-stop-shop for developers to get started quickly with OpenShift. We have improved the developer experience in OpenShift 4.7 by creating a consistent experience across catalogs while also offering contextual views for specific catalog types.&lt;/p&gt; &lt;p&gt;When entering the developer catalog, users can now view all content in a single catalog. Several sub-catalogs are available by default: Builder images, Helm charts, Operator-backed services, and samples. Other sub-catalogs are available based on the installed &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes/operators"&gt;Operators&lt;/a&gt;. OpenShift 4.7 has sub-catalogs for event sources and virtual machines, and more are coming in future releases.&lt;/p&gt; &lt;p&gt;When you drill into sub-catalogs, the features and filters exposed are specific to a given catalog type. As an example, did you know that administrators can add multiple Helm chart repositories? The Helm chart catalog exposes charts from multiple repositories and lets you filter by any Helm chart repository.&lt;/p&gt; &lt;p&gt;Finally, we have received many requests to allow administrators to customize the developer catalog experience. In OpenShift 4.7, we&amp;#8217;ve added a customization feature for catalog administrators. To modify the developer catalog&amp;#8217;s available categories, you only need to add a customization section to the console operator resource. You can then use the resulting YAML snippet to add the default categories to start with and edit them from there.&lt;/p&gt; &lt;h2&gt;Developer quick starts&lt;/h2&gt; &lt;p&gt;You can now access developer quick starts from the &lt;b&gt;+Add&lt;/b&gt; page or from the &lt;b&gt;Quick Starts&lt;/b&gt; item in the OpenShift web console&amp;#8217;s &lt;b&gt;Help&lt;/b&gt; menu. The quick-starts catalog, shown in Figure 3, offers a variety of new developer quick starts—try one out!&lt;/p&gt; &lt;div id="attachment_873397" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev.png"&gt;&lt;img aria-describedby="caption-attachment-873397" class="wp-image-873397 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-1024x562.png" alt="Tiles represent quick starts in the catalog." width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-1024x562.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-300x165.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-768x421.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-873397" class="wp-caption-text"&gt;Figure 3: Developer quick starts in the quick-starts catalog.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Tekton pipelines&lt;/h2&gt; &lt;p&gt;The OpenShift 4.7 web console offers a couple of enhancements for Tekton pipelines. For one, you can now easily access your Tekton pipeline metrics, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_873377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics.png"&gt;&lt;img aria-describedby="caption-attachment-873377" class="wp-image-873377 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-1024x615.png" alt="A demonstration of viewing Tekton metrics in the console." width="640" height="384" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-1024x615.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-300x180.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-768x461.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-873377" class="wp-caption-text"&gt;Figure 4: Tekton pipeline metrics.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We&amp;#8217;ve also enhanced the &lt;b&gt;PipelineRun&lt;/b&gt; details page, as demonstrated in Figure 5.&lt;/p&gt; &lt;div id="attachment_877857" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PLREnhancements.gif"&gt;&lt;img aria-describedby="caption-attachment-877857" class="wp-image-877857 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4-7-fig5.gif" alt="A demonstration of viewing the PipelineRun details page." width="640" height="369" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877857" class="wp-caption-text"&gt;Figure 5: The improved PipelineRun details page.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;From the &lt;b&gt;Events&lt;/b&gt; tab, you can now easily access events related to the &lt;code&gt;PipelineRun&lt;/code&gt;, including &lt;code&gt;TaskRun&lt;/code&gt; and pod events. You can also download logs from the &lt;b&gt;Logs&lt;/b&gt; tab.&lt;/p&gt; &lt;h2&gt;Serverless&lt;/h2&gt; &lt;p&gt;Web console support for OpenShift Serverless includes the ability to create channels. Once created, brokers and channels are displayed in the topology view. In addition to creating subscriptions and triggers from action menus, you can now drag-and-drop to initiate these actions from the topology view.&lt;/p&gt; &lt;p&gt;We have also enhanced the creation flow for event sources. Event sources are custom resources, and we needed to address scalability issues in this feature, so we’ve changed the user experience to be catalog-based. You can now view event sources along with other objects in the service catalog. Alternatively, you can click on the event source type and drill into a catalog solely focused on event sources. As an example, if you had the &lt;a target="_blank" rel="nofollow" href="/integration"&gt;Red Hat Integration&lt;/a&gt; &lt;a target="_blank" rel="nofollow" href="/topics/camel-k"&gt;Camel K&lt;/a&gt; Operator installed, you would see Camel K connectors in the catalog.&lt;/p&gt; &lt;p&gt;We’ve also updated the administrator perspective for OpenShift Serverless. The web console includes a primary navigation section for OpenShift Serverless, which contains two sub-sections. One sub-section focuses on serving resources, and the other is for eventing. You can navigate to these sections to find details about your OpenShift event sources, brokers, triggers, channels, and subscriptions. These items are also accessible in the developer perspective&amp;#8217;s topology view and on the search page.&lt;/p&gt; &lt;h2&gt;We want your feedback&lt;/h2&gt; &lt;p&gt;Community feedback helps us continually improve the OpenShift developer experience, and we want to hear from you. You can attend our office hours on &lt;a target="_blank" rel="nofollow" href="http://openshift.tv"&gt;Red Hat OpenShift Streaming&lt;/a&gt; or join the &lt;a target="_blank" rel="nofollow" href="https://groups.google.com/forum/#!forum/openshift-dev-users"&gt;OpenShift Developer Experience Google group&lt;/a&gt;. We hope you will share your tips for using the OpenShift web console, get help with what doesn’t work, and shape the future of the OpenShift developer experience. Ready to get started? &lt;a target="_blank" rel="nofollow" href="http://www.openshift.com/try"&gt;Try OpenShift today&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#038;title=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/" data-a2a-title="New developer quick starts and more in the Red Hat OpenShift 4.7 web console"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/"&gt;New developer quick starts and more in the Red Hat OpenShift 4.7 web console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ihpK80S_v6g" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;We are continuing to evolve the developer experience in Red Hat OpenShift 4.7. This article highlights what&amp;#8217;s new for developers in the OpenShift 4.7 web console. Keep reading to learn about exciting changes to the topology view, an improved developer catalog experience, new developer quick starts, user interface support for Red Hat OpenShift Pipelines and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/"&gt;New developer quick starts and more in the Red Hat OpenShift 4.7 web console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">873037</post-id><dc:creator>Serena Chechile Nichols</dc:creator><dc:date>2021-03-08T08:00:26Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/</feedburner:origLink></entry></feed>
