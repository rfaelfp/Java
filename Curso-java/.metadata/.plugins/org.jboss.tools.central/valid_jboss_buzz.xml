<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Write your own Red Hat Ansible Tower inventory plugin</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ykaTXiaqjao/" /><category term="Automation" /><category term="Python" /><category term="Ansible" /><category term="Ansible inventories" /><category term="Ansible inventory plugin" /><category term="AWX" /><category term="Python 3" /><author><name>Rigel Di Scala</name></author><id>https://developers.redhat.com/blog/?p=780487</id><updated>2021-03-10T08:00:44Z</updated><published>2021-03-10T08:00:44Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/ansible/ansible"&gt;Ansible&lt;/a&gt; is an engine and language for automating many different IT tasks, such as provisioning a physical device, creating a virtual machine, or configuring an application and its dependencies. Ansible organizes these tasks in &lt;em&gt;playbook&lt;/em&gt; files, which run on one or more remote target hosts. &lt;em&gt;Inventory&lt;/em&gt; files maintain lists of these hosts and are formatted as YAML or INI documents. For example, a simple inventory file in INI format follows:&lt;/p&gt; &lt;pre&gt;[web] web1.example.com web2.example.com &lt;/pre&gt; &lt;p&gt;Ansible inventories can be &lt;em&gt;static&lt;/em&gt; (stored in a file and managed in a source code repository) or &lt;em&gt;dynamic&lt;/em&gt; (retrieved from an external web resource, such as through a RESTful API). Dynamic inventories are generated on-demand using &lt;em&gt;inventory scripts&lt;/em&gt; or &lt;em&gt;inventory plugins&lt;/em&gt;, consisting of code that Ansible runs to get a list of hosts to target when executing playbooks.&lt;/p&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/reference_appendices/tower.html"&gt;Red Hat Ansible Tower&lt;/a&gt;, also known as &lt;a target="_blank" rel="nofollow" href="https://github.com/ansible/awx"&gt;AWX&lt;/a&gt; (the name of its upstream community project), is a front-end to &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/products/red-hat-ansible-engine/"&gt;Red Hat Ansible Engine&lt;/a&gt; that simplifies operations on large IT infrastructures. Operators can log into the Ansible Tower web interface and create single jobs or complex workflows using Ansible Engine building blocks such as tasks, roles, and playbooks. Enterprises typically manage assets in a configuration management database (CMDB), such as &lt;a target="_blank" rel="nofollow" href="https://netbox.readthedocs.io/en/stable/"&gt;NetBox&lt;/a&gt;, which Ansible Tower connects to using a specially written script or plugin.&lt;/p&gt; &lt;p&gt;This article shows you how to use Ansible Tower to create dynamic inventories. We&amp;#8217;ll start with a sample inventory script, then transform the script into a plugin. As you&amp;#8217;ll see, inventory plugins can accept parameters, which gives them an advantage over plain scripts.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Inventory scripts are &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible-tower/latest/html/administration/custom_inventory_script.html#"&gt;deprecated in Ansible Tower&lt;/a&gt;, so they will be removed in a future version. There’s a good reason: Source code is properly managed in a version control system, where developers and operators can track and review changes to its corpus.&lt;/p&gt; &lt;h2&gt;A sample inventory script&lt;/h2&gt; &lt;p&gt;Inventory scripts are organized in a single executable file, written in a scripting language such as Python or Bash. The script must return its data in JSON format. For instance, the following output provides the Ansible playbook with a list of hosts and related data:&lt;/p&gt; &lt;pre&gt;{ "all": { "hosts": ["web1.example.com", "web2.example.com"] }, "_meta": { "hostvars": { "web1.example.com": { "ansible_user": "root" }, "web2.example.com": { "ansible_user": "root" } } } } &lt;/pre&gt; &lt;p&gt;The following Bash code is an inventory script that generates the output just shown:&lt;/p&gt; &lt;pre&gt;#!/usr/bin/env bash # id: scripts/trivial-inventory-script.sh cat &amp;#60;&amp;#60; EOF { "all": { "hosts": ["web1.example.com", "web2.example.com"] }, "_meta": { "hostvars": { "web1.example.com": { "ansible_user": "rdiscala" }, "web2.example.com": { "ansible_user": "rdiscala" } } } } EOF &lt;/pre&gt; &lt;p&gt;Here, an Ansible command runs the inventory script and compares the actual output to the expected output:&lt;/p&gt; &lt;pre&gt;$ ansible -m ping -i scripts/trivial-inventory-script.sh all web1.example.com | SUCCESS =&amp;#62; { "ansible_facts": { "discovered_interpreter_python": "/usr/bin/python" }, "changed": false, "ping": "pong" } web2.example.com | SUCCESS =&amp;#62; { "ansible_facts": { "discovered_interpreter_python": "/usr/bin/python" }, "changed": false, "ping": "pong" } &lt;/pre&gt; &lt;p&gt;The output shows that Ansible correctly interpreted the information given in the &lt;code&gt;hostvars&lt;/code&gt; section and used my username &lt;code&gt;rdiscala&lt;/code&gt; to connect via SSH to the server hosts.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The sample script is intentionally brief and omits a detail: Ansible invokes these scripts with the &lt;code&gt;--list&lt;/code&gt; option if a list of hosts needs to be produced, as it does in our case. Alternatively, Ansible provides the &lt;code&gt;--host=NAME&lt;/code&gt; option when it needs the variables of a specific host, identified by its &lt;code&gt;NAME&lt;/code&gt;. To make the script fully compliant, you would need to implement logic to handle these options.&lt;/p&gt; &lt;h2&gt;Making scripts work in Ansible Tower&lt;/h2&gt; &lt;p&gt;Scripts are defined in the Inventory Scripts section of Ansible Tower&amp;#8217;s web interface. Alternatively, you can write a script in any scripting language supported on the Ansible Tower host. As shown in Figure 1, you can paste the script we&amp;#8217;ve just written directly into the &lt;b&gt;CUSTOM SCRIPT&lt;/b&gt; field and use it to sync an inventory inside Ansible Tower.&lt;/p&gt; &lt;div id="attachment_780867" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script.png"&gt;&lt;img aria-describedby="caption-attachment-780867" class="wp-image-780867" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-300x191.png" alt="Ansible Tower's Inventory Scripts screen contains a text field named CUSTOM SCRIPT, where an administrator can insert an inventory script." width="640" height="408" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-300x191.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-768x490.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script.png 936w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780867" class="wp-caption-text"&gt;Figure 1: You can plug a pre-written script into Ansible Tower&amp;#8217;s Inventory Scripts section.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can now use this new script as an &lt;em&gt;inventory source&lt;/em&gt; in any Ansible Tower inventory. An inventory source provides information about hosts to Ansible Tower on demand. When the source syncs, the script will run, fetch the data, and format it as shown previously so that Ansible Tower can import it into its own host database. The complete list of hosts will show up in the &lt;b&gt;HOSTS&lt;/b&gt; table, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_780877" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts.png"&gt;&lt;img aria-describedby="caption-attachment-780877" class="wp-image-780877 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts-1024x482.png" alt="Ansible Tower's Inventory Scripts screen contains a text field named CUSTOM SCRIPT, where an administrator can insert an inventory script." width="640" height="301" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts-1024x482.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts-300x141.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts-768x362.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tower-inventory-script-hosts.png 1036w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780877" class="wp-caption-text"&gt;Figure 2: Find the complete list of hosts in the HOSTS table.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Create an inventory plugin with Ansible Galaxy&lt;/h2&gt; &lt;p&gt;The newer and recommended way to distribute and consume Ansible content is to create an inventory plugin and package it as an &lt;a target="_blank" rel="nofollow" href="https://www.ansible.com/blog/getting-started-with-ansible-collections"&gt;Ansible collection&lt;/a&gt;. An inventory plugin is considered a module when packaged in a collection.&lt;/p&gt; &lt;p&gt;You can kickstart your effort by using the &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/cli/ansible-galaxy.html"&gt;Ansible Galaxy command-line program&lt;/a&gt; to create the basic structure for a collection:&lt;/p&gt; &lt;pre&gt;$ ansible-galaxy collection init zedr.blog_examples - Collection zedr.blog_examples was created successfully $ tree . . └── zedr └── blog_examples ├── docs ├── galaxy.yml ├── plugins │ └── README.md ├── README.md └── roles &lt;/pre&gt; &lt;p&gt;Let’s start with &lt;code&gt;galaxy.yml&lt;/code&gt;, the manifest file describes this collection:&lt;/p&gt; &lt;pre&gt;namespace: zedr name: blog_examples version: 1.0.0 readme: README.md authors: - Rigel Di Scala &amp;#60;rigel@redhat.com&amp;#62; &lt;/pre&gt; &lt;p&gt;We will create our plugin as a Python script named &lt;code&gt;example_hosts.py&lt;/code&gt; inside the &lt;code&gt;plugins/inventory&lt;/code&gt; folder. Placing the script in this location lets Ansible detect it as an inventory plugin. We can delete the &lt;code&gt;docs&lt;/code&gt; and &lt;code&gt;roles&lt;/code&gt; folders to focus on the minimum viable set of files needed to implement our collection. We should end up with a folder structure like this one:&lt;/p&gt; &lt;pre&gt;$ tree . . └── zedr └── blog_examples ├── galaxy.yml ├── plugins │ └── inventory │ └── example_hosts.py └── README.md &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Important&lt;/strong&gt;: Always specify the full namespace of the collection (for instance, &lt;code&gt;zedr.blog_examples&lt;/code&gt;) when referring to assets contained within it, such as roles and plugins.&lt;/p&gt; &lt;p&gt;We can now copy over, clean up, and populate the &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html"&gt;basic boilerplate code&lt;/a&gt; for an inventory plugin:&lt;/p&gt; &lt;pre&gt;from ansible.plugins.inventory import BaseInventoryPlugin ANSIBLE_METADATA = { 'metadata_version': '', 'status': [], 'supported_by': '' } DOCUMENTATION = ''' --- module: plugin_type: short_description: version_added: "" description: options: author: ''' class InventoryModule(BaseInventoryPlugin): """An example inventory plugin.""" NAME = 'FQDN_OF_THE_PLUGIN_GOES_HERE' def verify_file(self, path): """Verify that the source file can be processed correctly. Parameters: path:AnyStr The path to the file that needs to be verified Returns: bool True if the file is valid, else False """ def parse(self, inventory, loader, path, cache=True): """Parse and populate the inventory with data about hosts. Parameters: inventory The inventory to populate """ # The following invocation supports Python 2 in case we are # still relying on it. Use the more convenient, pure Python 3 syntax # if you don't need it. super(InventoryModule, self).parse(inventory, loader, path, cache) &lt;/pre&gt; &lt;h3&gt;About the code&lt;/h3&gt; &lt;p&gt;You&amp;#8217;ll note that this boilerplate defines two methods: &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#verify-file"&gt;&lt;code&gt;verify_file()&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;parse()&lt;/code&gt;. Use &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#verify-file"&gt;&lt;code&gt;verify_file()&lt;/code&gt;&lt;/a&gt; when the host list you want to process comes from a file, such as a CSV document, on a filesystem at a given path. This method is used to validate the file quickly before passing it to the more expensive &lt;code&gt;parse()&lt;/code&gt; method. Normally, &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#verify-file"&gt;&lt;code&gt;verify_file()&lt;/code&gt;&lt;/a&gt; ensures that the file is valid incoming JSON and matches a predefined schema. (Note that the &lt;code&gt;verify_file()&lt;/code&gt; method is currently empty and must be filled in.)&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;verify_file()&lt;/code&gt; method can return &lt;code&gt;True&lt;/code&gt; when input comes from a source other than a file, such as when calling a remote HTTP API. But it could also verify the incoming JSON.&lt;/p&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#parse"&gt;&lt;code&gt;parse()&lt;/code&gt;&lt;/a&gt; method does most of the work of processing the source data to filter and format it correctly. However, instead of directly constructing the payload&amp;#8217;s &lt;code&gt;dict&lt;/code&gt; namespace, as we did in the inventory script, we will rely on the &lt;em&gt;instance attribute&lt;/em&gt;, &lt;code&gt;self.inventory&lt;/code&gt;, which is a special object with its own methods. The attribute offers &lt;code&gt;add_host()&lt;/code&gt; and &lt;code&gt;set_variable()&lt;/code&gt; methods to construct a data object suitable for Ansible to consume. (The &lt;code&gt;parse()&lt;/code&gt; method is currently empty except for a call to the superclass&amp;#8217;s function.)&lt;/p&gt; &lt;p&gt;Additionally, note that the module-level attributes &lt;code&gt;ANSIBLE_METADATA&lt;/code&gt; and &lt;code&gt;DOCUMENTATION&lt;/code&gt; are required, and that the &lt;code&gt;NAME&lt;/code&gt; attribute must have the plugin&amp;#8217;s fully qualified domain name, including the namespace.&lt;/p&gt; &lt;h3&gt;Invoking the plugin&lt;/h3&gt; &lt;p&gt;When the plugin is invoked in Ansible from the command line, the following chain of events occurs:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The conventional name &lt;code&gt;InventoryModule&lt;/code&gt; is imported from the chosen inventory module (&lt;code&gt;zedr.blog_example.example_hosts.py&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;An instance of &lt;code&gt;InventoryModule&lt;/code&gt; is created.&lt;/li&gt; &lt;li&gt;The instance method &lt;code&gt;InventoryModule.verify_file()&lt;/code&gt; is called to perform an initial validation of the file (when applicable) and is expected to return a truthy value to proceed.&lt;/li&gt; &lt;li&gt;The instance method &lt;code&gt;InventoryModule.parse()&lt;/code&gt; is called to populate the &lt;code&gt;InventoryModule.inventory&lt;/code&gt; object.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;InventoryModule.inventory&lt;/code&gt; object is introspected to retrieve the host data that Ansible will consume.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We can now rewrite the script logic as follows:&lt;/p&gt; &lt;pre&gt;from ansible.plugins.inventory import BaseInventoryPlugin ANSIBLE_METADATA = { 'metadata_version': '1.0.0', 'status': ['preview'], 'supported_by': 'community' } DOCUMENTATION = ''' --- module: example_hosts plugin_type: inventory short_description: An example Ansible Inventory Plugin version_added: "2.9.13" description: - "A very simple Inventory Plugin created for demonstration purposes only." options: author: - Rigel Di Scala ''' class InventoryModule(BaseInventoryPlugin): """An example inventory plugin.""" NAME = 'zedr.blog_examples.example_hosts' def verify_file(self, path): """Verify that the source file can be processed correctly. Parameters: path:AnyStr The path to the file that needs to be verified Returns: bool True if the file is valid, else False """ # Unused, always return True return True def _get_raw_host_data(self): """Get the raw static data for the inventory hosts Returns: dict The host data formatted as expected for an Inventory Script """ return { "all": { "hosts": ["web1.example.com", "web2.example.com"] }, "_meta": { "hostvars": { "web1.example.com": { "ansible_user": "rdiscala" }, "web2.example.com": { "ansible_user": "rdiscala" } } } } def parse(self, inventory, *args, **kwargs): """Parse and populate the inventory with data about hosts. Parameters: inventory The inventory to populate We ignore the other parameters in the future signature, as we will not use them. Returns: None """ # The following invocation supports Python 2 in case we are # still relying on it. Use the more convenient, pure Python 3 syntax # if you don't need it. super(InventoryModule, self).parse(inventory, *args, **kwargs) raw_data = self._get_raw_host_data() _meta = raw_data.pop('_meta') for group_name, group_data in raw_data.items(): for host_name in group_data['hosts']: self.inventory.add_host(host_name) for var_key, var_val in _meta['hostvars'][host_name].items(): self.inventory.set_variable(host_name, var_key, var_val) &lt;/pre&gt; &lt;p&gt;Note that we have ignored facilities related to grouping and &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html#inventory-cache"&gt;caching&lt;/a&gt; to keep things simple. These facilities are worth looking into to organize the host list better and optimize the synchronization process&amp;#8217;s performance.&lt;/p&gt; &lt;h3&gt;Build, install, and test the plugin&lt;/h3&gt; &lt;p&gt;The next step is to build the Ansible collection package, install it locally, and test the plugin:&lt;/p&gt; &lt;pre&gt;$ cd zedr/blog_examples $ mkdir build $ ansible-galaxy collection build -f --output-path build Created collection for zedr.blog_examples at /home/rdiscala/blog/ansible-tower-inventory-plugin/collections/zedr/blog_examples/build/zedr-blog_examples-1.0.0.tar.gz $ ansible-galaxy collection install build/zedr-blog_examples-1.0.0.tar.gz Process install dependency map Starting collection install process Installing 'zedr.blog_examples:1.0.0' to '/home/rdiscala/.ansible/collections/ansible_collections/zedr/blog_examples' &lt;/pre&gt; &lt;p&gt;Next, we need to enable our plugin by adding a local &lt;code&gt;galaxy.cfg&lt;/code&gt; file in our current working directory. The contents are:&lt;/p&gt; &lt;pre&gt;[inventory] enable_plugins = zedr.blog_examples.example_hosts &lt;/pre&gt; &lt;p&gt;To check whether the local installation was successful, we can attempt to display the documentation for our inventory plugin, using its fully qualified domain name:&lt;/p&gt; &lt;pre&gt;$ ansible-doc -t inventory zedr.blog_examples.example_hosts &amp;#62; INVENTORY (/home/rdiscala/.ansible/collections/ansible_collections/zedr/blog_examples/plugins/inventory/example_hosts.py) An example Inventory Plugin created for demonstration purposes only. * This module is maintained by The Ansible Community AUTHOR: Rigel Di Scala &amp;#60;rigel@redhat.com&amp;#62; METADATA: status: - preview supported_by: community PLUGIN_TYPE: inventory &lt;/pre&gt; &lt;p&gt;We can also list the available plugins to verify that ours is detected correctly. Note that for this to work with the Ansible collection, you will need &lt;a target="_blank" rel="nofollow" href="https://pypi.org/project/ansible/#history2.10"&gt;Ansible version 3.0 or higher&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;$ ansible-doc -t inventory -l advanced_host_list Parses a 'host list' with ranges amazon.aws.aws_ec2 EC2 inventory source amazon.aws.aws_rds rds instance source auto Loads and executes an inventory plugin specified in a YAML config (...) zedr.blog_examples.example_hosts A trivial example of an Ansible Inventory Plugin &lt;/pre&gt; &lt;p&gt;Finally, we can test the plugin locally by running it using an inventory configuration file. Create a file named &lt;code&gt;inventory.yml&lt;/code&gt; with the following content:&lt;/p&gt; &lt;pre&gt;plugin: "zedr.blog_examples.example_hosts" &lt;/pre&gt; &lt;p&gt;Here is the command to invoke the plugin and generate the inventory data:&lt;/p&gt; &lt;pre&gt;$ ansible-inventory --list -i inventory.yml { "_meta": { "hostvars": { "web1.example.com": { "ansible_user": "rdiscala" }, "web2.example.com": { "ansible_user": "rdiscala" } } }, "all": { "children": [ "ungrouped" ] }, "ungrouped": { "hosts": [ "web1.example.com", "web2.example.com" ] } } &lt;/pre&gt; &lt;p&gt;Ansible has generated two &amp;#8220;virtual&amp;#8221; groups: &lt;code&gt;ungrouped&lt;/code&gt;, with our list of hosts, and &lt;code&gt;all&lt;/code&gt;, which includes &lt;code&gt;ungrouped&lt;/code&gt;. We have verified that the plugin is working correctly.&lt;/p&gt; &lt;h2&gt;Making the plugin work in Ansible Tower&lt;/h2&gt; &lt;p&gt;Ansible Tower can automate a collection&amp;#8217;s installation, making its roles and plugins available to projects and job templates. To make it work, we need the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A place to provide the package file that we built for our collection. We&amp;#8217;ll use a Git repo hosted on GitHub, but it could also be published on &lt;a target="_blank" rel="nofollow" href="https://galaxy.ansible.com/"&gt;Ansible Galaxy&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;A repo for the project files containing the &lt;code&gt;requirements.yml&lt;/code&gt; file that references our collection and the &lt;code&gt;inventory.yml&lt;/code&gt; configuration file we used previously.&lt;/li&gt; &lt;li&gt;An Ansible Tower project that points to the project files repo.&lt;/li&gt; &lt;li&gt;An Ansible Tower inventory.&lt;/li&gt; &lt;li&gt;An Ansible Tower inventory source for our inventory.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The following events will be triggered when Ansible Tower executes a job that uses this inventory:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The job triggers a project update (the internal &lt;code&gt;project_update.yml&lt;/code&gt; playbook).&lt;/li&gt; &lt;li&gt;The project syncs with its associated Git repo.&lt;/li&gt; &lt;li&gt;If necessary, the project installs any needed dependencies, which should be listed in the &lt;code&gt;collection/requirements.yml&lt;/code&gt; file.&lt;/li&gt; &lt;li&gt;The project update triggers an inventory update.&lt;/li&gt; &lt;li&gt;The inventory update triggers an inventory source sync.&lt;/li&gt; &lt;li&gt;The inventory source sync reads the inventory file &lt;code&gt;inventory.yml&lt;/code&gt; and runs our plugin to fetch the host data.&lt;/li&gt; &lt;li&gt;The host data populates the inventory.&lt;/li&gt; &lt;li&gt;The job runs the associated playbook on the inventory host list using the provided hostnames and variables.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Figure 3 shows this workflow.&lt;/p&gt; &lt;div id="attachment_780817" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow.png"&gt;&lt;img aria-describedby="caption-attachment-780817" class="wp-image-780817 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow-1024x512.png" alt="Visualizing the inventory-update process workflow just described." width="640" height="320" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow-1024x512.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow-300x150.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-plugin-workflow-768x384.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780817" class="wp-caption-text"&gt;Figure 3: The workflow for populating a host list using an inventory plugin.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, let&amp;#8217;s create the components required to make the plugin work.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The following example was tested on Ansible Tower 3.7.1.&lt;/p&gt; &lt;h3&gt;Create a Git repo for the collection&lt;/h3&gt; &lt;p&gt;To start, we&amp;#8217;ll create a new repo on Github and push the collection files we created earlier. A &lt;a target="_blank" rel="nofollow" href="https://github.com/zedr/blog_examples"&gt;sample repo&lt;/a&gt; is available on GitHub.&lt;/p&gt; &lt;p&gt;Ansible cannot clone a repository and build the collection by itself, so we need to build the package and make it available as a downloadable &lt;code&gt;tar.gz&lt;/code&gt; file. As an example, from the &lt;a href="https://github.com/zedr/blog_examples/releases/"&gt;Releases page&lt;/a&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: At the time of writing, Ansible Tower cannot fetch the package as an authenticated user, so you will need to allow anonymous clients.&lt;/p&gt; &lt;p&gt;If you are using GitHub, you can set up a GitHub Actions workflow to fully automate this process:&lt;/p&gt; &lt;pre&gt;# id: .github/workflows/main.yml name: CI # Only build releases when a new tag is pushed. on: push: tags: - '*' jobs: build: runs-on: ubuntu-latest steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v2 # Extract the version from the tag name so it can be used later. - name: Get the version id: get_version run: echo ::set-output name=VERSION::${GITHUB_REF#refs/tags/} # Install a recent version of Python 3 - name: Setup Python uses: actions/setup-python@v2 with: python-version: 3.7 # Install our dependencies, e.g. Ansible - name: Install Python 3.7 run: python3.7 -m pip install -r requirements.txt - name: Build the Ansible collection run: | mkdir -p build ansible-galaxy collection build -f --output-path build - name: Create a Release id: create_a_release uses: actions/create-release@v1 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: tag_name: ${{ steps.get_version.outputs.VERSION }} release_name: Release ${{ steps.get_version.outputs.VERSION }} draft: false - name: Upload a Release Asset uses: actions/upload-release-asset@v1.0.2 env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} with: upload_url: ${{ steps.create_a_release.outputs.upload_url }} asset_path: build/zedr-blog_examples-${{ steps.get_version.outputs.VERSION }}.tar.gz asset_name: "zedr-blog_examples-${{ steps.get_version.outputs.VERSION }}.tar.gz" asset_content_type: "application/gzip" &lt;/pre&gt; &lt;h3&gt;Create a Git repo for project files&lt;/h3&gt; &lt;p&gt;Next, we need another Git repo for the files that the Ansible Tower project will source. Here is the folder structure:&lt;/p&gt; &lt;pre&gt;$ tree . . ├── collections │ └── requirements.yml └── inventory.yml &lt;/pre&gt; &lt;p&gt;Note that &lt;code&gt;collections/requirements.yml&lt;/code&gt; will contain a reference to our Ansible collection package so that Ansible Tower can download, install, and use it when the inventory is synced. Additionally, the &lt;code&gt;inventory.yml&lt;/code&gt; is the same file we created earlier, containing the plugin&amp;#8217;s fully qualified domain name. See the &lt;a target="_blank" rel="nofollow" href="https://github.com/zedr-automation/example_project"&gt;example repo&lt;/a&gt; for more details.&lt;/p&gt; &lt;h3&gt;Create a new Ansible Tower project&lt;/h3&gt; &lt;p&gt;Next, sign in to your Ansible Tower instance, create a new project, and fill in the following fields and checkboxes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Name&lt;/b&gt;: &lt;code&gt;My Project&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Organization&lt;/b&gt;: &lt;code&gt;Default&lt;/code&gt; (or whatever you prefer).&lt;/li&gt; &lt;li&gt;&lt;b&gt;SCM Type&lt;/b&gt;: &lt;code&gt;Git&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;SCM URL&lt;/b&gt;: &lt;code&gt;https://github.com/zedr-automation/example_project.git&lt;/code&gt; (or the Git repo URL of your project).&lt;/li&gt; &lt;li&gt;&lt;b&gt;SCM Branch/Tag/Commit&lt;/b&gt;: &lt;code&gt;master&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;SCM Update Options&lt;/b&gt;: select &lt;b&gt;Clean&lt;/b&gt;, &lt;b&gt;Delete On Update&lt;/b&gt;, and &lt;b&gt;Update Revision on Launch&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Figure 4 shows the resulting form.&lt;/p&gt; &lt;div id="attachment_780857" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project.png"&gt;&lt;img aria-describedby="caption-attachment-780857" class="wp-image-780857" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project-300x246.png" alt="This form creates the Ansible Tower project." width="640" height="525" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project-300x246.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project-768x629.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-project.png 920w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780857" class="wp-caption-text"&gt;Figure 4: Creating the Ansible Tower project.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Create a new Ansible Tower inventory&lt;/h3&gt; &lt;p&gt;There are just two fields to create a new inventory in Tower: For the &lt;b&gt;Name&lt;/b&gt; field, enter &lt;code&gt;My Inventory&lt;/code&gt;. For the &lt;b&gt;Organization&lt;/b&gt;, you can select the default or whatever you previously entered. Figure 5 shows the resulting form.&lt;/p&gt; &lt;div id="attachment_780837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory.png"&gt;&lt;img aria-describedby="caption-attachment-780837" class="wp-image-780837" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory-300x214.png" alt="This form creates the Ansible Tower inventory." width="640" height="456" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory-300x214.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory-768x548.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-inventory.png 923w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780837" class="wp-caption-text"&gt;Figure 5: Creating the Ansible Tower inventory.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Create a new inventory source for the inventory&lt;/h3&gt; &lt;p&gt;Finally, create a new inventory source for the inventory. Fill in the fields and checkboxes as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Name&lt;/b&gt;: &lt;code&gt;My inventory source&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Source&lt;/b&gt;: &lt;code&gt;Sourced from a project&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Project&lt;/b&gt;: &lt;code&gt;My project&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Inventory File&lt;/b&gt;: &lt;code&gt;inventory.yml&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Update Options&lt;/b&gt;: Select &lt;b&gt;Overwrite&lt;/b&gt;, &lt;b&gt;Overwrite Variables&lt;/b&gt;, and &lt;b&gt;Update on Project Update&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Save the form and then click the &lt;b&gt;Start sync process&lt;/b&gt; button for the new inventory source you just created. If the process finishes correctly, your inventory&amp;#8217;s HOSTS page will display the two example hosts, as shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_780827" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts.png"&gt;&lt;img aria-describedby="caption-attachment-780827" class="wp-image-780827" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts-300x148.png" alt="The two hosts just created appear in the hosts list in the Ansible Tower inventory." width="640" height="316" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts-768x380.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ansible-tower-hosts.png 999w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780827" class="wp-caption-text"&gt;Figure 6: Viewing the HOSTS list in the Ansible Tower inventory.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Final thoughts&lt;/h2&gt; &lt;p&gt;The inventory plugin we&amp;#8217;ve created is basic, but it’s a good foundation for implementing more complex ones that can query external sources of data, perhaps using third-party libraries. Being modules, inventory plugins can also accept parameters, giving them an advantage over plain scripts. For more information, see the official Ansible documentation on &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible/latest/dev_guide/developing_plugins.html#plugin-configuration-documentation-standards"&gt;plugin configuration&lt;/a&gt;. Also, note that if you decide to use a third-party library not present in Python’s standard library, such as &lt;a target="_blank" rel="nofollow" href="https://requests.readthedocs.io/en/master/"&gt;Requests&lt;/a&gt;, you will need to install it manually in the appropriate &lt;a target="_blank" rel="nofollow" href="https://docs.ansible.com/ansible-tower/3.7.1/html/administration/tipsandtricks.html#using-virtualenv-with-at"&gt;Python virtual environment inside Ansible Tower&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Happy developing!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#38;linkname=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F10%2Fwrite-your-own-red-hat-ansible-tower-inventory-plugin%2F&amp;#038;title=Write%20your%20own%20Red%20Hat%20Ansible%20Tower%20inventory%20plugin" data-a2a-url="https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/" data-a2a-title="Write your own Red Hat Ansible Tower inventory plugin"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/"&gt;Write your own Red Hat Ansible Tower inventory plugin&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ykaTXiaqjao" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Ansible is an engine and language for automating many different IT tasks, such as provisioning a physical device, creating a virtual machine, or configuring an application and its dependencies. Ansible organizes these tasks in playbook files, which run on one or more remote target hosts. Inventory files maintain lists of these hosts and are formatted [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/"&gt;Write your own Red Hat Ansible Tower inventory plugin&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">780487</post-id><dc:creator>Rigel Di Scala</dc:creator><dc:date>2021-03-10T08:00:44Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/10/write-your-own-red-hat-ansible-tower-inventory-plugin/</feedburner:origLink></entry><entry><title>An introduction to JavaScript SDK for CloudEvents</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/QyzqZRtXZYY/" /><category term="Event-Driven" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="CloudEvents" /><category term="serverless functions" /><category term="Typescript" /><author><name>Lucas Holmquist</name></author><id>https://developers.redhat.com/blog/?p=810797</id><updated>2021-03-09T08:00:50Z</updated><published>2021-03-09T08:00:50Z</published><content type="html">&lt;p&gt;In today&amp;#8217;s world of &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;serverless&lt;/a&gt; functions and &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt;, events are everywhere. The problem is that they are described differently depending on the producer technology you use.&lt;/p&gt; &lt;p&gt;Without a common standard, the burden is on developers to constantly relearn how to consume events. Not having a standard also makes it more difficult for authors of libraries and tooling to deliver event data across environments like SDKs. Recently, a new project was created to help with this effort.&lt;/p&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://cloudevents.io/"&gt;CloudEvents&lt;/a&gt; is a specification for describing event data in common formats to provide interoperability across services, platforms, and systems. In fact, Red Hat OpenShift Serverless Functions uses CloudEvents. For more information about this new developer feature, see &lt;a target="_blank" rel="nofollow" href="/blog/2021/01/04/create-your-first-serverless-function-with-red-hat-openshift-serverless-functions/"&gt;&lt;em&gt;Create your first serverless function with Red Hat OpenShift Serverless Functions&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;The CloudEvents specification&lt;/h2&gt; &lt;p&gt;The specification&amp;#8217;s goal isn’t to create yet another event format and try to force everyone to use it. Rather, we want to define common metadata for events and establish where this metadata should appear in the message being sent.&lt;/p&gt; &lt;p&gt;It is a simple spec with simple goals. In fact, a CloudEvent requires only four pieces of metadata:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;type&lt;/code&gt; describes what kind of event this might be (e.g., a “create” event).&lt;/li&gt; &lt;li&gt;&lt;code&gt;specversion&lt;/code&gt; denotes the version of the spec used to create the CloudEvent.&lt;/li&gt; &lt;li&gt;&lt;code&gt;source&lt;/code&gt; describes where the event came from.&lt;/li&gt; &lt;li&gt;&lt;code&gt;id&lt;/code&gt; is a unique identifier that is useful for de-duping.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There are other useful fields, like &lt;code&gt;subject&lt;/code&gt;, which when combined with &lt;code&gt;source&lt;/code&gt; can add a little more context to where the event originated.&lt;/p&gt; &lt;p&gt;As I mentioned, the CloudEvents specification is only concerned with the common metadata listed above, and the location where this metadata is placed when sending the event.&lt;/p&gt; &lt;p&gt;Currently, there are two event formats: Binary, which is the preferred format, and structured. Binary is recommended because it is additive. That is, the binary format only adds some headers to the HTTP request. If there is a middleware that doesn’t understand CloudEvents, it won’t break anything, but if that system is updated to support CloudEvents, it starts working.&lt;/p&gt; &lt;p&gt;Structured formats are for those who don’t have any format currently defined and are looking for guidance on how things should be structured.&lt;/p&gt; &lt;p&gt;Here is a quick example of what those two event formats might look like in raw HTTP:&lt;/p&gt; &lt;pre&gt;// Binary Post /event HTTP/1.0 Host: example.com Content-Type: application/json ce-specversion: 1.0 ce-type: com.nodeshift.create ce-source: nodeshift.dev ce-id: 123456 { "action": "createThing", "item": "2187" } // Structured Post /event HTTP/1.0 Host: example.com Content-Type: application/cloudevents+json { "specversion": "1.0" "type": "com.nodeshift.create" "source": "nodeshift.dev" "id": "123456" "data": { "action": "createThing", "item": "2187" } } &lt;/pre&gt; &lt;h2&gt;JavaScript SDK for CloudEvents&lt;/h2&gt; &lt;p&gt;Of course, we don’t want to have to format these events manually. That is where the &lt;a target="_blank" rel="nofollow" href="https://www.npmjs.com/package/cloudevents"&gt;JavaScript SDK for CloudEvents&lt;/a&gt; comes in. There are three main goals that an SDK should accomplish:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Compose an event.&lt;/li&gt; &lt;li&gt;Encode an event for sending.&lt;/li&gt; &lt;li&gt;Decode an incoming event.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Installing the JavaScript SDK is like using any other Node module:&lt;/p&gt; &lt;pre&gt;$ npm install cloudevents &lt;/pre&gt; &lt;p&gt;Now that we’ve seen what a CloudEvent is and how it is useful let&amp;#8217;s take a look at an example.&lt;/p&gt; &lt;h2&gt;Create a new CloudEvent&lt;/h2&gt; &lt;p&gt;First, we are going to create a new CloudEvent object:&lt;/p&gt; &lt;pre&gt;const { CloudEvent } = require('cloudevents'); // Create a new CloudEvent const ce = new CloudEvent({ type: 'com.cloudevent.fun', source: 'fun-with-cloud-events', data: { key: 'DATA' } }); &lt;/pre&gt; &lt;p&gt;If we log this out with the object&amp;#8217;s built-in &lt;code&gt;toJSON&lt;/code&gt; method, we might see something like this:&lt;/p&gt; &lt;pre&gt;console.log(ce.toJSON()); { id: '...', type: 'com.cloudevent.fun', source: 'fun-with-cloud-events', specversion: '1.0', time: '...', data: { key: 'DATA' } } &lt;/pre&gt; &lt;h3&gt;Sending the message&lt;/h3&gt; &lt;p&gt;Next, let&amp;#8217;s look at how to send this over HTTP using the binary format.&lt;/p&gt; &lt;p&gt;First, we need to create our message in the binary format, which you can do easily with the &lt;code&gt;HTTP.binary&lt;/code&gt; method. We will use the CloudEvent from the previous example:&lt;/p&gt; &lt;pre&gt; const message = HTTP.binary(ce); //const message = HTTP.structured(ce); // Showing just for completeness &lt;/pre&gt; &lt;p&gt;Again, if we log this out, it might look something like this:&lt;/p&gt; &lt;pre&gt; headers: { 'content-type': 'application/json;', 'ce-id': '...', 'ce-type': 'com.cloudevent.fun', 'ce-source': 'fun-with-cloud-events', 'ce-specversion': '1.0', 'ce-time': '...' }, body: { key: 'DATA' } } &lt;/pre&gt; &lt;p&gt;Now that the message has been formatted properly, we can send it by using a library like &lt;a target="_blank" rel="nofollow" href="https://github.com/axios/axios"&gt;Axios&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Note that the CloudEvents SDK doesn’t handle sending messages; it only handles formatting the message headers and message body. This allows you to use any HTTP library you want to send the message.&lt;/p&gt; &lt;pre&gt;const axios = require('axios') axios({ method: 'post', url: 'http://localhost:3000/cloudeventy', data: message.body, headers: message.headers }).then((response) =&amp;#62; { console.log(response.data); }); &lt;/pre&gt; &lt;p&gt;We are sending a POST request to the “cloudevent-y” REST endpoint. In this example, I have used a simple Express.js application, but you can use any framework you like.&lt;/p&gt; &lt;h3&gt;Receiving the message&lt;/h3&gt; &lt;p&gt;Once we have the message, we can use the &lt;code&gt;HTTP.toEvent&lt;/code&gt; method to convert it back into a CloudEvent object.&lt;/p&gt; &lt;pre&gt;const express = require('express'); const { HTTP } = require('cloudevents'); const app = express(); app.post('/cloudeventy', (req, res) =&amp;#62; { const ce = HTTP.toEvent({ headers: req.headers, body: req.body }); console.log(ce.toJSON()); res.send({key: 'Event Received'}); }); &lt;/pre&gt; &lt;p&gt;Again, the log output looks similar to what we saw when we output the CloudEvent object:&lt;/p&gt; &lt;pre&gt;{ id: '...', type: 'com.cloudevent.fun', source: 'fun-with-cloud-events', specversion: '1.0', time: '...', data: { key: 'DATA' } } &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;To learn more about the JavaScript SDK for CloudEvents, &lt;a target="_blank" rel="nofollow" href="https://github.com/cloudevents/sdk-javascript"&gt;check out the GitHub project&lt;/a&gt;. For more information about the history, development, and design rationale behind the specification, see the &lt;a href="https://github.com/cloudevents/spec/blob/master/primer.md" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;CloudEvents Primer&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#38;linkname=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fan-introduction-to-javascript-sdk-for-cloudevents%2F&amp;#038;title=An%20introduction%20to%20JavaScript%20SDK%20for%20CloudEvents" data-a2a-url="https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/" data-a2a-title="An introduction to JavaScript SDK for CloudEvents"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/"&gt;An introduction to JavaScript SDK for CloudEvents&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/QyzqZRtXZYY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In today&amp;#8217;s world of serverless functions and microservices, events are everywhere. The problem is that they are described differently depending on the producer technology you use. Without a common standard, the burden is on developers to constantly relearn how to consume events. Not having a standard also makes it more difficult for authors of libraries [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/"&gt;An introduction to JavaScript SDK for CloudEvents&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">810797</post-id><dc:creator>Lucas Holmquist</dc:creator><dc:date>2021-03-09T08:00:50Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/09/an-introduction-to-javascript-sdk-for-cloudevents/</feedburner:origLink></entry><entry><title>Deploying Node.js applications to Kubernetes with Nodeshift and Minikube</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/fAqJZg6t3vY/" /><category term="Developer Tools" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="minikube" /><category term="nodeshift" /><category term="openshift" /><category term="S2I" /><author><name>Lucas Holmquist</name></author><id>https://developers.redhat.com/blog/?p=865157</id><updated>2021-03-09T08:00:39Z</updated><published>2021-03-09T08:00:39Z</published><content type="html">&lt;p&gt;In a &lt;a target="_blank" rel="nofollow" href="/blog/2019/08/30/easily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift/"&gt;previous article&lt;/a&gt;, I showed how easy it was to deploy a &lt;a target="_blank" rel="nofollow" href="/topics/nodejs"&gt;Node.js&lt;/a&gt; application during development to &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; using the Nodeshift command-line interface (CLI). In this article, we will take a look at using Nodeshift to deploy Node.js applications to vanilla &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;—specifically, with Minikube.&lt;/p&gt; &lt;h2&gt;Getting started&lt;/h2&gt; &lt;p&gt;If you want to follow along with this tutorial, you will need to run Minikube. I won&amp;#8217;t cover the setup process, but &lt;a target="_blank" rel="nofollow" href="https://minikube.sigs.k8s.io/docs/start/"&gt;Minikube&amp;#8217;s documentation&lt;/a&gt; can guide you through it. For the tutorial, I also assume that you have installed &lt;a target="_blank" rel="nofollow" href="https://nodejs.org/en/download"&gt;Node.js and Node Package Manager (npm)&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The code samples we&amp;#8217;ll use are available on &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift-starters/basic-node-app-dockerized"&gt;GitHub&lt;/a&gt;. Our example is a very basic Node.js application with a Dockerfile. In fact, it is taken from the &lt;a target="_blank" rel="nofollow" href="https://nodejs.org/en/docs/guides/nodejs-docker-webapp/"&gt;&lt;i&gt;Dockerizing a Node.js web app&lt;/i&gt;&lt;/a&gt; guide on Nodejs.org.&lt;/p&gt; &lt;h2&gt;The Nodeshift CLI&lt;/h2&gt; &lt;p&gt;As the Nodeshift module readme states, Nodeshift is an opinionated command-line application and programmable API that you can use to deploy Node.js applications to &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. You can easily run it using the &lt;code&gt;npx&lt;/code&gt; command, and it will create the appropriate YAML files to deploy your application.&lt;/p&gt; &lt;p&gt;Nodeshift is a great tool to use if you are developing against an OpenShift cluster, which uses the Source-to-Image (S2I) workflow. In short, Nodeshift creates an OpenShift &lt;code&gt;BuildConfig&lt;/code&gt;, which calls a Node.js S2I image to build your Node application. In most cases, you can achieve this by running &lt;code&gt;npm install&lt;/code&gt;. The build result is put into an OpenShift &lt;code&gt;ImageStream&lt;/code&gt; that resides in the internal OpenShift container registry. This image is then used to deploy your application.&lt;/p&gt; &lt;p&gt;But what about deploying to a vanilla Kubernetes cluster that doesn’t know anything about BuildConfigs, ImageStreams, or S2I? Well, as of &lt;a href="https://github.com/nodeshift/nodeshift/releases/tag/v7.3.0"&gt;Nodeshift&amp;#8217;s 7.3 release&lt;/a&gt;, you can now deploy your Node.js applications to Minikube.&lt;/p&gt; &lt;h2&gt;Deploying Node.js to Minikube&lt;/h2&gt; &lt;p&gt;Before we look at how Nodeshift works for deploying a Node.js application to Minikube, let’s take a minute for a high-level overview of deploying to Kubernetes.&lt;/p&gt; &lt;p&gt;First, you will create an application container image, which you can do with Docker. Once you have a container image, you&amp;#8217;ll need to push that image to a container registry that your cluster has access to, something like &lt;a target="_blank" rel="nofollow" href="https://hub.docker.com/"&gt;Docker Hub&lt;/a&gt;. Once the image is available, you must then specify that image in your deployment YAML and create a service to expose the application.&lt;/p&gt; &lt;p&gt;This flow starts to be more cumbersome when you start iterating on your code. It isn’t really development-friendly if you need to run a Docker build and push that new image to Docker Hub every time. Not to mention that you also need to update your deployment with the new version of the image to ensure it redeploys.&lt;/p&gt; &lt;p&gt;Nodeshift&amp;#8217;s goal is to make developers&amp;#8217; lives easier when deploying to OpenShift and Kubernetes. Let&amp;#8217;s see how Nodeshift helps with each of those unwieldy steps.&lt;/p&gt; &lt;h2&gt;Minikube&amp;#8217;s internal Docker server&lt;/h2&gt; &lt;p&gt;A major difference between OpenShift and Kubernetes is that there is no easy way to run S2I builds on plain Kubernetes. We also don’t want to run a Docker build and push to Docker Hub every time we change our code. Fortunately, Minikube gives us an alternative.&lt;/p&gt; &lt;p&gt;Minikube has its own internal Docker server that we can connect to using the &lt;a target="_blank" rel="nofollow" href="https://docs.docker.com/engine/api/v1.41/#"&gt;Docker Engine API&lt;/a&gt;. We can use this server to run our Docker build in the environment, which means that we don’t have to push the image to an external resource like Docker Hub. We can then use this image in our deployment.&lt;/p&gt; &lt;p&gt;To get access to the internal Docker server, Minikube has a command to export some environment variables to add to your terminal shell. This command is &lt;code&gt;minikube docker-env&lt;/code&gt;, which might output something like this:&lt;/p&gt; &lt;pre&gt;export DOCKER_TLS_VERIFY="1" export DOCKER_HOST="tcp://192.168.39.12:2376" export DOCKER_CERT_PATH="/home/lucasholmquist/.minikube/certs" export MINIKUBE_ACTIVE_DOCKERD="minikube" # To point your shell to minikube's docker-daemon, run: # eval $(minikube -p minikube docker-env) &lt;/pre&gt; &lt;h2&gt;Making it easier with Nodeshift&lt;/h2&gt; &lt;p&gt;Nodeshift abstracts the details we don’t really care about so we can focus on our applications. In this case, we don’t want to think about how to connect to Minikube&amp;#8217;s internal server or how to run Docker commands by hand, and we don’t want to think about updating our deployment YAML every time we build a new image to redeploy it.&lt;/p&gt; &lt;p&gt;Using the Nodeshift CLI with the &lt;code&gt;--kube&lt;/code&gt; flag simplifies those tasks. Let’s see how it works using our &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift-starters/basic-node-app-dockerized"&gt;example application&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;We will use &lt;code&gt;npx&lt;/code&gt; to deploy the Node.js application to Minikube, so we don’t need to install anything globally. Run it like this in the example directory:&lt;/p&gt; &lt;pre&gt;$ npx nodeshift --kube &lt;/pre&gt; &lt;p&gt;Nodeshift creates a service and deployment by default if none are provided. Also, note that the type of service it creates is a &lt;code&gt;LoadBalancer&lt;/code&gt;, which allows us to expose our application without using ingress.&lt;/p&gt; &lt;p&gt;The Nodeshift CLI runs the same &lt;code&gt;goals&lt;/code&gt; for a Kubernetes deploy as it does for an OpenShift deploy. The key difference comes during the &lt;code&gt;build&lt;/code&gt; phase. Instead of creating an OpenShift &lt;code&gt;BuildConfig&lt;/code&gt; and running an S2I process on the cluster, Nodeshift uses the &lt;a target="_blank" rel="nofollow" href="https://www.npmjs.com/package/dockerode"&gt;dockerode&lt;/a&gt; module to connect to Minikube&amp;#8217;s internal Docker server and run a build using the provided Dockerfile. The built image is now in that internal registry, ready to be deployed by the deployment YAML that the Nodeshift CLI creates. Nodeshift also adds a randomly-generated number to the deployment&amp;#8217;s metadata, which is then applied during every redeploy. This will trigger Minikube to redeploy the application with the new image.&lt;/p&gt; &lt;p&gt;The following is an example log output:&lt;/p&gt; &lt;pre&gt;~/develop/nodeshift-starters/basic-node-app-dockerized» npx nodeshift --kube 2021-02-09T20:03:18.405Z INFO loading configuration 2021-02-09T20:03:18.452Z INFO Using the kubernetes flag. 2021-02-09T20:03:18.762Z INFO using namespace default at https://192.168.39.12:8443 2021-02-09T20:03:18.763Z WARNING a file property was not found in your package.json, archiving the current directory. 2021-02-09T20:03:18.773Z INFO creating archive of .dockerignore, .gitignore, Dockerfile, README.md, package-lock.json, package.json, server.js 2021-02-09T20:03:18.774Z INFO Building Docker Image 2021-02-09T20:03:18.848Z TRACE {"stream":"Step 1/7 : FROM node:14"} 2021-02-09T20:03:18.848Z TRACE {"stream":"\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":" ---\u003e cb544c4472e9\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":"Step 2/7 : WORKDIR /usr/src/app"} 2021-02-09T20:03:18.849Z TRACE {"stream":"\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":" ---\u003e Using cache\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":" ---\u003e 57c9e3a4e918\n"} 2021-02-09T20:03:18.849Z TRACE {"stream":"Step 3/7 : COPY package*.json ./"} 2021-02-09T20:03:18.850Z TRACE {"stream":"\n"} 2021-02-09T20:03:19.050Z TRACE {"stream":" ---\u003e 742050ca3266\n"} 2021-02-09T20:03:19.050Z TRACE {"stream":"Step 4/7 : RUN npm install"} 2021-02-09T20:03:19.050Z TRACE {"stream":"\n"} 2021-02-09T20:03:19.109Z TRACE {"stream":" ---\u003e Running in f3477d5f2b00\n"} 2021-02-09T20:03:21.739Z TRACE {"stream":"\u001b[91mnpm WARN basic-node-app-dockerized@1.0.0 No description\n\u001b[0m"} 2021-02-09T20:03:21.744Z TRACE {"stream":"\u001b[91mnpm WARN basic-node-app-dockerized@1.0.0 No repository field.\n\u001b[0m"} 2021-02-09T20:03:21.745Z TRACE {"stream":"\u001b[91m\n\u001b[0m"} 2021-02-09T20:03:21.746Z TRACE {"stream":"added 50 packages from 37 contributors and audited 50 packages in 1.387s\n"} 2021-02-09T20:03:21.780Z TRACE {"stream":"found 0 vulnerabilities\n\n"} 2021-02-09T20:03:22.303Z TRACE {"stream":"Removing intermediate container f3477d5f2b00\n"} 2021-02-09T20:03:22.303Z TRACE {"stream":" ---\u003e afb97a82c035\n"} 2021-02-09T20:03:22.303Z TRACE {"stream":"Step 5/7 : COPY . ."} 2021-02-09T20:03:22.303Z TRACE {"stream":"\n"} 2021-02-09T20:03:22.481Z TRACE {"stream":" ---\u003e 1a451003c472\n"} 2021-02-09T20:03:22.481Z TRACE {"stream":"Step 6/7 : EXPOSE 8080"} 2021-02-09T20:03:22.482Z TRACE {"stream":"\n"} 2021-02-09T20:03:22.545Z TRACE {"stream":" ---\u003e Running in a76389d44b59\n"} 2021-02-09T20:03:22.697Z TRACE {"stream":"Removing intermediate container a76389d44b59\n"} 2021-02-09T20:03:22.697Z TRACE {"stream":" ---\u003e 8ee240b7f9ab\n"} 2021-02-09T20:03:22.697Z TRACE {"stream":"Step 7/7 : CMD [ \"node\", \"server.js\" ]"} 2021-02-09T20:03:22.698Z TRACE {"stream":"\n"} 2021-02-09T20:03:22.759Z TRACE {"stream":" ---\u003e Running in 1f7325ab3c64\n"} 2021-02-09T20:03:22.911Z TRACE {"stream":"Removing intermediate container 1f7325ab3c64\n"} 2021-02-09T20:03:22.912Z TRACE {"stream":" ---\u003e d7f5d1e95592\n"} 2021-02-09T20:03:22.912Z TRACE {"aux":{"ID":"sha256:d7f5d1e9559242f767b54b168c36df5c7cbce6ebc7eb1145d7f6292f20e8cda2"}} 2021-02-09T20:03:22.913Z TRACE {"stream":"Successfully built d7f5d1e95592\n"} 2021-02-09T20:03:22.929Z TRACE {"stream":"Successfully tagged basic-node-app-dockerized:latest\n"} 2021-02-09T20:03:22.933Z WARNING No .nodeshift directory 2021-02-09T20:03:22.954Z INFO openshift.yaml and openshift.json written to /home/lucasholmquist/develop/nodeshift-starters/basic-node-app-dockerized/tmp/nodeshift/resource/ 2021-02-09T20:03:22.975Z INFO creating new service basic-node-app-dockerized 2021-02-09T20:03:22.979Z TRACE Deployment Applied 2021-02-09T20:03:23.036Z INFO Application running at: http://192.168.39.12:30076 2021-02-09T20:03:23.036Z INFO complete &lt;/pre&gt; &lt;p&gt;Following the deployment, the Nodeshift CLI also provides the URL where the application is running in the console output. The output might look something like this:&lt;/p&gt; &lt;pre&gt;... INFO Application running at http://192.168.39.12:30769 ... &lt;/pre&gt; &lt;p&gt;Navigating to the URL provided returns &amp;#8220;Hello World.&amp;#8221;&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article gave a brief overview of the Nodeshift CLI&amp;#8217;s support for deploying to Minikube. In the future, we plan to add more Kubernetes platforms and other developer-friendly features, like possibly having the Nodeshift CLI create a default Dockerfile if there isn’t one.&lt;/p&gt; &lt;p&gt;If you like what you see and want to learn more, check out the &lt;a target="_blank" rel="nofollow" href="https://nodeshift.dev/"&gt;Nodeshift project&lt;/a&gt;. As always, if there are more features you would like to see, &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift/nodeshift"&gt;create an issue&lt;/a&gt; over on GitHub. To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js landing page.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#38;linkname=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fdeploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube%2F&amp;#038;title=Deploying%20Node.js%20applications%20to%20Kubernetes%20with%20Nodeshift%20and%20Minikube" data-a2a-url="https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/" data-a2a-title="Deploying Node.js applications to Kubernetes with Nodeshift and Minikube"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/"&gt;Deploying Node.js applications to Kubernetes with Nodeshift and Minikube&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/fAqJZg6t3vY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In a previous article, I showed how easy it was to deploy a Node.js application during development to Red Hat OpenShift using the Nodeshift command-line interface (CLI). In this article, we will take a look at using Nodeshift to deploy Node.js applications to vanilla Kubernetes—specifically, with Minikube. Getting started If you want to follow along [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/"&gt;Deploying Node.js applications to Kubernetes with Nodeshift and Minikube&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">865157</post-id><dc:creator>Lucas Holmquist</dc:creator><dc:date>2021-03-09T08:00:39Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/09/deploying-node-js-applications-to-kubernetes-with-nodeshift-and-minikube/</feedburner:origLink></entry><entry><title>A guide to Red Hat OpenShift 4.5 installer-provisioned infrastructure on vSphere</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/V3nPGQGz_F8/" /><category term="Kubernetes" /><category term="Linux" /><category term="Operator" /><category term="container host provisioning" /><category term="installer" /><category term="openshift" /><category term="RHEL" /><category term="vSphere" /><author><name>Nuttee Jirattivongvibul</name></author><id>https://developers.redhat.com/blog/?p=785627</id><updated>2021-03-09T08:00:38Z</updated><published>2021-03-09T08:00:38Z</published><content type="html">&lt;p&gt;With &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift 4&lt;/a&gt;, Red Hat completely re-architected how developers install, upgrade, and manage OpenShift to develop applications on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. Under the hood, the installation process uses the &lt;a target="_blank" rel="nofollow" href="https://github.com/openshift/installer"&gt;OpenShift installer&lt;/a&gt; to automate container host provisioning using &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) CoreOS. It is then easy to initialize the cluster and set up the cloud domain name system (DNS), load balancer, storage, and so on.&lt;/p&gt; &lt;p&gt;Initially, the fully automated OpenShift installation option (called &lt;em&gt;installer-provisioned infrastructure&lt;/em&gt;) was available only for public and private clouds. In &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/welcome/index.html"&gt;OpenShift 4.5&lt;/a&gt;, the installer was updated to support installer-provisioned infrastructure on &lt;a target="_blank" rel="nofollow" href="https://www.vmware.com/products/vsphere.html"&gt;VMware vSphere&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article is for enterprise IT users and developers who run their workloads on vSphere. I will show you how to bring up your OpenShift clusters in 30 minutes without the pain of needing to do manual tasks each time.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s walk through the prerequisites for using OpenShift&amp;#8217;s installer-provisioned infrastructure with vSphere. Make sure your development environment is set up as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;To download and run the OpenShift installer binary, you will need a &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; virtual machine (VM) or a Linux guest on your laptop. This host must be able to access your vCenter and VM subnet.&lt;/li&gt; &lt;li&gt;You will also need a VMware cluster with the following configuration: &lt;ul&gt; &lt;li&gt;One vCenter instance.&lt;/li&gt; &lt;li&gt;An ESXi cluster with the minimum for provisioning a standard OpenShift cluster.&lt;/li&gt; &lt;li&gt;vSphere 6.5 with hardware version 13 or 6.7 update 2.&lt;/li&gt; &lt;li&gt;800GB storage from the datastore.&lt;/li&gt; &lt;li&gt;18 or more virtual central processing units (vCPUs). The minimum setup is three leaders with four vCPUs per node and three followers with two vCPUs per node. The recommended configuration is four vCPUs on followers, even for lab purposes. You will also need a temporary vCPU for the bootstrap machine.&lt;/li&gt; &lt;li&gt;88GB memory. You will need three leaders with 16GB RAM per node, three followers with 8GB RAM per node, and 16GB temporary RAM for the bootstrap machine.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Network configurations&lt;/h3&gt; &lt;p&gt;You will need a network and subnet with Dynamic Host Configuration Protocol (DHCP) enabled with the long-lease time for this pool. As an example, my lab network is VM Network with the IP address of 198.18.1.0/24. The DHCP pool is at 198.18.1.11-200.&lt;/p&gt; &lt;p&gt;For the DNS server IP requirements, you will need a DNS server with two A records. Note that the two DNS A records point to the API and ingress virtual IP addresses. These will point to the OpenShift installer-provisioned cluster load balancer (&lt;a target="_blank" rel="nofollow" href="https://www.haproxy.com/"&gt;HAProxy&lt;/a&gt; with Keepalived run as containers in OpenShift nodes).&lt;/p&gt; &lt;p&gt;Here is how OpenShift vSphere&amp;#8217;s installer-provisioned infrastructure simplifies the load balancer service for the cluster:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;api.&amp;#60;cluster-name&amp;#62;.&amp;#60;base-domain&amp;#62;&lt;/code&gt; with one reserved IP address for the API virtual IP on the same cluster network. As an example, the IP address for &lt;code&gt;api.ocp01.example.com&lt;/code&gt; could be 198.18.1.201.&lt;/li&gt; &lt;li&gt;&lt;code&gt;*.apps.&amp;#60;cluster-name&amp;#62;.&amp;#60;base-domain&amp;#62;&lt;/code&gt; with one reserved IP address for the ingress virtual IP on the same cluster network. As an example, the IP address for &lt;code&gt;api.ocp01.example.com&lt;/code&gt; could be 198.18.1.202.&lt;/li&gt; &lt;li&gt;The DNS test result should look like this: &lt;pre&gt;[root@centos7-tools1 ~]# nslookup api.apps.ocp01.example.com Server: 198.18.133.1 Address: 198.18.133.1#53 Name: api.ocp01.example.com Address: 198.18.1.201 [root@centos7-tools1 ~]# nslookup api.apps.ocp01.example.com Server: 198.18.133.1 Address: 198.18.133.1#53 Name: api.ocp01.example.com Address: 198.18.1.201&lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Account privileges&lt;/h3&gt; &lt;p&gt;You will also need to configure the vCenter account privileges specified in the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/installing/installing_vsphere/installing-vsphere-installer-provisioned.html#installation-vsphere-installer-infra-requirements_installing-vsphere-installer-provisioned"&gt;OpenShift guide to installing a cluster on vSphere&lt;/a&gt;. Please set your account privileges before continuing with this guide.&lt;/p&gt; &lt;p&gt;Finally, you&amp;#8217;ll need a Red Hat account to access &lt;a target="_blank" rel="nofollow" href="https://cloud.redhat.com"&gt;cloud.redhat.com&lt;/a&gt; and retrieve your pull secret for the OpenShift self-supported 60-day trial.&lt;/p&gt; &lt;p&gt;When you are done, the infrastructure preparation should look similar to the diagram in Figure 1.&lt;/p&gt; &lt;div id="attachment_875697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1.png"&gt;&lt;img aria-describedby="caption-attachment-875697" class="wp-image-875697" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1.png" alt="Components in the external network and OpenShift cluster network." width="640" height="458" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1.png 937w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1-300x215.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-1-768x550.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-875697" class="wp-caption-text"&gt;Figure 1: Set up your development environment for installer-provisioned infrastructure on vSphere.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once your development environment is set up, we can continue to the next step.&lt;/p&gt; &lt;h2&gt;Set up the installer VM&lt;/h2&gt; &lt;p&gt;You need to perform a few one-time tasks before starting the OpenShift installer. Once you&amp;#8217;ve done these tasks, you will be able to re-use them to deploy as many clusters as you like.&lt;/p&gt; &lt;h3&gt;Generate the SSH private key&lt;/h3&gt; &lt;p&gt;Generate your secure shell (SSH) private and public key if you don&amp;#8217;t have one in your &lt;code&gt;~/.ssh/&lt;/code&gt; directory. You will need the key for OpenShift node access when it is time to perform debugging tasks:&lt;/p&gt; &lt;pre&gt;ssh-keygen -t rsa -b 4096 -N '' -f ~/.ssh/id_rsa&lt;/pre&gt; &lt;h3&gt;Obtain the installation and client binaries&lt;/h3&gt; &lt;p&gt;You can create your free account and go to the &lt;a target="_blank" rel="nofollow" href="https://cloud.redhat.com/openshift/install"&gt;Red Hat Cloud Services Portal—OpenShift Cluster Manager&lt;/a&gt; to obtain the installer and client binaries for your operating system. Do the following from the portal&amp;#8217;s web user interface:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Log in to the &lt;a target="_blank" rel="nofollow" href="https://cloud.redhat.com/openshift/install"&gt;OpenShift Cluster Manager&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Create an OpenShift cluster&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Choose &lt;strong&gt;Red Hat OpenShift Container Platform&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;On &lt;strong&gt;Select an infrastructure provider&lt;/strong&gt;, select &lt;strong&gt;Run on VMware vSphere&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;In the OpenShift installer, select your operating system binary, for example, Linux. Then, click &lt;strong&gt;Download installer&lt;/strong&gt;. If you want the latest release, use this download URL: &lt;a target="_blank" rel="nofollow" href="https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-install-linux.tar.gz"&gt;https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-install-linux.tar.gz&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Download pull secret&lt;/strong&gt; or copy the pull secret and save it to a file.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Download command-line tools&lt;/strong&gt; and select your operating system. Or, you can use this URL for the latest Linux binary: &lt;a target="_blank" rel="nofollow" href="https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux.tar.gz"&gt;https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux.tar.gz&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Extract the installation and client programs. For example, run this command: &lt;pre&gt;tar xvf openshift-install-linux.tar.gz tar xvf openshift-client-linux.tar.gz cp oc /usr/local/bin/ &lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Add the vCenter root CA certificates to your system trust&lt;/h3&gt; &lt;p&gt;The OpenShift installer requires access to vCenter&amp;#8217;s API, so the vCenter certificate must be trusted. Download the vCenter&amp;#8217;s root certificate authority (CA) certificates and extract and copy them to your system trust:&lt;/p&gt; &lt;pre&gt;export VCENTER=&lt;b&gt;&amp;#60;your vcenter hostname or IP Address&amp;#62;&lt;/b&gt; wget https://${VCENTER}/certs/download.zip --no-check-certificate unzip download.zip cp certs/lin/* /etc/pki/ca-trust/source/anchors update-ca-trust extract &lt;/pre&gt; &lt;p&gt;Your installer machine is now set up, and you can run the installer as many times as you want.&lt;/p&gt; &lt;h2&gt;Demonstration: Deploying a simple cluster&lt;/h2&gt; &lt;p&gt;For this demonstration, we will deploy a quick, standard cluster that doesn&amp;#8217;t require any customization.&lt;/p&gt; &lt;h3&gt;Run the installer&lt;/h3&gt; &lt;p&gt;The OpenShift installer is a command-line interface that requests your input for the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;SSH public key: For example, &lt;code&gt;/root/.ssh/id_rsa.pub&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Platform: vSphere.&lt;/li&gt; &lt;li&gt;vCenter: Your vCenter hostname, for example, &lt;code&gt;vc1.example.com&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Username: Your vCenter username, for example, &lt;code&gt;administrator@vsphere.local&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Password: Your vCenter password.&lt;/li&gt; &lt;li&gt;Network: Select your cluster network with the DHCP you previously set up.&lt;br /&gt; The OpenShift installer will connect to your vCenter and list your network for you to select.&lt;/li&gt; &lt;li&gt;A virtual IP address for the API: This is the IP address that you allocated and mapped to the &lt;code&gt;api.&amp;#60;cluster-name&amp;#62;.&amp;#60;base-domain&amp;#62;&lt;/code&gt; DNS record (for example, 198.18.1.201).&lt;/li&gt; &lt;li&gt;A virtual IP address for ingress: This is the IP address that you allocated and mapped to the &lt;code&gt;*.apps.&amp;#60;cluster-name&amp;#62;.&amp;#60;base-domain&amp;#62;&lt;/code&gt; DNS record (for example, 198.18.1.202).&lt;/li&gt; &lt;li&gt;Base domain: This will be the same as your &lt;code&gt;&amp;#60;base-domain&amp;#62;&lt;/code&gt;, such as &lt;code&gt;example.com&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Cluster name: This will be the same as your &lt;code&gt;&amp;#60;cluster-name&amp;#62;&lt;/code&gt;, such as &lt;code&gt;ocp01&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Pull secret: The pull secret that you downloaded or copied from the OpenShift cluster management page.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Here is an example of output from the OpenShift installer&amp;#8217;s installation process:&lt;/p&gt; &lt;pre&gt;export INSTALLATION_DIR=$HOME/ocp01-01 mkdir $INSTALLATION_DIR ./openshift-install create cluster --dir=$INSTALLATION_DIR --log-level=info ? SSH Public Key /root/.ssh/id_rsa.pub ? Platform vsphere ? vCenter vc1.example.com ? Username administrator@vsphere.local ? Password [? for help] ************* INFO Connecting to vCenter vc1.example.com INFO Defaulting to only available datacenter: DC1 INFO Defaulting to only available cluster: DC1-Cluster INFO Defaulting to only available datastore: NFS_Datastore ? Network: VM Network ? Virtual IP Address for API: 198.18.1.201 ? Virtual IP Address for Ingress: 198.18.1.202 ? Base Domain: example.com ? Cluster Name: ocp01 ? Pull Secret [? for help] *************** &lt;/pre&gt; &lt;h3&gt;Provision a bootstrap machine and leader nodes&lt;/h3&gt; &lt;p&gt;The OpenShift installer will now provision a bootstrap machine and three leader nodes. Your API virtual IP and ingress virtual IP will first host on the bootstrap machine for the leader nodes to self-initialize with the ignition and bootstrapping process. The deployment in the bootstrapping stage will look like the diagram in Figure 2.&lt;/p&gt; &lt;div id="attachment_875717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2.png"&gt;&lt;img aria-describedby="caption-attachment-875717" class="wp-image-875717" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2.png" alt="A diagram of the bootstrapping deployment." width="640" height="458" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2.png 937w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2-300x215.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-2-768x550.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-875717" class="wp-caption-text"&gt;Figure 2: Deployment in the bootstrapping stage.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When the bootstrapping is complete and all the leader node&amp;#8217;s API servers are up, the OpenShift bootstrap node will be destroyed automatically with the installer. Then, the installer will start provisioning the follower nodes with an &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/machine_management/creating-infrastructure-machinesets.html"&gt;OpenShift MachineSet&lt;/a&gt;. For this, you could do a machine auto-scaler or manually increase or decrease the nodes later, using either the OpenShift web console or command-line tools (&lt;code&gt;oc&lt;/code&gt; or &lt;code&gt;kubectl&lt;/code&gt;). The API virtual IP and ingress virtual IP will also be moved to &lt;em&gt;hosted&lt;/em&gt; status on the leader nodes and infrastructure and follower nodes.&lt;/p&gt; &lt;p&gt;Your deployment in the provisioning stage will look like the diagram in Figure 3.&lt;/p&gt; &lt;div id="attachment_875727" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3.png"&gt;&lt;img aria-describedby="caption-attachment-875727" class="wp-image-875727" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3.png" alt="A diagram of the deployment in the provisioning stage." width="640" height="458" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3.png 937w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3-300x215.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/VMware-IPI-step-3-768x550.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-875727" class="wp-caption-text"&gt;Figure 3: Deployment in the provisioning stage.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Provisioning the OpenShift cluster normally takes 40 to 60 minutes to complete.&lt;/p&gt; &lt;h2&gt;Post-installation configuration&lt;/h2&gt; &lt;p&gt;You can log into your cluster as a default system user by exporting a &lt;code&gt;kubeconfig&lt;/code&gt; file to &lt;code&gt;KUBECONFIG ENV&lt;/code&gt; vars. This file is created during the installation for a specific cluster and stored in &lt;code&gt;$INSTALLATION_DIR/auth/kubeconfig&lt;/code&gt;. Let&amp;#8217;s go through the post-installation configuration process together.&lt;/p&gt; &lt;p&gt;First, export the &lt;code&gt;kubeadmin&lt;/code&gt; credentials:&lt;/p&gt; &lt;pre&gt;export KUBECONFIG=$INSTALLATION_DIR/auth/kubeconfig&lt;/pre&gt; &lt;p&gt;Next, verify that you can run the &lt;code&gt;oc&lt;/code&gt; command successfully using the exported configuration:&lt;/p&gt; &lt;pre&gt;oc whoami oc get node &lt;/pre&gt; &lt;p&gt;Infrastructure administrators and developers can use the OpenShift console to work with Kubernetes clusters. To access the console for the first time, the installer generates a &lt;code&gt;kubeadmin&lt;/code&gt; credential in the &lt;code&gt;$INSTALLATION_DIR/auth/password&lt;/code&gt; file. Use the &lt;code&gt;oc&lt;/code&gt; command to get the URL for your OpenShift console:&lt;/p&gt; &lt;pre&gt;oc -n openshift-console get route &lt;/pre&gt; &lt;p&gt;Copy the URL and open it in your web browser, and use the initial credentials to log in. For the username, enter &lt;code&gt;kubeadmin&lt;/code&gt;; for the password, use the password from &lt;code&gt;$INSTALLATION_DIR/auth/kubeadmin_password&lt;/code&gt;, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_792547" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login.png"&gt;&lt;img aria-describedby="caption-attachment-792547" class="wp-image-792547 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login-1024x541.png" alt="The login screen." width="640" height="338" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login-1024x541.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login-300x158.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-login-768x405.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792547" class="wp-caption-text"&gt;Figure 4: The OpenShift console OAuth login screen.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 5 shows the overview page in the OpenShift console.&lt;/p&gt; &lt;div id="attachment_792557" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview.png"&gt;&lt;img aria-describedby="caption-attachment-792557" class="wp-image-792557 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview-1024x527.png" alt="The overview page shows the cluster details, status, and current utilization." width="640" height="329" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview-1024x527.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview-300x154.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-home-overview-768x395.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792557" class="wp-caption-text"&gt;Figure 5: The OpenShift console overview page.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Container registry storage&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/courses/openshift/getting-started"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; uses an internal registry to upgrade clusters and support continuous integration and continuous deployment (&lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;CI/CD&lt;/a&gt;) with containers built within clusters. You will need to set up storage for OpenShift&amp;#8217;s internal registry before you can deploy the demo application.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: For our example, we will use ReadWriteOnce (RWO) storage that supports only a single registry instance. For production, Red Hat recommends using the scalable registry that requires ReadWriteMany (RWX) storage.&lt;/p&gt; &lt;h3&gt;Configuring the OpenShift image registry&lt;/h3&gt; &lt;p&gt;You can configure the OpenShift image registry using either the web console or a command-line tool. I&amp;#8217;ll show you how to do this task both ways. If you are new to Kubernetes, you might find the OpenShift console helpful for seeing and understanding your cluster&amp;#8217;s status. On the other hand, using a CLI tool is powerful and gets the tasks done quickly with JSON or YAML declarations.&lt;/p&gt; &lt;h4&gt;Using the OpenShift web console&lt;/h4&gt; &lt;p&gt;The first thing you&amp;#8217;ll do is create a persistent volume claim (PVC) with 100GB capacity from the default storage class (&amp;#8220;thin&amp;#8221;) using the VMware datastore:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Change to the &lt;b&gt;openshift-image-registry&lt;/b&gt; project.&lt;/li&gt; &lt;li&gt;Go to &lt;b&gt;Storage &amp;#62; Persistent Volume Claims&lt;/b&gt; and click &lt;b&gt;Create Persistent Volume Claim&lt;/b&gt;, as shown in Figure 6. &lt;p&gt;&lt;div id="attachment_792637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1.png"&gt;&lt;img aria-describedby="caption-attachment-792637" class="wp-image-792637 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1-1024x546.png" alt="The initial page to create a persistent volume claim." width="640" height="341" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1-1024x546.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1-300x160.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1-768x409.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792637" class="wp-caption-text"&gt;Figure 6: Create a persistent volume claim.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Enter the following parameters: &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Storage Class&lt;/strong&gt;: &lt;code&gt;thin&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Persistent Volume Claim Name&lt;/strong&gt;: &lt;code&gt;image-registry-storage&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Access Mode&lt;/strong&gt;: &lt;code&gt;Single User (RWO)&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Size&lt;/strong&gt;: &lt;code&gt;100GiB&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Then, click &lt;b&gt;Create&lt;/b&gt;, as shown in Figure 7. &lt;p&gt;&lt;div id="attachment_792627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02.png"&gt;&lt;img aria-describedby="caption-attachment-792627" class="wp-image-792627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02-1024x637.png" alt="Configure the PVC, then click Create." width="640" height="398" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02-1024x637.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02-300x187.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-02-768x478.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792627" class="wp-caption-text"&gt;Figure 7: Configure and create the persistent volume claim.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Next, you will edit the registry configuration to use the &lt;strong&gt;&amp;#60;PVC name&amp;#62;&lt;/strong&gt; you&amp;#8217;ve just created and also update the &lt;code&gt;managementState&lt;/code&gt; and &lt;code&gt;updateStrategy&lt;/code&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Go to &lt;b&gt;Administration &amp;#62; Custom Resource Definitions&lt;/b&gt;, shown in Figure 8. &lt;p&gt;&lt;div id="attachment_792617" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01.png"&gt;&lt;img aria-describedby="caption-attachment-792617" class="wp-image-792617 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1024x546.png" alt="Edit the registry configuration to use the new PVC." width="640" height="341" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-1024x546.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-300x160.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-01-768x409.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792617" class="wp-caption-text"&gt;Figure 8: Go to &lt;strong&gt;Administration &amp;#62; Custom Resource Definitions&lt;/strong&gt; in the OpenShift web console.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Click on the &lt;b&gt;CRD Config&lt;/b&gt; of &lt;code&gt;imageregistry.operator.openshift.io&lt;/code&gt;, shown in Figure 9. &lt;p&gt;&lt;div id="attachment_792607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04.png"&gt;&lt;img aria-describedby="caption-attachment-792607" class="wp-image-792607 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04-1024x549.png" alt="Click the 'CRD config' link." width="640" height="343" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04-1024x549.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04-300x161.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-04-768x412.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792607" class="wp-caption-text"&gt;Figure 9: Click &lt;strong&gt;CRD Config&lt;/strong&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Change to the &lt;b&gt;Instance&lt;/b&gt; tab and click on the config name &lt;b&gt;cluster&lt;/b&gt;, shown in Figure 10. &lt;p&gt;&lt;div id="attachment_792597" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06.png"&gt;&lt;img aria-describedby="caption-attachment-792597" class="wp-image-792597 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06-1024x543.png" alt="Click the config name 'cluster.'" width="640" height="339" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06-1024x543.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06-300x159.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-06-768x407.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792597" class="wp-caption-text"&gt;Figure 10: Click the config name, &lt;strong&gt;cluster&lt;/strong&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Select the action &lt;b&gt;Edit Config&lt;/b&gt;, shown in Figure 11: &lt;p&gt;&lt;div id="attachment_792587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07.png"&gt;&lt;img aria-describedby="caption-attachment-792587" class="wp-image-792587 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07-1024x483.png" alt="Edit the configuration." width="640" height="302" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07-1024x483.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07-300x142.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-07-768x363.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792587" class="wp-caption-text"&gt;Figure 11: Select &lt;strong&gt;Edit Config&lt;/strong&gt;.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt;Edit the following parameters and click &lt;b&gt;Save&lt;/b&gt;: &lt;pre&gt;managementState: Managed rolloutStrategy: Recreate storage: pvc: claim: image-registry-storage &lt;/pre&gt; &lt;p&gt;Figure 12 shows the resulting YAML file on the &lt;b&gt;Config Details&lt;/b&gt; page.&lt;/p&gt; &lt;p&gt;&lt;div id="attachment_792577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08.png"&gt;&lt;img aria-describedby="caption-attachment-792577" class="wp-image-792577 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08-1024x418.png" alt="A screenshot of the YAML file." width="640" height="261" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08-1024x418.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08-300x123.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-08-768x314.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792577" class="wp-caption-text"&gt;Figure 12: The edited configuration file.&lt;/p&gt;&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The Image Registry Operator will now create an image registry for your OpenShift cluster. You can check by selecting &lt;b&gt;Project = openshift-image-registry&lt;/b&gt; and going to &lt;b&gt;Workloads &amp;#62; Pods&lt;/b&gt;. You will see the &lt;code&gt;image-registry&lt;/code&gt; pod is in the process of being created, as shown in Figure 13.&lt;/p&gt; &lt;div id="attachment_792567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09.png"&gt;&lt;img aria-describedby="caption-attachment-792567" class="wp-image-792567 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09-1024x520.png" alt="The image-registry pod was started seconds ago." width="640" height="325" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09-1024x520.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ocp-registry-pvc-09-768x390.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-792567" class="wp-caption-text"&gt;Figure 13: The image-registry pod is being created.&lt;/p&gt;&lt;/div&gt; &lt;h4&gt;Using the OpenShift CLI&lt;/h4&gt; &lt;p&gt;Now, we&amp;#8217;ll perform the same tasks using the OpenShift CLI. Once again, we start by creating a persistent volume claim:&lt;/p&gt; &lt;pre&gt;cat &amp;#60;&amp;#60;EOF &amp;#62;&amp;#62; image-registry-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: image-registry-storage namespace: openshift-image-registry spec: accessModes: - ReadWriteOnce resources: requests: storage: 100Gi storageClassName: 'thin' EOF oc apply -f image-registry-pvc.yaml &lt;/pre&gt; &lt;p&gt;Next, patch the &lt;code&gt;imageregistry.operator.openshift.io config&lt;/code&gt; &amp;#8220;cluster&amp;#8221;:&lt;/p&gt; &lt;pre&gt;$ oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed","rolloutStrategy":"Recreate","storage":{"pvc":{"claim":"image-registry-storage"}}}}'&lt;/pre&gt; &lt;p&gt;That&amp;#8217;s it! Your OpenShift cluster is ready to build and deploy to your container applications.&lt;/p&gt; &lt;h2&gt;Conclusion and next steps&lt;/h2&gt; &lt;p&gt;This article showed you how to use OpenShift&amp;#8217;s installer-provisioned infrastructure to quickly create and configure an enterprise-grade, production-ready Kubernetes cluster with Red Hat OpenShift Container Platform on VMware vSphere. Visit &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/"&gt;learn.openshift.com&lt;/a&gt; for free, guided hands-on labs to keep learning how to deploy your applications or learn basic OpenShift operations.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#38;linkname=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F09%2Fa-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere%2F&amp;#038;title=A%20guide%20to%20Red%20Hat%20OpenShift%204.5%20installer-provisioned%20infrastructure%20on%20vSphere" data-a2a-url="https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/" data-a2a-title="A guide to Red Hat OpenShift 4.5 installer-provisioned infrastructure on vSphere"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/"&gt;A guide to Red Hat OpenShift 4.5 installer-provisioned infrastructure on vSphere&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/V3nPGQGz_F8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;With Red Hat OpenShift 4, Red Hat completely re-architected how developers install, upgrade, and manage OpenShift to develop applications on Kubernetes. Under the hood, the installation process uses the OpenShift installer to automate container host provisioning using Red Hat Enterprise Linux (RHEL) CoreOS. It is then easy to initialize the cluster and set up the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/"&gt;A guide to Red Hat OpenShift 4.5 installer-provisioned infrastructure on vSphere&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">785627</post-id><dc:creator>Nuttee Jirattivongvibul</dc:creator><dc:date>2021-03-09T08:00:38Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/09/a-guide-to-red-hat-openshift-4-5-installer-provisioned-infrastructure-on-vsphere/</feedburner:origLink></entry><entry><title>Red Hat Summit Virtual Experience 2021: Register today</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qxEz7hH963I/" /><category term="Uncategorized" /><category term="Burr Sutter" /><category term="red hat summit" /><category term="Summit 2021" /><author><name>Red Hat Developer</name></author><id>https://developers.redhat.com/blog/?p=878357</id><updated>2021-03-08T08:00:55Z</updated><published>2021-03-08T08:00:55Z</published><content type="html">&lt;p&gt;Automation, application deployment, and how to speed up your journey to the cloud. These and other developer hot topics will take center stage at &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/summit"&gt;Red Hat Summit 2021&lt;/a&gt;. Join thousands of your peers by &lt;a target="_blank" rel="nofollow" href="https://reg.summit.redhat.com/flow/redhat/sum21/regGeneralAttendee/login?intcmp=7013a0000026UTXAA2"&gt;registering&lt;/a&gt; for our all-new, free, two-part virtual Summit experience. Keynote speaker Burr Sutter will be delving deep into developer technologies as we come together to learn, share stories of success and failure, and turn knowledge into action.&lt;/p&gt; &lt;p&gt;We’ve reimagined this year’s Red Hat Summit as a multi-part experience that includes two no-cost virtual components in April and June, followed by a series of small-scale in-person events later in the year.&lt;/p&gt; &lt;h2&gt;Virtual Experience | &lt;a target="_blank" rel="nofollow" href="https://www.addevent.com/event/gw5377211"&gt;April 27-28, 2021&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Join us online from wherever you are in the world.&lt;/p&gt; &lt;p&gt;What to expect:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Keynotes from Red Hat leaders&lt;/li&gt; &lt;li&gt;Exciting news and announcements&lt;/li&gt; &lt;li&gt;Global customer and partner spotlights&lt;/li&gt; &lt;li&gt;Live demos&lt;/li&gt; &lt;li&gt;Access to Red Hat experts&lt;/li&gt; &lt;li&gt;Games and entertainment&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Virtual Experience | &lt;a target="_blank" rel="nofollow" href="https://www.addevent.com/event/Kx5377253"&gt;June 15-16, 2021&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Build on what you learned in April in this second installment.&lt;/p&gt; &lt;p&gt;What to expect:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Seven channels of breakout sessions featuring in-depth technical content&lt;/li&gt; &lt;li&gt;Even more access to Red Hat experts&lt;/li&gt; &lt;li&gt;Customer stories and global content&lt;/li&gt; &lt;li&gt;Demos, chat lounges, and community engagement&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://reg.summit.redhat.com/flow/redhat/sum21/regGeneralAttendee/login?intcmp=7013a0000026UTXAA2"&gt;Visit the Red Hat Summit site to secure your spot at both events with one registration&lt;/a&gt;. &lt;a target="_blank" rel="nofollow" href="/summit"&gt;Bookmark this page&lt;/a&gt; for the latest Summit-related developer sessions and on-demand videos.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#038;title=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/" data-a2a-title="Red Hat Summit Virtual Experience 2021: Register today"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/"&gt;Red Hat Summit Virtual Experience 2021: Register today&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qxEz7hH963I" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Automation, application deployment, and how to speed up your journey to the cloud. These and other developer hot topics will take center stage at Red Hat Summit 2021. Join thousands of your peers by registering for our all-new, free, two-part virtual Summit experience. Keynote speaker Burr Sutter will be delving deep into developer technologies as [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/"&gt;Red Hat Summit Virtual Experience 2021: Register today&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">878357</post-id><dc:creator>Red Hat Developer</dc:creator><dc:date>2021-03-08T08:00:55Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/</feedburner:origLink></entry><entry><title>New developer quick starts and more in the Red Hat OpenShift 4.7 web console</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ihpK80S_v6g/" /><category term="CI/CD" /><category term="Kubernetes" /><category term="Operator" /><category term="Serverless" /><category term="helm charts" /><category term="openshift" /><category term="serverless" /><category term="Tekton" /><author><name>Serena Chechile Nichols</name></author><id>https://developers.redhat.com/blog/?p=873037</id><updated>2021-03-08T08:00:26Z</updated><published>2021-03-08T08:00:26Z</published><content type="html">&lt;p&gt;We are continuing to evolve the developer experience in &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com"&gt;Red Hat OpenShift 4.7&lt;/a&gt;. This article highlights what&amp;#8217;s new for developers in the OpenShift 4.7 web console. Keep reading to learn about exciting changes to the topology view, an improved developer catalog experience, new developer quick starts, user interface support for &lt;a target="_blank" rel="nofollow" href="/courses/middleware/openshift-pipelines"&gt;Red Hat OpenShift Pipelines&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="/topics/serverless-architecture"&gt;Red Hat OpenShift Serverless&lt;/a&gt;, and more.&lt;/p&gt; &lt;h2&gt;Quick-add in the topology view&lt;/h2&gt; &lt;p&gt;One of my favorite features in OpenShift 4.7 is the new quick-add option in the web console&amp;#8217;s topology view. You can use this UI control to search for an item from the developer catalog directly from the topology view without changing context. As you type, matches are dynamically shown in a list. You can then click on a match to see a quick overview in the right panel, then click on the call-to-action to install it. The demonstration in Figure 1 shows the new quick-add feature.&lt;/p&gt; &lt;div id="attachment_877827" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/quickadd.gif"&gt;&lt;img aria-describedby="caption-attachment-877827" class="wp-image-877827 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4.7-fig1.gif" alt="An animated demonstration of the quick-add feature." width="640" height="348" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877827" class="wp-caption-text"&gt;Figure 1: The new quick-add feature in the OpenShift web console&amp;#8217;s topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Additionally, the web console now offers persistent storage for user settings so that you can persist layouts in the topology view. We&amp;#8217;ve had many requests for this feature, shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_877837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/topology-layout.gif"&gt;&lt;img aria-describedby="caption-attachment-877837" class="wp-image-877837 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4-7-fig2.gif" alt="A demonstration of persistence in the topology graph layouts." width="640" height="369" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877837" class="wp-caption-text"&gt;Figure 2: Topology graph layouts are now persisted.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;New features in the developer catalog&lt;/h2&gt; &lt;p&gt;The developer catalog is a one-stop-shop for developers to get started quickly with OpenShift. We have improved the developer experience in OpenShift 4.7 by creating a consistent experience across catalogs while also offering contextual views for specific catalog types.&lt;/p&gt; &lt;p&gt;When entering the developer catalog, users can now view all content in a single catalog. Several sub-catalogs are available by default: Builder images, Helm charts, Operator-backed services, and samples. Other sub-catalogs are available based on the installed &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes/operators"&gt;Operators&lt;/a&gt;. OpenShift 4.7 has sub-catalogs for event sources and virtual machines, and more are coming in future releases.&lt;/p&gt; &lt;p&gt;When you drill into sub-catalogs, the features and filters exposed are specific to a given catalog type. As an example, did you know that administrators can add multiple Helm chart repositories? The Helm chart catalog exposes charts from multiple repositories and lets you filter by any Helm chart repository.&lt;/p&gt; &lt;p&gt;Finally, we have received many requests to allow administrators to customize the developer catalog experience. In OpenShift 4.7, we&amp;#8217;ve added a customization feature for catalog administrators. To modify the developer catalog&amp;#8217;s available categories, you only need to add a customization section to the console operator resource. You can then use the resulting YAML snippet to add the default categories to start with and edit them from there.&lt;/p&gt; &lt;h2&gt;Developer quick starts&lt;/h2&gt; &lt;p&gt;You can now access developer quick starts from the &lt;b&gt;+Add&lt;/b&gt; page or from the &lt;b&gt;Quick Starts&lt;/b&gt; item in the OpenShift web console&amp;#8217;s &lt;b&gt;Help&lt;/b&gt; menu. The quick-starts catalog, shown in Figure 3, offers a variety of new developer quick starts—try one out!&lt;/p&gt; &lt;div id="attachment_873397" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev.png"&gt;&lt;img aria-describedby="caption-attachment-873397" class="wp-image-873397 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-1024x562.png" alt="Tiles represent quick starts in the catalog." width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-1024x562.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-300x165.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-768x421.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-873397" class="wp-caption-text"&gt;Figure 3: Developer quick starts in the quick-starts catalog.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Tekton pipelines&lt;/h2&gt; &lt;p&gt;The OpenShift 4.7 web console offers a couple of enhancements for Tekton pipelines. For one, you can now easily access your Tekton pipeline metrics, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_873377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics.png"&gt;&lt;img aria-describedby="caption-attachment-873377" class="wp-image-873377 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-1024x615.png" alt="A demonstration of viewing Tekton metrics in the console." width="640" height="384" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-1024x615.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-300x180.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-768x461.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-873377" class="wp-caption-text"&gt;Figure 4: Tekton pipeline metrics.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We&amp;#8217;ve also enhanced the &lt;b&gt;PipelineRun&lt;/b&gt; details page, as demonstrated in Figure 5.&lt;/p&gt; &lt;div id="attachment_877857" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PLREnhancements.gif"&gt;&lt;img aria-describedby="caption-attachment-877857" class="wp-image-877857 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4-7-fig5.gif" alt="A demonstration of viewing the PipelineRun details page." width="640" height="369" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877857" class="wp-caption-text"&gt;Figure 5: The improved PipelineRun details page.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;From the &lt;b&gt;Events&lt;/b&gt; tab, you can now easily access events related to the &lt;code&gt;PipelineRun&lt;/code&gt;, including &lt;code&gt;TaskRun&lt;/code&gt; and pod events. You can also download logs from the &lt;b&gt;Logs&lt;/b&gt; tab.&lt;/p&gt; &lt;h2&gt;Serverless&lt;/h2&gt; &lt;p&gt;Web console support for OpenShift Serverless includes the ability to create channels. Once created, brokers and channels are displayed in the topology view. In addition to creating subscriptions and triggers from action menus, you can now drag-and-drop to initiate these actions from the topology view.&lt;/p&gt; &lt;p&gt;We have also enhanced the creation flow for event sources. Event sources are custom resources, and we needed to address scalability issues in this feature, so we’ve changed the user experience to be catalog-based. You can now view event sources along with other objects in the service catalog. Alternatively, you can click on the event source type and drill into a catalog solely focused on event sources. As an example, if you had the &lt;a target="_blank" rel="nofollow" href="/integration"&gt;Red Hat Integration&lt;/a&gt; &lt;a target="_blank" rel="nofollow" href="/topics/camel-k"&gt;Camel K&lt;/a&gt; Operator installed, you would see Camel K connectors in the catalog.&lt;/p&gt; &lt;p&gt;We’ve also updated the administrator perspective for OpenShift Serverless. The web console includes a primary navigation section for OpenShift Serverless, which contains two sub-sections. One sub-section focuses on serving resources, and the other is for eventing. You can navigate to these sections to find details about your OpenShift event sources, brokers, triggers, channels, and subscriptions. These items are also accessible in the developer perspective&amp;#8217;s topology view and on the search page.&lt;/p&gt; &lt;h2&gt;We want your feedback&lt;/h2&gt; &lt;p&gt;Community feedback helps us continually improve the OpenShift developer experience, and we want to hear from you. You can attend our office hours on &lt;a target="_blank" rel="nofollow" href="http://openshift.tv"&gt;Red Hat OpenShift Streaming&lt;/a&gt; or join the &lt;a target="_blank" rel="nofollow" href="https://groups.google.com/forum/#!forum/openshift-dev-users"&gt;OpenShift Developer Experience Google group&lt;/a&gt;. We hope you will share your tips for using the OpenShift web console, get help with what doesn’t work, and shape the future of the OpenShift developer experience. Ready to get started? &lt;a target="_blank" rel="nofollow" href="http://www.openshift.com/try"&gt;Try OpenShift today&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#038;title=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/" data-a2a-title="New developer quick starts and more in the Red Hat OpenShift 4.7 web console"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/"&gt;New developer quick starts and more in the Red Hat OpenShift 4.7 web console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ihpK80S_v6g" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;We are continuing to evolve the developer experience in Red Hat OpenShift 4.7. This article highlights what&amp;#8217;s new for developers in the OpenShift 4.7 web console. Keep reading to learn about exciting changes to the topology view, an improved developer catalog experience, new developer quick starts, user interface support for Red Hat OpenShift Pipelines and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/"&gt;New developer quick starts and more in the Red Hat OpenShift 4.7 web console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">873037</post-id><dc:creator>Serena Chechile Nichols</dc:creator><dc:date>2021-03-08T08:00:26Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/</feedburner:origLink></entry><entry><title>What’s new in Red Hat OpenShift’s Web Terminal Operator 1.2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/KxWHVnxmaAk/" /><category term="DevOps" /><category term="Kubernetes" /><category term="Linux" /><category term="Operator" /><category term="openshift" /><category term="OpenShift Operator" /><category term="web console" /><category term="Web Terminal Operator" /><author><name>jpinkney</name></author><id>https://developers.redhat.com/blog/?p=872357</id><updated>2021-03-08T08:00:11Z</updated><published>2021-03-08T08:00:11Z</published><content type="html">&lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;&amp;#8216;s Web Terminal Operator is a way for users to access a web terminal with common cluster tooling pre-installed. This gives you the power and flexibility to work with your product directly through the OpenShift web console, eliminating the need to have all your tooling installed locally.&lt;/p&gt; &lt;p&gt;This article is an overview of the new features introduced in Web Terminal Operator 1.2. These improvements include allowing cluster administrators to securely access the terminal, more information for users when a terminal has shut down due to inactivity, and a tooling update to align with OpenShift 4.7.&lt;/p&gt; &lt;h2&gt;Easier access to the OpenShift web console&lt;/h2&gt; &lt;p&gt;In Web Terminal Operator 1.2, cluster administrators can access the web terminal directly, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_872407" style="width: 650px" class="wp-caption alignnone"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-1.gif"&gt;&lt;img aria-describedby="caption-attachment-872407" class="wp-image-872407" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-1.gif" alt="A cluster administrator accessing the web terminal on the OpenShift web console." width="640" height="332" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-872407" class="wp-caption-text"&gt;Figure 1: Opening the web terminal as a cluster administrator.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, everyone on your cluster can access their own web terminal, regardless of their permission level. Note that for security reasons, cluster administrators will automatically bypass the namespace picker and have their web terminal created in the &lt;code&gt;openshift-terminal&lt;/code&gt; namespace. Other than that, the functionality remains the same as that of a user without the cluster-admin role.&lt;/p&gt; &lt;h2&gt;Understanding why a terminal has stopped&lt;/h2&gt; &lt;p&gt;To conserve resources, the web terminal automatically shuts down after 15 minutes of inactivity. In Web Terminal Operator 1.2, we’ve added more information to help users understand why a terminal has stopped (see Figure 2).&lt;/p&gt; &lt;div id="attachment_872417" style="width: 650px" class="wp-caption alignnone"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2.png"&gt;&lt;img aria-describedby="caption-attachment-872417" class="wp-image-872417" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2.png" alt="The web console informing the user that the terminal has closed due to inactivity." width="640" height="333" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2.png 821w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2-768x399.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-872417" class="wp-caption-text"&gt;Figure 2: The terminal window indicating why a terminal has shut down.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Web Terminal Operator 1.2 also offers an easier way to restart the terminal with the click of a button, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_872427" style="width: 649px" class="wp-caption alignnone"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-3.gif"&gt;&lt;img aria-describedby="caption-attachment-872427" class="wp-image-872427" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-3.gif" alt="Clicking the Restart terminal button to restart the session." width="639" height="336" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-872427" class="wp-caption-text"&gt;Figure 3: Click &lt;b&gt;Restart terminal&lt;/b&gt; to restart a session.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Updated tooling&lt;/h2&gt; &lt;p&gt;We have updated the default binaries in Web Terminal Operator 1.2 to include the latest versions of the built-in command-line tools, as shown in Table 1.&lt;/p&gt; &lt;table align="”center”"&gt; &lt;caption&gt;&lt;b&gt;Table 1: Command-line tools in Web Terminal Operator 1.2&lt;/b&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;Binary&lt;/th&gt; &lt;th&gt;Old version&lt;/th&gt; &lt;th&gt;New version&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;oc&lt;/code&gt;&lt;/td&gt; &lt;td&gt;4.6.1&lt;/td&gt; &lt;td&gt;4.7.0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;kubectl&lt;/code&gt;&lt;/td&gt; &lt;td&gt;1.19.0&lt;/td&gt; &lt;td&gt;1.20.1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;odo&lt;/code&gt;&lt;/td&gt; &lt;td&gt;2.0.0&lt;/td&gt; &lt;td&gt;2.0.4&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;helm&lt;/code&gt;&lt;/td&gt; &lt;td&gt;3.3.4&lt;/td&gt; &lt;td&gt;3.5.0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;kn&amp;#60;/code&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.16.1&lt;/td&gt; &lt;td&gt;0.19.1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;tkn&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.11.0&lt;/td&gt; &lt;td&gt;0.15.0&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;p&gt;For a peek into how the Web Terminal Operator works under the hood, see &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/blog/a-deeper-look-at-the-web-terminal-operator-1"&gt;&lt;i&gt;A deeper look at the Web Terminal Operator&lt;/i&gt;&lt;/a&gt; by Angel Misevski. You can also check out the initial release article by Joshua Wood: &lt;a target="_blank" rel="nofollow" href="/blog/2020/10/01/command-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview/"&gt;&lt;i&gt;Command-line cluster management with Red Hat OpenShift’s new web terminal&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#038;title=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/" data-a2a-title="What’s new in Red Hat OpenShift’s Web Terminal Operator 1.2"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/"&gt;What&amp;#8217;s new in Red Hat OpenShift&amp;#8217;s Web Terminal Operator 1.2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/KxWHVnxmaAk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;&amp;#160; Red Hat OpenShift&amp;#8216;s Web Terminal Operator is a way for users to access a web terminal with common cluster tooling pre-installed. This gives you the power and flexibility to work with your product directly through the OpenShift web console, eliminating the need to have all your tooling installed locally. This article is an overview [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/"&gt;What&amp;#8217;s new in Red Hat OpenShift&amp;#8217;s Web Terminal Operator 1.2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">872357</post-id><dc:creator>jpinkney</dc:creator><dc:date>2021-03-08T08:00:11Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/</feedburner:origLink></entry><entry><title>Introduction to the Node.js reference architecture, Part 1: Overview</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pilWCtxrdN0/" /><category term="JavaScript" /><category term="Node.js" /><category term="Open source" /><category term="npm" /><category term="reference architecture" /><author><name>Michael Dawson</name></author><id>https://developers.redhat.com/blog/?p=865807</id><updated>2021-03-08T08:00:06Z</updated><published>2021-03-08T08:00:06Z</published><content type="html">&lt;p&gt;Welcome to this new series introducing the &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js reference architecture&lt;/a&gt; from Red Hat and IBM. This article is an overview of our reasons for developing the Node.js reference architecture—both what we hope the architecture will offer our developer community and what we &lt;em&gt;do not&lt;/em&gt; intend it to do. Future articles will offer a detailed look at different sections of the reference architecture.&lt;/p&gt; &lt;p&gt;Before we dive into this first article, it&amp;#8217;s important to acknowledge that the &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; reference architecture is a work in progress. The development team is working through different areas, discussing what we&amp;#8217;ve learned, and distilling that information into concise recommendations and guidance. Given the fast pace of development in the &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; ecosystem, the reference architecture might never be “finished.” Instead, we&amp;#8217;ll continue updating it to reflect what we learn through new Node.js production deployments and ongoing experience with our deployments at scale. The reference architecture is meant to reflect our current experience and thinking, which will evolve.&lt;/p&gt; &lt;h2&gt;Why we need a Node.js reference architecture&lt;/h2&gt; &lt;p&gt;The JavaScript ecosystem is fast-moving and vibrant. You only need to look at the &lt;a target="_blank" rel="nofollow" href="http://www.modulecounts.com/"&gt;growth rate of Node Package Manager (npm) modules&lt;/a&gt; to see that. In 2016, there were approximately 250,000 npm packages. In 2018, that number climbed to around 525,000, and in 2020 it was roughly 1.1 million. These numbers represent considerable choice and variety in the JavaScript ecosystem. That is clearly a strength for flourishing innovation and testing new ideas.&lt;/p&gt; &lt;p&gt;On the flip side, the wide variety of options can make choosing among Node.js packages very difficult. For any module, you might find several equally good choices, as well as several potentially very bad choices. Every application has a “secret sauce” that is key to its success. It is imperative to find the best fitting, newest, or most innovative package to use for this area of the application. For the rest of the application, you likely want something that works and for which you can share any experiences or best practices across your organization. In the latter case, having a reference architecture can help teams avoid relearning the same things again and again.&lt;/p&gt; &lt;h2&gt;What the reference architecture is&lt;/h2&gt; &lt;p&gt;Our Node.js teams at Red Hat and IBM can&amp;#8217;t be experts on 1.1 million JavaScript packages in the &lt;code&gt;npm&lt;/code&gt; registry. Similarly, we can&amp;#8217;t be involved in all of the projects to the level that we are involved in the Node.js project. Instead, our experience is based on our broad usage of Node.js. This includes large-scale deployments like the &lt;a target="_blank" rel="nofollow" href="https://developer.ibm.com/languages/node-js/articles/nodejs-weather-company-success-story/"&gt;Weather Company&lt;/a&gt;, as well as the work that our consulting groups do with customers.&lt;/p&gt; &lt;p&gt;If every internal team and customer who asks for help with their Node.js application uses different packages, it will be much harder to help them. The question is, how do we share our knowledge across the organization?&lt;/p&gt; &lt;p&gt;We want to help our internal teams and customers make good choices and deployment decisions. In cases where a team doesn&amp;#8217;t need to use a specific package, we can recommend a package based on the experience we’ve built across Red Hat and IBM. As developers, we can use the Node.js reference architecture to share and collaborate across teams and projects and establish common ground within our deployments.&lt;/p&gt; &lt;h2&gt;What the reference architecture is not&lt;/h2&gt; &lt;p&gt;I have described what we hope to do with the Node.js reference architecture. It is just as important to be clear about what we are &lt;em&gt;not&lt;/em&gt; trying to do.&lt;/p&gt; &lt;p&gt;First, the reference architecture is not an attempt to convince or force developers to use the packages we choose. Deployments are varied, and there will be good reasons to use specific modules in different circumstances.&lt;/p&gt; &lt;p&gt;Second, we do not claim that our recommendations are better than the alternatives. As I noted, you will often find several equally good packages or approaches available in the JavaScript ecosystem. Our recommendations favor what the Red Hat and IBM teams have used successfully and the technologies we are familiar with. We are not attempting to steer anyone to the “best” choice but instead to a “good” choice. Having a reference architecture maximizes the likelihood of leveraging lessons already learned and having common ground so that we can help each other.&lt;/p&gt; &lt;h2&gt;About this series&lt;/h2&gt; &lt;p&gt;The Node.js development team is having interesting discussions as we work through each section of the reference architecture. At the same time, we are trying to keep the reference architecture&amp;#8217;s content concise and to the point. As I&amp;#8217;ve mentioned, the goal is to provide good choices for the application&amp;#8217;s general architecture so that developers can focus on the application&amp;#8217;s &amp;#8220;secret sauce.&amp;#8221; In most cases, developers using the reference architecture will want to know what package or technology to use and how. As a result, the reference architecture won&amp;#8217;t include much about the interesting background and discussions that led to our decisions.&lt;/p&gt; &lt;p&gt;This series &lt;em&gt;will&lt;/em&gt; share the viewpoints gained from our internal discussions. As we work through each section of the reference architecture, we&amp;#8217;ll use this series to offer additional references and an opportunity to dive into more detail on related topics. I think you’ll find the varied experience of developers across the Node.js team gets you thinking. I learn something from every section we go through, and I hope you will, too.&lt;/p&gt; &lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;We plan to cover new topics regularly as part of this series. While you wait for the next installment, we invite you to visit the &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js reference architecture repository&lt;/a&gt; on GitHub. You&amp;#8217;ll be able to see the work we&amp;#8217;ve already done and the kinds of topics you can look forward to from this series. To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js landing page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#038;title=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/" data-a2a-title="Introduction to the Node.js reference architecture, Part 1: Overview"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/"&gt;Introduction to the Node.js reference architecture, Part 1: Overview&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pilWCtxrdN0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Welcome to this new series introducing the Node.js reference architecture from Red Hat and IBM. This article is an overview of our reasons for developing the Node.js reference architecture—both what we hope the architecture will offer our developer community and what we do not intend it to do. Future articles will offer a detailed look [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/"&gt;Introduction to the Node.js reference architecture, Part 1: Overview&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">865807</post-id><dc:creator>Michael Dawson</dc:creator><dc:date>2021-03-08T08:00:06Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/</feedburner:origLink></entry><entry><title type="html">Supply chain integration - An architectural introduction</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/RglmmpBvDao/supply-chain-integration-an-architectural-introduction.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/pvxTT3ZYk8A/supply-chain-integration-an-architectural-introduction.html</id><updated>2021-03-08T06:00:00Z</updated><content type="html">Part 1 - An architectural introduction If you've been following my writing over the last few years, you've grown accustomed to my sharing of various architecture blueprints. They're focusing on presenting access to ways of mapping successful implementations for specific use cases. It's an interesting challenge in our mission of creating of architectural content based on common customer adoption patterns. That's very different from most of the traditional marketing activities usually associated with generating content for the sole purpose of positioning products for solutions. When you're basing the content on actual execution in solution delivery, you're cutting out the chuff.  What's that mean? It means that it's going to provide you with a way to implement a solution using open source technologies by focusing on the integrations, structures and interactions that actually have been proven to work. What's not included are any vendor promises that you'll find in normal marketing content. Those promised that when it gets down to implementation crunch time, might not fully deliver on their promises. Enter the term Architectural Blueprint.  Let's look at these blueprints, how their created and what value they provide for your solution designs. THE PROCESS The first step is to decide the use case to start with, which in my case had to be linked to a higher level theme that becomes the leading focus. This higher level theme is not quite boiling the ocean, but it's so broad that it's going to require some division in to smaller parts. In this case we've aligned with the higher level theme being 'Retail' use cases, a vertical focus. This breaks down into the following use cases and in no particular order: * * * Point of sale * Headless eCommerce * Store health and safety * Real-time stock control * Retail data framework The case I'm tackling here is focused on supply chain integration. This use case we've defined as the following: Streamlining integration between different elements of a retail supply chain for on-premise, cloud, and other third-party interactions. The approach taken is to research our existing customers that have implemented solutions in this space, collect their public facing content, research the internal implementation documentation collections from their successful engagements, and where necessary reach out to the field resources involved.  To get an idea of what these blueprints look like, we refer you to the series previously discussed here: * * * * Now on to the task at hand. WHAT'S NEXT The resulting content for this project targets the following three items. * A slide deck of the architectural blueprint for use telling the portfolio solution story. * Generic architectural diagrams providing the general details for the portfolio solution. * A write-up of the portfolio solution in a series that can be used for a customer solution brief. An overview of this series on business optimisation portfolio architecture blueprint: 1. 2. Common architectural elements 3. Example of supply chain integration Catch up on any past articles you missed by following any published links above. Next in this series, taking a look at the generic common architectural elements for the supply chain integration architecture. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/RglmmpBvDao" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/pvxTT3ZYk8A/supply-chain-integration-an-architectural-introduction.html</feedburner:origLink></entry><entry><title type="html">Trying DB2 in Kubernetes for developers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qPr-LeKzOYU/" /><author><name /></author><id>https://blog.ramon-gordillo.dev/2021/03/trying-db2-in-kubernetes-for-developers/</id><updated>2021-03-08T00:00:00Z</updated><content type="html">Recently I have been asked a lot of similar questions like “does it make sense to invest in deploying legacy technology on kubernetes?". Well, first of all, I have to say that some technologies that are considered “legacy” have tons of new exciting features for the new workloads and applications. This is, for example, the case of DB2 with spatial queries and many others that you may have a look at (to be honest, I have very few experience with it). Secondly, not all the applications are greenfield. There are lots of old ones that are using those “legacy” technologies. Even some greenfield ones need to use data stored in long life systems. If I want to modernize those applications or build new ones based on these data, I should be able to develop in a friendly environment. And as a developer, I would be more than happy if I can create an instance where I have total control and that I can reuse the agility of containers. That is why I was tempted to try DB2 on containers. I was looking at an alternative to do as quickly as possible, so that is why I took some decisions that maybe do not follow exactly the guidelines that I would link as a reference. DISCLAIMER This is just a personal exercise, it does not represent IBM procedures or recommendations in any way. DB2® is copyright by IBM, every time I refer to DB2 it should be assumed implicitly DB2®. It is not an open source technology under different licences by IBM, in this case I would use the community edition, whose license and other details are commented . I would like to mention that is only an exercise. Please, use the recommended, documented and supported procedure if you need an stable version for your particular use case. Additionally we should remember db2 technology as most of the traditional databases, uses low level access to some resources (like shared memory, processes, and so on) to perform best on bare metal/virtual environments. That means it still , and although they are working on adapting better to cloud and containers, we are not used to see them in container native technologies. PREREQUISITES KUBERNETES As I have done in previous posts, I am using minikube for this exercise and a local domain served by dnsmasq on my laptop. That provides me the ability of working offline once the container images are deployed on the cluster. In my test I have used a configuration or 6 cpus and 12 Gb of RAM, as suggested in . If we are not deploying the Unified Console, we can reduce it to 4 cpus. I used the following command (check your driver): minikube start --cpus=6 --memory=12288 --driver=kvm2 --addons dashboard,ingress,metrics-server Additionally, in some steps we will need some ingress objects with passthrough ssl. That will simplify to provide SNI negotiation. To , review the deployment and add the --enable-ssl-passthrough arguments to the container ones. IBM API KEY You should register in IBM as a developer, and create an API key. I have used the console using . DEPLOYMENT I have modified a couple of things from the documentation I have found and linked, the most relevant are: * Use helm 3 instead of helm 2, because after November 2020 . * In vanilla kubernetes for developers, we don’t need to worry about , which provides an extra security to OpenShift environments. As our dev cluster is in a laptop, I can relax a little bit the security requirements (note: if the environment is shared, review the security or consider alternatives to avoid bad times). PREPARATION First, clone the repo . Go to stable/ibm-db2 folder, where there you can find most of the artifacts and information to deploy db2 community edition on OpenShift. We are now creating the namespace for deploying the database. We are creating a service account and provide the privileges through a role and a role binding to create some additional objects, as the helm chart will deploy some jobs to create the whole infrastructure on the namespace. kubectl create namespace db2 kubectl create serviceaccount db2u -n db2 kubectl create -f ibm_cloud_pak/pak_extensions/pre-install/namespaceAdministration/ibm-db2-role.yaml -n db2 kubectl create -f ibm_cloud_pak/pak_extensions/pre-install/namespaceAdministration/ibm-db2-rb.yaml -n db2 Then, as we will use a private registry (the ibm one), we need to set up the credentials for it. With the API Key that you should have obtained in the prerequisites, create a secret and add it to the service account to allow pulling the images needed for the deployment. kubectl create secret -n db2 docker-registry ibm-registry \ --docker-server=icr.io \ --docker-username=iamapikey \ --docker-password=&lt;api_key&gt; kubectl patch serviceaccount db2u -n db2 -p '{"imagePullSecrets": [{"name": "ibm-registry"}]}' We are now ready to deploy the database. DEPLOYMENT The official deployment script is db2u-install on the ibm_cloud_pak/pak_extensions/common folder. It encapsulates the helm 2 script, so I have done a little hack in order to use helm 3 and avoid using tiller. Also, I wanted to get the secrets created automatically, so I need to change generateSecrets=true that is false in the original script. With all those changes, we can create the jobs that will deploy all the infra, executing the helm command from stable/ibm-db2 folder. helm install db2poc $PWD --namespace db2 --values $PWD/values.yaml --set arch=x86_64 --set servicename=db2poc --set ldap.ldap_server=db2poc-db2u-ldap --set global.dbType=db2oltp --set database.name=BLUDB --set generateSecrets=true --set storage.storageClassName=standard --set storage.useDynamicProvisioning=true And voilá, after downloading images, and creating everything,we have a brand new db2 instance in our kuberenets cluster. We are going to do some additional tests to double check everything is ok. In the following picture, we can see the main architecture for the deployment. CREATING A DEVELOPER USER From , we have some hints on how to create an user on the ldap that this db2 instance uses as identity provider. tools_pod=$(kubectl get po -n db2 -o name | grep db2poc-db2u-tools) kubectl exec -it ${tools_pod} -- addLdapUser.py -u admin -p h4ck1t -r admin We will get something like Next UID will be 5003 Adding admin to LDAP server Updating LDAP password for user admin Added user to LDAP server After creating the user on the ldap, we check it is valid for use as db2 user: kubectl exec -it db2poc-db2u-0 -- id admin kubectl exec -it db2poc-db2u-0 -- su db2inst1 -c "~/sqllib/bin/db2 connect to bludb user admin using h4ck1t" If everything is ok, we will get uid=5003(admin) gid=3000(bluadmin) groups=3000(bluadmin) Database Connection Information Database server = DB2/LINUXX8664 11.5.4.0 SQL authorization ID = ADMIN Local database alias = BLUDB OPTIONAL: UNIFIED CONSOLE The instructions to deploy the unified console in the same namespace as the db2 instance are explaine in . Like previously, we prefer to use helm 3, so instead of using deploy-console.sh script, we are running directly the helm command. From the root path of your github clone, move to the stable/ibm-unified-console folder. Then, run the following command. helm install db2poc-console $PWD --set configMapName=db2poc-db2u-uc-config --set dataServer.ldap.rootPwdSecretName=db2poc-db2u-ldap --set dataServer.metadb.pwdSecretName=db2poc-db2u-instance --set dataServer.sharedPVC.name=db2poc-db2u-sqllib-shared --set global.image.secretName=ibm-registry -f $PWD/ibm_cloud_pak/pak_extensions/values-standalone-console.yaml --namespace db2 After deploying the chart, an additional ingress is needed. The deploy-console.sh creates the route object for OpenShift, a similar command for vanilla kubernetes ingress on nginx whould be: cat &lt;&lt; _EOF_ |kubectl apply -f - apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: db2poc-console namespace: db2 annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: "true" spec: rules: - host: db2poc-console.db2.minikube.cloud http: paths: - backend: service: name: db2poc-console-ibm-unified-console-ui port: number: 443 path: / pathType: ImplementationSpecific _EOF_ If everything is right, you may login into the ingress host (in my case, ) with the user credentials you have created previously and see a picture like the following. The whole architecture including the unified console now is as depicted. TESTING The chart deploys a nodeport service to access the database connecting through plain and ssl ports. We are going to do some initial tests based on it, but we are going to set up an ingress to use ssl passthrough to connect from outside the cluster. I am testing the connection using , which is under . These instructions will be similar to other jdbc-based database tools. At the time of writing this post, I have used the 11.5.4 client jdbc driver that can be downloaded from . As a reference, I use the document for setting up the connection. echo "Minikube IP is" $(minikube ip) echo "Non-secure NodePort is" $(kubectl get service db2poc-db2u-engn-svc -o jsonpath='{.spec.ports[?(@.name=="legacy-server")].nodePort}' ) Bearing in mind the default database is bludb, we add the alias jdbc:db2://&lt;minikube_ip&gt;:&lt;nodeport&gt;/bludb to connect, and get a successful session through the unsecure nodeport. I usually prefer to connect through a ssl passthrough ingress to the database from outside. A nodeport is ok, but has some drawbacks. If you want to try the ingress option, it is as simple as creating it with: cat &lt;&lt; _EOF_ |kubectl apply -f - apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: db2poc-db2u namespace: db2 annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-passthrough: "true" spec: rules: - host: "db2poc-db2u.minikube.cloud" http: paths: - backend: service: name: db2poc-db2u port: number: 50001 path: / pathType: ImplementationSpecific _EOF_ Now, you need the cert chain to add to the jdbc properties. You can extract the CA and the certificate connecting with openssl to the secured ingress connection, in my case using the following. echo -n | openssl s_client -connect db2poc-db2u.minikube.cloud:443 -servername db2poc-db2u.minikube.cloud -showcerts 2&gt;/dev/null |sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' &gt; /tmp/certs.pem In order to double check, the cert subject should be: CN=ibm.com,OU=ICP,O=IBM,L=Toronto,ST=Ontario,C=CA CN=ibm.com,OU=db2ssl,O=IBM,L=Toronto,ST=Ontario,C=CA You need to add those certs to a java keystore (jks). We can do it through the command line with keytool or use a visual tool like . Once you have the jks, you only need to add that information to the jdbc. A brief and useful can help you through the parameters. An example of secured url through the ingress is jdbc:db2://db2poc-db2u.minikube.cloud:443/bludb:sslConnection=true;sslTrustStoreLocation=/tmp/db2-server.jks;sslTrustStorePassword=h4ck1t;. Don’t forget the semicolon at the end of the url! MORE INFORMATION Other than the previous links and their related pages, you may find some useful information about the architecture, sizing, etc, for a production deployment on OpenShift in&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qPr-LeKzOYU" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://blog.ramon-gordillo.dev/2021/03/trying-db2-in-kubernetes-for-developers/</feedburner:origLink></entry></feed>
